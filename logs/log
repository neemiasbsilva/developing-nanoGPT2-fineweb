2024-06-14 18:42:27,194 train.py gpt_config=GPTConfig(block_size=1024, vocab_size=50304, n_layer=12, n_head=12, n_embd=768) train_config=TrainConfig(random_state=42, total_batch_size=5242888, batch_size=16, sequence_length=1024, max_lr=0.0006, warmup_steps=715, max_steps=19073, weight_decay=0.1) data_config=DataConfig(data_root='data/processed/edu_fineweb10B')
2024-06-14 18:42:27,532 train.py Using device: cuda
2024-06-14 18:42:27,927 train.py Total desired batch size: 5242888
2024-06-14 18:42:27,928 train.py => calculated gradient accumulation steps: 320
2024-06-14 18:42:27,928 manager_data.py found 99 shards for split train
2024-06-14 18:42:28,349 manager_data.py found 1 shards for split val
2024-06-14 18:42:37,406 gpt2_model.py num decayed tensors: 51 | num of parameters: 162988032
2024-06-14 18:42:37,407 gpt2_model.py num non-decayed tensors: 98 | num of parameters: 121344
2024-06-14 18:43:08,209 train.py validation loss: 11.0213
2024-06-14 18:45:08,384 train.py step     0 | loss: 11.027695 | lr 8.3916e-07 | norm: 14.3291 | dt: 150975.71ms | tok/sec: 34726.65
2024-06-14 18:46:33,669 train.py step     1 | loss: 10.977922 | lr 1.6783e-06 | norm: 14.0113 | dt: 85284.43ms | tok/sec: 61475.23
2024-06-14 18:47:59,003 train.py step     2 | loss: 10.880912 | lr 2.5175e-06 | norm: 13.8977 | dt: 85333.06ms | tok/sec: 61440.20
2024-06-14 18:49:24,362 train.py step     3 | loss: 10.748536 | lr 3.3566e-06 | norm: 12.7454 | dt: 85359.27ms | tok/sec: 61421.33
2024-06-14 18:50:49,734 train.py step     4 | loss: 10.596173 | lr 4.1958e-06 | norm: 10.7963 | dt: 85371.45ms | tok/sec: 61412.57
2024-06-14 18:52:15,083 train.py step     5 | loss: 10.452603 | lr 5.0350e-06 | norm: 8.9600 | dt: 85348.77ms | tok/sec: 61428.89
2024-06-14 18:53:40,364 train.py step     6 | loss: 10.326414 | lr 5.8741e-06 | norm: 7.6634 | dt: 85280.69ms | tok/sec: 61477.93
2024-06-14 18:55:05,647 train.py step     7 | loss: 10.205937 | lr 6.7133e-06 | norm: 6.7805 | dt: 85281.77ms | tok/sec: 61477.15
2024-06-14 18:56:30,946 train.py step     8 | loss: 10.096906 | lr 7.5524e-06 | norm: 5.8825 | dt: 85298.45ms | tok/sec: 61465.12
2024-06-14 18:57:56,231 train.py step     9 | loss: 9.992125 | lr 8.3916e-06 | norm: 5.0448 | dt: 85284.59ms | tok/sec: 61475.12
2024-06-14 18:59:21,507 train.py step    10 | loss: 9.912889 | lr 9.2308e-06 | norm: 4.2329 | dt: 85275.89ms | tok/sec: 61481.39
2024-06-14 19:00:46,772 train.py step    11 | loss: 9.837478 | lr 1.0070e-05 | norm: 3.6629 | dt: 85264.27ms | tok/sec: 61489.77
2024-06-14 19:02:12,019 train.py step    12 | loss: 9.780374 | lr 1.0909e-05 | norm: 3.2745 | dt: 85246.18ms | tok/sec: 61502.82
2024-06-14 19:03:37,266 train.py step    13 | loss: 9.729486 | lr 1.1748e-05 | norm: 2.9446 | dt: 85247.16ms | tok/sec: 61502.11
2024-06-14 19:05:02,469 train.py step    14 | loss: 9.673626 | lr 1.2587e-05 | norm: 2.7613 | dt: 85202.81ms | tok/sec: 61534.12
2024-06-14 19:06:27,714 train.py step    15 | loss: 9.662128 | lr 1.3427e-05 | norm: 2.4868 | dt: 85243.68ms | tok/sec: 61504.62
2024-06-14 19:07:52,911 train.py step    16 | loss: 9.624195 | lr 1.4266e-05 | norm: 2.4067 | dt: 85197.30ms | tok/sec: 61538.10
2024-06-14 19:09:18,121 train.py step    17 | loss: 9.601824 | lr 1.5105e-05 | norm: 2.3304 | dt: 85209.44ms | tok/sec: 61529.33
2024-06-14 19:10:43,326 train.py step    18 | loss: 9.567920 | lr 1.5944e-05 | norm: 2.2917 | dt: 85204.14ms | tok/sec: 61533.16
2024-06-14 19:12:08,555 train.py step    19 | loss: 9.550309 | lr 1.6783e-05 | norm: 2.3351 | dt: 85228.71ms | tok/sec: 61515.42
2024-06-14 19:13:33,772 train.py step    20 | loss: 9.549826 | lr 1.7622e-05 | norm: 2.2166 | dt: 85216.99ms | tok/sec: 61523.88
2024-06-14 19:14:58,958 train.py step    21 | loss: 9.519933 | lr 1.8462e-05 | norm: 2.2268 | dt: 85185.43ms | tok/sec: 61546.67
2024-06-14 19:16:24,111 train.py step    22 | loss: 9.480587 | lr 1.9301e-05 | norm: 2.2442 | dt: 85152.30ms | tok/sec: 61570.62
2024-06-14 19:17:49,298 train.py step    23 | loss: 9.452349 | lr 2.0140e-05 | norm: 2.1923 | dt: 85186.56ms | tok/sec: 61545.86
2024-06-14 19:19:14,498 train.py step    24 | loss: 9.429703 | lr 2.0979e-05 | norm: 2.1526 | dt: 85199.46ms | tok/sec: 61536.54
2024-06-14 19:20:39,710 train.py step    25 | loss: 9.412748 | lr 2.1818e-05 | norm: 2.0796 | dt: 85211.94ms | tok/sec: 61527.53
2024-06-14 19:22:04,942 train.py step    26 | loss: 9.367515 | lr 2.2657e-05 | norm: 2.0776 | dt: 85231.18ms | tok/sec: 61513.64
2024-06-14 19:23:30,152 train.py step    27 | loss: 9.325733 | lr 2.3497e-05 | norm: 2.0615 | dt: 85210.30ms | tok/sec: 61528.71
2024-06-14 19:24:55,349 train.py step    28 | loss: 9.300944 | lr 2.4336e-05 | norm: 2.0325 | dt: 85196.66ms | tok/sec: 61538.56
2024-06-14 19:26:20,575 train.py step    29 | loss: 9.272890 | lr 2.5175e-05 | norm: 2.0409 | dt: 85225.54ms | tok/sec: 61517.71
2024-06-14 19:27:45,795 train.py step    30 | loss: 9.232911 | lr 2.6014e-05 | norm: 2.0027 | dt: 85219.30ms | tok/sec: 61522.21
2024-06-14 19:29:11,041 train.py step    31 | loss: 9.187886 | lr 2.6853e-05 | norm: 1.9039 | dt: 85245.06ms | tok/sec: 61503.62
2024-06-14 19:30:36,290 train.py step    32 | loss: 9.138777 | lr 2.7692e-05 | norm: 1.9416 | dt: 85249.30ms | tok/sec: 61500.57
2024-06-14 19:32:01,548 train.py step    33 | loss: 9.127251 | lr 2.8531e-05 | norm: 2.1719 | dt: 85257.68ms | tok/sec: 61494.52
2024-06-14 19:33:26,792 train.py step    34 | loss: 9.104737 | lr 2.9371e-05 | norm: 2.7192 | dt: 85243.53ms | tok/sec: 61504.73
2024-06-14 19:34:52,054 train.py step    35 | loss: 9.030972 | lr 3.0210e-05 | norm: 2.0017 | dt: 85260.91ms | tok/sec: 61492.19
2024-06-14 19:36:17,300 train.py step    36 | loss: 8.993124 | lr 3.1049e-05 | norm: 2.0122 | dt: 85245.93ms | tok/sec: 61503.00
2024-06-14 19:37:42,557 train.py step    37 | loss: 8.958265 | lr 3.1888e-05 | norm: 2.0426 | dt: 85256.70ms | tok/sec: 61495.23
2024-06-14 19:39:07,819 train.py step    38 | loss: 8.952807 | lr 3.2727e-05 | norm: 2.0384 | dt: 85261.47ms | tok/sec: 61491.79
2024-06-14 19:40:33,051 train.py step    39 | loss: 8.915381 | lr 3.3566e-05 | norm: 1.7750 | dt: 85232.21ms | tok/sec: 61512.89
2024-06-14 19:41:58,278 train.py step    40 | loss: 8.876918 | lr 3.4406e-05 | norm: 1.7511 | dt: 85226.28ms | tok/sec: 61517.18
2024-06-14 19:43:23,493 train.py step    41 | loss: 8.788633 | lr 3.5245e-05 | norm: 1.7582 | dt: 85214.74ms | tok/sec: 61525.51
2024-06-14 19:44:48,711 train.py step    42 | loss: 8.763712 | lr 3.6084e-05 | norm: 1.7536 | dt: 85217.25ms | tok/sec: 61523.69
2024-06-14 19:46:13,962 train.py step    43 | loss: 8.767531 | lr 3.6923e-05 | norm: 1.8030 | dt: 85250.85ms | tok/sec: 61499.44
2024-06-14 19:47:39,213 train.py step    44 | loss: 8.722264 | lr 3.7762e-05 | norm: 1.6927 | dt: 85249.95ms | tok/sec: 61500.09
2024-06-14 19:49:04,494 train.py step    45 | loss: 8.652908 | lr 3.8601e-05 | norm: 1.8869 | dt: 85280.92ms | tok/sec: 61477.76
2024-06-14 19:50:29,755 train.py step    46 | loss: 8.596125 | lr 3.9441e-05 | norm: 2.0022 | dt: 85260.73ms | tok/sec: 61492.32
2024-06-14 19:51:55,023 train.py step    47 | loss: 8.600193 | lr 4.0280e-05 | norm: 1.6966 | dt: 85267.07ms | tok/sec: 61487.75
2024-06-14 19:53:20,323 train.py step    48 | loss: 8.565346 | lr 4.1119e-05 | norm: 1.5948 | dt: 85299.26ms | tok/sec: 61464.54
2024-06-14 19:54:45,615 train.py step    49 | loss: 8.527426 | lr 4.1958e-05 | norm: 1.6071 | dt: 85292.22ms | tok/sec: 61469.61
2024-06-14 19:56:10,879 train.py step    50 | loss: 8.456175 | lr 4.2797e-05 | norm: 1.8901 | dt: 85262.93ms | tok/sec: 61490.73
2024-06-14 19:57:36,131 train.py step    51 | loss: 8.409191 | lr 4.3636e-05 | norm: 1.9587 | dt: 85251.45ms | tok/sec: 61499.01
2024-06-14 19:59:01,405 train.py step    52 | loss: 8.427672 | lr 4.4476e-05 | norm: 1.6900 | dt: 85273.31ms | tok/sec: 61483.25
2024-06-14 20:00:26,679 train.py step    53 | loss: 8.396482 | lr 4.5315e-05 | norm: 1.4970 | dt: 85274.08ms | tok/sec: 61482.69
2024-06-14 20:01:51,933 train.py step    54 | loss: 8.310197 | lr 4.6154e-05 | norm: 1.6401 | dt: 85253.42ms | tok/sec: 61497.59
2024-06-14 20:03:17,183 train.py step    55 | loss: 8.271050 | lr 4.6993e-05 | norm: 2.0277 | dt: 85249.26ms | tok/sec: 61500.59
2024-06-14 20:04:42,453 train.py step    56 | loss: 8.236318 | lr 4.7832e-05 | norm: 1.7083 | dt: 85269.41ms | tok/sec: 61486.06
2024-06-14 20:06:07,730 train.py step    57 | loss: 8.253788 | lr 4.8671e-05 | norm: 1.5275 | dt: 85277.27ms | tok/sec: 61480.39
2024-06-14 20:07:33,028 train.py step    58 | loss: 8.210570 | lr 4.9510e-05 | norm: 1.6516 | dt: 85297.28ms | tok/sec: 61465.97
2024-06-14 20:08:58,325 train.py step    59 | loss: 8.173309 | lr 5.0350e-05 | norm: 1.4783 | dt: 85296.26ms | tok/sec: 61466.70
2024-06-14 20:10:23,624 train.py step    60 | loss: 8.070406 | lr 5.1189e-05 | norm: 1.5840 | dt: 85298.43ms | tok/sec: 61465.14
2024-06-14 20:11:48,896 train.py step    61 | loss: 8.038307 | lr 5.2028e-05 | norm: 1.6880 | dt: 85271.12ms | tok/sec: 61484.83
2024-06-14 20:13:14,190 train.py step    62 | loss: 8.070415 | lr 5.2867e-05 | norm: 1.3968 | dt: 85293.34ms | tok/sec: 61468.81
2024-06-14 20:14:39,482 train.py step    63 | loss: 8.013773 | lr 5.3706e-05 | norm: 1.3940 | dt: 85290.39ms | tok/sec: 61470.93
2024-06-14 20:16:04,783 train.py step    64 | loss: 7.936138 | lr 5.4545e-05 | norm: 1.2716 | dt: 85300.99ms | tok/sec: 61463.30
2024-06-14 20:17:30,067 train.py step    65 | loss: 7.873574 | lr 5.5385e-05 | norm: 1.2860 | dt: 85283.21ms | tok/sec: 61476.11
2024-06-14 20:18:55,342 train.py step    66 | loss: 7.897825 | lr 5.6224e-05 | norm: 1.4618 | dt: 85273.63ms | tok/sec: 61483.02
2024-06-14 20:20:20,634 train.py step    67 | loss: 7.871428 | lr 5.7063e-05 | norm: 1.3794 | dt: 85291.37ms | tok/sec: 61470.23
2024-06-14 20:21:45,954 train.py step    68 | loss: 7.831064 | lr 5.7902e-05 | norm: 1.3170 | dt: 85319.49ms | tok/sec: 61449.97
2024-06-14 20:23:11,264 train.py step    69 | loss: 7.751576 | lr 5.8741e-05 | norm: 1.3923 | dt: 85310.08ms | tok/sec: 61456.75
2024-06-14 20:24:36,546 train.py step    70 | loss: 7.700388 | lr 5.9580e-05 | norm: 1.4796 | dt: 85281.05ms | tok/sec: 61477.67
2024-06-14 20:26:01,818 train.py step    71 | loss: 7.742808 | lr 6.0420e-05 | norm: 1.4885 | dt: 85271.48ms | tok/sec: 61484.57
2024-06-14 20:27:27,071 train.py step    72 | loss: 7.714042 | lr 6.1259e-05 | norm: 1.2610 | dt: 85251.99ms | tok/sec: 61498.62
2024-06-14 20:28:52,336 train.py step    73 | loss: 7.634274 | lr 6.2098e-05 | norm: 1.1782 | dt: 85264.93ms | tok/sec: 61489.29
2024-06-14 20:30:17,610 train.py step    74 | loss: 7.580970 | lr 6.2937e-05 | norm: 1.1732 | dt: 85272.77ms | tok/sec: 61483.64
2024-06-14 20:31:42,891 train.py step    75 | loss: 7.550667 | lr 6.3776e-05 | norm: 1.0060 | dt: 85280.90ms | tok/sec: 61477.78
2024-06-14 20:33:08,179 train.py step    76 | loss: 7.602336 | lr 6.4615e-05 | norm: 1.0829 | dt: 85286.78ms | tok/sec: 61473.54
2024-06-14 20:34:33,450 train.py step    77 | loss: 7.559403 | lr 6.5455e-05 | norm: 1.0810 | dt: 85270.56ms | tok/sec: 61485.23
2024-06-14 20:35:58,748 train.py step    78 | loss: 7.534180 | lr 6.6294e-05 | norm: 0.9884 | dt: 85297.47ms | tok/sec: 61465.84
2024-06-14 20:37:24,078 train.py step    79 | loss: 7.421958 | lr 6.7133e-05 | norm: 1.3694 | dt: 85327.97ms | tok/sec: 61443.86
2024-06-14 20:38:49,347 train.py step    80 | loss: 7.380296 | lr 6.7972e-05 | norm: 1.2024 | dt: 85269.44ms | tok/sec: 61486.04
2024-06-14 20:40:14,661 train.py step    81 | loss: 7.458567 | lr 6.8811e-05 | norm: 1.2682 | dt: 85312.88ms | tok/sec: 61454.73
2024-06-14 20:41:39,951 train.py step    82 | loss: 7.401507 | lr 6.9650e-05 | norm: 0.8409 | dt: 85289.37ms | tok/sec: 61471.67
2024-06-14 20:43:05,247 train.py step    83 | loss: 7.331117 | lr 7.0490e-05 | norm: 0.9940 | dt: 85295.04ms | tok/sec: 61467.58
2024-06-14 20:44:30,558 train.py step    84 | loss: 7.273290 | lr 7.1329e-05 | norm: 0.9954 | dt: 85310.31ms | tok/sec: 61456.58
2024-06-14 20:45:55,903 train.py step    85 | loss: 7.306946 | lr 7.2168e-05 | norm: 0.9755 | dt: 85344.95ms | tok/sec: 61431.64
2024-06-14 20:47:21,194 train.py step    86 | loss: 7.312944 | lr 7.3007e-05 | norm: 1.3808 | dt: 85290.36ms | tok/sec: 61470.95
2024-06-14 20:48:46,490 train.py step    87 | loss: 7.277702 | lr 7.3846e-05 | norm: 1.1318 | dt: 85295.53ms | tok/sec: 61467.23
2024-06-14 20:50:11,773 train.py step    88 | loss: 7.198107 | lr 7.4685e-05 | norm: 1.1710 | dt: 85281.96ms | tok/sec: 61477.01
2024-06-14 20:51:37,065 train.py step    89 | loss: 7.153032 | lr 7.5524e-05 | norm: 1.1767 | dt: 85291.14ms | tok/sec: 61470.40
2024-06-14 20:53:02,360 train.py step    90 | loss: 7.218159 | lr 7.6364e-05 | norm: 1.1834 | dt: 85295.27ms | tok/sec: 61467.42
2024-06-14 20:54:27,634 train.py step    91 | loss: 7.199877 | lr 7.7203e-05 | norm: 1.0462 | dt: 85273.80ms | tok/sec: 61482.89
2024-06-14 20:55:52,910 train.py step    92 | loss: 7.141743 | lr 7.8042e-05 | norm: 1.1413 | dt: 85275.43ms | tok/sec: 61481.72
2024-06-14 20:57:18,168 train.py step    93 | loss: 7.083163 | lr 7.8881e-05 | norm: 0.9134 | dt: 85257.10ms | tok/sec: 61494.93
2024-06-14 20:58:43,410 train.py step    94 | loss: 7.052769 | lr 7.9720e-05 | norm: 0.7275 | dt: 85241.29ms | tok/sec: 61506.34
2024-06-14 21:00:08,659 train.py step    95 | loss: 7.144699 | lr 8.0559e-05 | norm: 0.7880 | dt: 85248.92ms | tok/sec: 61500.84
2024-06-14 21:01:33,921 train.py step    96 | loss: 7.099512 | lr 8.1399e-05 | norm: 0.9297 | dt: 85261.40ms | tok/sec: 61491.84
2024-06-14 21:02:59,172 train.py step    97 | loss: 7.102264 | lr 8.2238e-05 | norm: 1.3672 | dt: 85251.21ms | tok/sec: 61499.18
2024-06-14 21:04:24,435 train.py step    98 | loss: 6.974095 | lr 8.3077e-05 | norm: 0.7347 | dt: 85262.55ms | tok/sec: 61491.01
2024-06-14 21:05:49,712 train.py step    99 | loss: 6.943526 | lr 8.3916e-05 | norm: 1.1214 | dt: 85275.94ms | tok/sec: 61481.35
2024-06-14 21:07:15,004 train.py step   100 | loss: 7.041035 | lr 8.4755e-05 | norm: 1.1259 | dt: 85292.45ms | tok/sec: 61469.45
2024-06-14 21:08:40,288 train.py step   101 | loss: 6.998638 | lr 8.5594e-05 | norm: 1.0075 | dt: 85283.17ms | tok/sec: 61476.14
2024-06-14 21:10:05,552 train.py step   102 | loss: 6.934744 | lr 8.6434e-05 | norm: 1.3595 | dt: 85263.27ms | tok/sec: 61490.49
2024-06-14 21:11:30,832 train.py step   103 | loss: 6.875820 | lr 8.7273e-05 | norm: 0.7980 | dt: 85279.77ms | tok/sec: 61478.59
2024-06-14 21:12:56,137 train.py step   104 | loss: 6.910787 | lr 8.8112e-05 | norm: 0.6820 | dt: 85304.76ms | tok/sec: 61460.58
2024-06-14 21:14:21,491 train.py step   105 | loss: 6.943030 | lr 8.8951e-05 | norm: 0.9474 | dt: 85353.14ms | tok/sec: 61425.74
2024-06-14 21:15:46,774 train.py step   106 | loss: 6.918482 | lr 8.9790e-05 | norm: 1.3297 | dt: 85282.88ms | tok/sec: 61476.35
2024-06-14 21:17:12,089 train.py step   107 | loss: 6.832400 | lr 9.0629e-05 | norm: 1.1104 | dt: 85315.07ms | tok/sec: 61453.16
2024-06-14 21:18:37,430 train.py step   108 | loss: 6.796094 | lr 9.1469e-05 | norm: 1.6196 | dt: 85340.30ms | tok/sec: 61434.99
2024-06-14 21:20:02,742 train.py step   109 | loss: 6.862863 | lr 9.2308e-05 | norm: 0.9978 | dt: 85311.51ms | tok/sec: 61455.72
2024-06-14 21:21:28,075 train.py step   110 | loss: 6.861989 | lr 9.3147e-05 | norm: 1.0822 | dt: 85332.75ms | tok/sec: 61440.42
2024-06-14 21:22:53,424 train.py step   111 | loss: 6.813254 | lr 9.3986e-05 | norm: 0.6539 | dt: 85348.43ms | tok/sec: 61429.13
2024-06-14 21:24:18,756 train.py step   112 | loss: 6.746370 | lr 9.4825e-05 | norm: 1.2375 | dt: 85331.23ms | tok/sec: 61441.51
2024-06-14 21:25:44,097 train.py step   113 | loss: 6.721141 | lr 9.5664e-05 | norm: 0.7898 | dt: 85341.51ms | tok/sec: 61434.11
2024-06-14 21:27:09,431 train.py step   114 | loss: 6.817166 | lr 9.6503e-05 | norm: 0.8997 | dt: 85333.10ms | tok/sec: 61440.17
2024-06-14 21:28:34,748 train.py step   115 | loss: 6.798426 | lr 9.7343e-05 | norm: 0.8437 | dt: 85316.35ms | tok/sec: 61452.23
2024-06-14 21:30:00,072 train.py step   116 | loss: 6.792643 | lr 9.8182e-05 | norm: 0.8935 | dt: 85324.01ms | tok/sec: 61446.72
2024-06-14 21:31:25,397 train.py step   117 | loss: 6.680743 | lr 9.9021e-05 | norm: 1.2947 | dt: 85324.62ms | tok/sec: 61446.28
2024-06-14 21:32:50,747 train.py step   118 | loss: 6.640459 | lr 9.9860e-05 | norm: 0.9174 | dt: 85350.00ms | tok/sec: 61428.01
2024-06-14 21:34:16,093 train.py step   119 | loss: 6.737506 | lr 1.0070e-04 | norm: 1.1562 | dt: 85345.55ms | tok/sec: 61431.20
2024-06-14 21:35:41,446 train.py step   120 | loss: 6.712969 | lr 1.0154e-04 | norm: 1.0379 | dt: 85351.88ms | tok/sec: 61426.65
2024-06-14 21:37:06,806 train.py step   121 | loss: 6.661642 | lr 1.0238e-04 | norm: 1.3215 | dt: 85359.84ms | tok/sec: 61420.92
2024-06-14 21:38:32,166 train.py step   122 | loss: 6.604164 | lr 1.0322e-04 | norm: 1.1584 | dt: 85360.02ms | tok/sec: 61420.79
2024-06-14 21:39:57,512 train.py step   123 | loss: 6.631617 | lr 1.0406e-04 | norm: 1.1320 | dt: 85345.33ms | tok/sec: 61431.36
2024-06-14 21:41:22,870 train.py step   124 | loss: 6.672781 | lr 1.0490e-04 | norm: 0.8455 | dt: 85358.06ms | tok/sec: 61422.20
2024-06-14 21:42:48,206 train.py step   125 | loss: 6.649269 | lr 1.0573e-04 | norm: 0.9184 | dt: 85335.05ms | tok/sec: 61438.76
2024-06-14 21:44:13,563 train.py step   126 | loss: 6.576344 | lr 1.0657e-04 | norm: 0.7628 | dt: 85356.76ms | tok/sec: 61423.14
2024-06-14 21:45:38,916 train.py step   127 | loss: 6.534074 | lr 1.0741e-04 | norm: 0.7083 | dt: 85352.33ms | tok/sec: 61426.33
2024-06-14 21:47:04,249 train.py step   128 | loss: 6.604476 | lr 1.0825e-04 | norm: 0.7572 | dt: 85332.64ms | tok/sec: 61440.50
2024-06-14 21:48:29,602 train.py step   129 | loss: 6.610771 | lr 1.0909e-04 | norm: 0.7036 | dt: 85352.78ms | tok/sec: 61426.00
2024-06-14 21:49:54,962 train.py step   130 | loss: 6.577657 | lr 1.0993e-04 | norm: 0.6715 | dt: 85359.70ms | tok/sec: 61421.02
2024-06-14 21:51:20,323 train.py step   131 | loss: 6.502142 | lr 1.1077e-04 | norm: 0.6690 | dt: 85360.66ms | tok/sec: 61420.33
2024-06-14 21:52:45,681 train.py step   132 | loss: 6.474443 | lr 1.1161e-04 | norm: 0.7834 | dt: 85357.08ms | tok/sec: 61422.91
2024-06-14 21:54:11,029 train.py step   133 | loss: 6.585062 | lr 1.1245e-04 | norm: 1.2532 | dt: 85347.56ms | tok/sec: 61429.76
2024-06-14 21:55:36,373 train.py step   134 | loss: 6.579884 | lr 1.1329e-04 | norm: 1.2902 | dt: 85344.23ms | tok/sec: 61432.16
2024-06-14 21:57:01,728 train.py step   135 | loss: 6.571602 | lr 1.1413e-04 | norm: 1.0685 | dt: 85354.29ms | tok/sec: 61424.92
2024-06-14 21:58:27,080 train.py step   136 | loss: 6.459738 | lr 1.1497e-04 | norm: 1.0627 | dt: 85351.25ms | tok/sec: 61427.10
2024-06-14 21:59:52,448 train.py step   137 | loss: 6.417329 | lr 1.1580e-04 | norm: 1.0499 | dt: 85368.21ms | tok/sec: 61414.90
2024-06-14 22:01:17,796 train.py step   138 | loss: 6.525698 | lr 1.1664e-04 | norm: 1.5970 | dt: 85347.31ms | tok/sec: 61429.94
2024-06-14 22:02:43,146 train.py step   139 | loss: 6.504731 | lr 1.1748e-04 | norm: 0.8838 | dt: 85349.32ms | tok/sec: 61428.49
2024-06-14 22:04:08,504 train.py step   140 | loss: 6.463291 | lr 1.1832e-04 | norm: 1.4086 | dt: 85358.04ms | tok/sec: 61422.22
2024-06-14 22:05:33,857 train.py step   141 | loss: 6.404848 | lr 1.1916e-04 | norm: 0.8150 | dt: 85352.71ms | tok/sec: 61426.05
2024-06-14 22:06:59,210 train.py step   142 | loss: 6.411159 | lr 1.2000e-04 | norm: 0.8502 | dt: 85352.46ms | tok/sec: 61426.23
2024-06-14 22:08:24,556 train.py step   143 | loss: 6.485894 | lr 1.2084e-04 | norm: 1.0586 | dt: 85345.92ms | tok/sec: 61430.94
2024-06-14 22:09:49,897 train.py step   144 | loss: 6.462071 | lr 1.2168e-04 | norm: 1.1455 | dt: 85340.24ms | tok/sec: 61435.03
2024-06-14 22:11:15,249 train.py step   145 | loss: 6.386513 | lr 1.2252e-04 | norm: 0.8003 | dt: 85351.33ms | tok/sec: 61427.05
2024-06-14 22:12:40,610 train.py step   146 | loss: 6.351464 | lr 1.2336e-04 | norm: 1.0182 | dt: 85360.43ms | tok/sec: 61420.50
2024-06-14 22:14:05,969 train.py step   147 | loss: 6.421043 | lr 1.2420e-04 | norm: 1.4506 | dt: 85359.38ms | tok/sec: 61421.25
2024-06-14 22:15:31,335 train.py step   148 | loss: 6.436955 | lr 1.2503e-04 | norm: 0.8711 | dt: 85365.05ms | tok/sec: 61417.17
2024-06-14 22:16:56,661 train.py step   149 | loss: 6.407654 | lr 1.2587e-04 | norm: 1.2536 | dt: 85325.56ms | tok/sec: 61445.60
2024-06-14 22:18:22,001 train.py step   150 | loss: 6.332970 | lr 1.2671e-04 | norm: 1.0958 | dt: 85340.14ms | tok/sec: 61435.10
2024-06-14 22:19:47,356 train.py step   151 | loss: 6.307431 | lr 1.2755e-04 | norm: 1.4925 | dt: 85354.00ms | tok/sec: 61425.12
2024-06-14 22:21:12,716 train.py step   152 | loss: 6.418346 | lr 1.2839e-04 | norm: 1.1104 | dt: 85359.69ms | tok/sec: 61421.03
2024-06-14 22:22:38,074 train.py step   153 | loss: 6.421939 | lr 1.2923e-04 | norm: 1.1832 | dt: 85357.93ms | tok/sec: 61422.29
2024-06-14 22:24:03,428 train.py step   154 | loss: 6.400836 | lr 1.3007e-04 | norm: 1.0358 | dt: 85353.06ms | tok/sec: 61425.80
2024-06-14 22:25:28,767 train.py step   155 | loss: 6.312217 | lr 1.3091e-04 | norm: 1.2019 | dt: 85338.77ms | tok/sec: 61436.09
2024-06-14 22:26:54,127 train.py step   156 | loss: 6.255562 | lr 1.3175e-04 | norm: 0.8163 | dt: 85360.23ms | tok/sec: 61420.64
2024-06-14 22:28:19,481 train.py step   157 | loss: 6.349360 | lr 1.3259e-04 | norm: 0.8195 | dt: 85353.45ms | tok/sec: 61425.52
2024-06-14 22:29:44,835 train.py step   158 | loss: 6.362104 | lr 1.3343e-04 | norm: 1.0956 | dt: 85353.03ms | tok/sec: 61425.82
2024-06-14 22:31:10,160 train.py step   159 | loss: 6.314852 | lr 1.3427e-04 | norm: 0.9918 | dt: 85325.03ms | tok/sec: 61445.98
2024-06-14 22:32:35,513 train.py step   160 | loss: 6.271545 | lr 1.3510e-04 | norm: 1.6783 | dt: 85352.68ms | tok/sec: 61426.07
2024-06-14 22:34:00,840 train.py step   161 | loss: 6.259623 | lr 1.3594e-04 | norm: 1.0302 | dt: 85326.12ms | tok/sec: 61445.20
2024-06-14 22:35:26,183 train.py step   162 | loss: 6.350143 | lr 1.3678e-04 | norm: 1.3375 | dt: 85342.91ms | tok/sec: 61433.11
2024-06-14 22:36:51,553 train.py step   163 | loss: 6.314438 | lr 1.3762e-04 | norm: 1.0062 | dt: 85369.67ms | tok/sec: 61413.85
2024-06-14 22:38:16,906 train.py step   164 | loss: 6.262760 | lr 1.3846e-04 | norm: 1.3444 | dt: 85352.33ms | tok/sec: 61426.32
2024-06-14 22:39:42,248 train.py step   165 | loss: 6.230573 | lr 1.3930e-04 | norm: 1.3006 | dt: 85341.71ms | tok/sec: 61433.97
2024-06-14 22:41:07,584 train.py step   166 | loss: 6.264260 | lr 1.4014e-04 | norm: 0.8804 | dt: 85336.11ms | tok/sec: 61438.00
2024-06-14 22:42:32,912 train.py step   167 | loss: 6.323259 | lr 1.4098e-04 | norm: 1.4204 | dt: 85327.62ms | tok/sec: 61444.12
2024-06-14 22:43:58,265 train.py step   168 | loss: 6.268292 | lr 1.4182e-04 | norm: 0.8074 | dt: 85352.45ms | tok/sec: 61426.24
2024-06-14 22:45:23,619 train.py step   169 | loss: 6.204511 | lr 1.4266e-04 | norm: 0.8136 | dt: 85353.31ms | tok/sec: 61425.62
2024-06-14 22:46:48,944 train.py step   170 | loss: 6.171638 | lr 1.4350e-04 | norm: 0.9367 | dt: 85325.08ms | tok/sec: 61445.94
2024-06-14 22:48:14,297 train.py step   171 | loss: 6.285835 | lr 1.4434e-04 | norm: 1.2219 | dt: 85352.70ms | tok/sec: 61426.06
2024-06-14 22:49:39,631 train.py step   172 | loss: 6.292175 | lr 1.4517e-04 | norm: 1.0714 | dt: 85333.56ms | tok/sec: 61439.84
2024-06-14 22:51:04,944 train.py step   173 | loss: 6.267759 | lr 1.4601e-04 | norm: 0.8137 | dt: 85312.08ms | tok/sec: 61455.31
2024-06-14 22:52:30,256 train.py step   174 | loss: 6.178286 | lr 1.4685e-04 | norm: 0.8068 | dt: 85312.13ms | tok/sec: 61455.27
2024-06-14 22:53:55,541 train.py step   175 | loss: 6.134558 | lr 1.4769e-04 | norm: 1.1864 | dt: 85283.94ms | tok/sec: 61475.58
2024-06-14 22:55:20,869 train.py step   176 | loss: 6.228345 | lr 1.4853e-04 | norm: 1.0202 | dt: 85327.88ms | tok/sec: 61443.93
2024-06-14 22:56:46,228 train.py step   177 | loss: 6.237981 | lr 1.4937e-04 | norm: 1.0133 | dt: 85358.97ms | tok/sec: 61421.55
2024-06-14 22:58:11,603 train.py step   178 | loss: 6.194269 | lr 1.5021e-04 | norm: 1.0761 | dt: 85373.86ms | tok/sec: 61410.83
2024-06-14 22:59:36,973 train.py step   179 | loss: 6.146863 | lr 1.5105e-04 | norm: 1.1025 | dt: 85369.57ms | tok/sec: 61413.92
2024-06-14 23:01:02,334 train.py step   180 | loss: 6.120279 | lr 1.5189e-04 | norm: 1.0243 | dt: 85361.27ms | tok/sec: 61419.90
2024-06-14 23:02:27,709 train.py step   181 | loss: 6.232754 | lr 1.5273e-04 | norm: 1.2564 | dt: 85374.22ms | tok/sec: 61410.57
2024-06-14 23:03:53,080 train.py step   182 | loss: 6.189685 | lr 1.5357e-04 | norm: 0.9500 | dt: 85370.46ms | tok/sec: 61413.28
2024-06-14 23:05:18,453 train.py step   183 | loss: 6.149254 | lr 1.5441e-04 | norm: 0.9259 | dt: 85372.16ms | tok/sec: 61412.06
2024-06-14 23:06:43,821 train.py step   184 | loss: 6.100247 | lr 1.5524e-04 | norm: 0.7566 | dt: 85367.04ms | tok/sec: 61415.74
2024-06-14 23:08:09,172 train.py step   185 | loss: 6.133522 | lr 1.5608e-04 | norm: 0.9781 | dt: 85350.79ms | tok/sec: 61427.43
2024-06-14 23:09:34,540 train.py step   186 | loss: 6.194423 | lr 1.5692e-04 | norm: 1.4865 | dt: 85367.49ms | tok/sec: 61415.42
2024-06-14 23:10:59,915 train.py step   187 | loss: 6.172939 | lr 1.5776e-04 | norm: 1.6674 | dt: 85374.12ms | tok/sec: 61410.65
2024-06-14 23:12:25,286 train.py step   188 | loss: 6.099761 | lr 1.5860e-04 | norm: 1.2610 | dt: 85371.04ms | tok/sec: 61412.86
2024-06-14 23:13:50,682 train.py step   189 | loss: 6.050883 | lr 1.5944e-04 | norm: 0.9441 | dt: 85395.28ms | tok/sec: 61395.43
2024-06-14 23:15:16,119 train.py step   190 | loss: 6.162341 | lr 1.6028e-04 | norm: 0.9581 | dt: 85436.01ms | tok/sec: 61366.16
2024-06-14 23:16:41,520 train.py step   191 | loss: 6.185658 | lr 1.6112e-04 | norm: 1.4338 | dt: 85400.12ms | tok/sec: 61391.95
2024-06-14 23:18:06,912 train.py step   192 | loss: 6.161112 | lr 1.6196e-04 | norm: 0.9146 | dt: 85391.49ms | tok/sec: 61398.16
2024-06-14 23:19:32,292 train.py step   193 | loss: 6.070558 | lr 1.6280e-04 | norm: 1.0449 | dt: 85379.54ms | tok/sec: 61406.75
2024-06-14 23:20:57,693 train.py step   194 | loss: 6.032034 | lr 1.6364e-04 | norm: 1.1066 | dt: 85401.20ms | tok/sec: 61391.18
2024-06-14 23:22:23,077 train.py step   195 | loss: 6.116506 | lr 1.6448e-04 | norm: 1.5080 | dt: 85383.03ms | tok/sec: 61404.24
2024-06-14 23:23:48,484 train.py step   196 | loss: 6.133321 | lr 1.6531e-04 | norm: 1.3353 | dt: 85406.43ms | tok/sec: 61387.42
2024-06-14 23:25:13,855 train.py step   197 | loss: 6.102542 | lr 1.6615e-04 | norm: 1.2178 | dt: 85371.06ms | tok/sec: 61412.85
2024-06-14 23:26:39,242 train.py step   198 | loss: 6.037466 | lr 1.6699e-04 | norm: 0.9113 | dt: 85385.94ms | tok/sec: 61402.15
2024-06-14 23:28:04,630 train.py step   199 | loss: 6.005633 | lr 1.6783e-04 | norm: 1.1273 | dt: 85387.85ms | tok/sec: 61400.78
2024-06-14 23:29:30,028 train.py step   200 | loss: 6.132835 | lr 1.6867e-04 | norm: 1.2787 | dt: 85397.56ms | tok/sec: 61393.79
2024-06-14 23:30:55,393 train.py step   201 | loss: 6.079334 | lr 1.6951e-04 | norm: 1.0466 | dt: 85364.39ms | tok/sec: 61417.65
2024-06-14 23:32:20,770 train.py step   202 | loss: 6.042086 | lr 1.7035e-04 | norm: 1.0406 | dt: 85376.34ms | tok/sec: 61409.05
2024-06-14 23:33:46,126 train.py step   203 | loss: 6.006063 | lr 1.7119e-04 | norm: 1.0661 | dt: 85355.44ms | tok/sec: 61424.09
2024-06-14 23:35:11,516 train.py step   204 | loss: 6.025871 | lr 1.7203e-04 | norm: 1.1817 | dt: 85389.09ms | tok/sec: 61399.88
2024-06-14 23:36:36,891 train.py step   205 | loss: 6.086161 | lr 1.7287e-04 | norm: 0.9752 | dt: 85374.09ms | tok/sec: 61410.67
2024-06-14 23:38:02,278 train.py step   206 | loss: 6.069575 | lr 1.7371e-04 | norm: 1.0806 | dt: 85387.22ms | tok/sec: 61401.23
2024-06-14 23:39:27,658 train.py step   207 | loss: 5.988317 | lr 1.7455e-04 | norm: 0.9299 | dt: 85379.15ms | tok/sec: 61407.03
2024-06-14 23:40:53,074 train.py step   208 | loss: 5.952210 | lr 1.7538e-04 | norm: 1.1758 | dt: 85415.37ms | tok/sec: 61380.99
2024-06-14 23:42:18,481 train.py step   209 | loss: 6.052155 | lr 1.7622e-04 | norm: 1.1465 | dt: 85406.38ms | tok/sec: 61387.45
2024-06-14 23:43:43,836 train.py step   210 | loss: 6.078594 | lr 1.7706e-04 | norm: 1.0296 | dt: 85354.41ms | tok/sec: 61424.83
2024-06-14 23:45:09,233 train.py step   211 | loss: 6.061140 | lr 1.7790e-04 | norm: 1.2618 | dt: 85396.94ms | tok/sec: 61394.24
2024-06-14 23:46:34,601 train.py step   212 | loss: 5.973614 | lr 1.7874e-04 | norm: 1.1933 | dt: 85367.64ms | tok/sec: 61415.31
2024-06-14 23:47:59,969 train.py step   213 | loss: 5.942262 | lr 1.7958e-04 | norm: 1.3328 | dt: 85367.36ms | tok/sec: 61415.51
2024-06-14 23:49:25,324 train.py step   214 | loss: 5.993882 | lr 1.8042e-04 | norm: 1.0225 | dt: 85354.93ms | tok/sec: 61424.45
2024-06-14 23:50:50,698 train.py step   215 | loss: 6.037973 | lr 1.8126e-04 | norm: 1.1612 | dt: 85373.06ms | tok/sec: 61411.41
2024-06-14 23:52:16,069 train.py step   216 | loss: 5.996197 | lr 1.8210e-04 | norm: 1.0176 | dt: 85371.31ms | tok/sec: 61412.67
2024-06-14 23:53:41,433 train.py step   217 | loss: 5.953665 | lr 1.8294e-04 | norm: 1.2398 | dt: 85362.86ms | tok/sec: 61418.75
2024-06-14 23:55:06,806 train.py step   218 | loss: 5.898865 | lr 1.8378e-04 | norm: 0.9754 | dt: 85372.92ms | tok/sec: 61411.51
2024-06-14 23:56:32,197 train.py step   219 | loss: 6.021761 | lr 1.8462e-04 | norm: 0.8375 | dt: 85390.27ms | tok/sec: 61399.03
2024-06-14 23:57:57,605 train.py step   220 | loss: 5.980604 | lr 1.8545e-04 | norm: 0.8603 | dt: 85408.10ms | tok/sec: 61386.22
2024-06-14 23:59:23,043 train.py step   221 | loss: 5.941072 | lr 1.8629e-04 | norm: 0.7547 | dt: 85436.91ms | tok/sec: 61365.52
2024-06-15 00:00:48,465 train.py step   222 | loss: 5.903917 | lr 1.8713e-04 | norm: 1.0381 | dt: 85422.26ms | tok/sec: 61376.04
2024-06-15 00:02:13,882 train.py step   223 | loss: 5.934097 | lr 1.8797e-04 | norm: 1.7748 | dt: 85416.31ms | tok/sec: 61380.32
2024-06-15 00:03:39,320 train.py step   224 | loss: 5.991249 | lr 1.8881e-04 | norm: 0.8256 | dt: 85437.55ms | tok/sec: 61365.06
2024-06-15 00:05:04,751 train.py step   225 | loss: 5.978025 | lr 1.8965e-04 | norm: 1.4236 | dt: 85430.72ms | tok/sec: 61369.96
2024-06-15 00:06:30,167 train.py step   226 | loss: 5.902691 | lr 1.9049e-04 | norm: 1.1305 | dt: 85414.84ms | tok/sec: 61381.37
2024-06-15 00:07:55,591 train.py step   227 | loss: 5.856437 | lr 1.9133e-04 | norm: 0.8866 | dt: 85424.13ms | tok/sec: 61374.70
2024-06-15 00:09:21,005 train.py step   228 | loss: 5.949136 | lr 1.9217e-04 | norm: 1.4783 | dt: 85413.23ms | tok/sec: 61382.52
2024-06-15 00:10:46,436 train.py step   229 | loss: 6.004235 | lr 1.9301e-04 | norm: 1.5087 | dt: 85430.39ms | tok/sec: 61370.20
2024-06-15 00:12:11,863 train.py step   230 | loss: 5.960389 | lr 1.9385e-04 | norm: 0.9196 | dt: 85427.14ms | tok/sec: 61372.53
2024-06-15 00:13:37,299 train.py step   231 | loss: 5.876810 | lr 1.9469e-04 | norm: 0.9483 | dt: 85435.19ms | tok/sec: 61366.75
2024-06-15 00:15:02,743 train.py step   232 | loss: 5.851988 | lr 1.9552e-04 | norm: 1.2629 | dt: 85443.38ms | tok/sec: 61360.87
2024-06-15 00:16:28,170 train.py step   233 | loss: 5.890244 | lr 1.9636e-04 | norm: 0.9997 | dt: 85426.59ms | tok/sec: 61372.93
2024-06-15 00:17:53,588 train.py step   234 | loss: 5.941927 | lr 1.9720e-04 | norm: 1.0172 | dt: 85417.46ms | tok/sec: 61379.49
2024-06-15 00:19:19,000 train.py step   235 | loss: 5.905228 | lr 1.9804e-04 | norm: 0.9842 | dt: 85412.41ms | tok/sec: 61383.12
2024-06-15 00:20:44,395 train.py step   236 | loss: 5.864649 | lr 1.9888e-04 | norm: 1.3591 | dt: 85394.29ms | tok/sec: 61396.14
2024-06-15 00:22:09,827 train.py step   237 | loss: 5.810302 | lr 1.9972e-04 | norm: 1.0882 | dt: 85431.64ms | tok/sec: 61369.30
2024-06-15 00:23:35,267 train.py step   238 | loss: 5.923382 | lr 2.0056e-04 | norm: 1.1033 | dt: 85439.24ms | tok/sec: 61363.84
2024-06-15 00:25:00,672 train.py step   239 | loss: 5.897531 | lr 2.0140e-04 | norm: 1.2810 | dt: 85405.09ms | tok/sec: 61388.38
2024-06-15 00:26:26,057 train.py step   240 | loss: 5.856893 | lr 2.0224e-04 | norm: 0.9631 | dt: 85384.46ms | tok/sec: 61403.21
2024-06-15 00:27:51,461 train.py step   241 | loss: 5.812134 | lr 2.0308e-04 | norm: 0.9763 | dt: 85403.01ms | tok/sec: 61389.87
2024-06-15 00:29:16,855 train.py step   242 | loss: 5.822579 | lr 2.0392e-04 | norm: 1.2796 | dt: 85394.30ms | tok/sec: 61396.14
2024-06-15 00:30:42,284 train.py step   243 | loss: 5.899042 | lr 2.0476e-04 | norm: 0.8283 | dt: 85427.85ms | tok/sec: 61372.02
2024-06-15 00:32:07,732 train.py step   244 | loss: 5.880824 | lr 2.0559e-04 | norm: 1.0972 | dt: 85447.67ms | tok/sec: 61357.79
2024-06-15 00:33:33,177 train.py step   245 | loss: 5.811286 | lr 2.0643e-04 | norm: 1.1066 | dt: 85444.48ms | tok/sec: 61360.08
2024-06-15 00:34:58,597 train.py step   246 | loss: 5.775948 | lr 2.0727e-04 | norm: 1.2311 | dt: 85419.98ms | tok/sec: 61377.68
2024-06-15 00:36:24,010 train.py step   247 | loss: 5.842988 | lr 2.0811e-04 | norm: 0.9925 | dt: 85412.88ms | tok/sec: 61382.78
2024-06-15 00:37:49,429 train.py step   248 | loss: 5.905881 | lr 2.0895e-04 | norm: 1.1312 | dt: 85418.08ms | tok/sec: 61379.04
2024-06-15 00:39:14,856 train.py step   249 | loss: 5.867902 | lr 2.0979e-04 | norm: 1.2169 | dt: 85427.01ms | tok/sec: 61372.63
2024-06-15 00:39:16,984 train.py validation loss: 5.8727
2024-06-15 00:40:43,489 train.py step   250 | loss: 5.793170 | lr 2.1063e-04 | norm: 1.1338 | dt: 88632.35ms | tok/sec: 59153.12
2024-06-15 00:42:08,895 train.py step   251 | loss: 5.757483 | lr 2.1147e-04 | norm: 0.9677 | dt: 85405.42ms | tok/sec: 61388.14
2024-06-15 00:43:34,343 train.py step   252 | loss: 5.788282 | lr 2.1231e-04 | norm: 0.9406 | dt: 85447.77ms | tok/sec: 61357.72
2024-06-15 00:44:59,771 train.py step   253 | loss: 5.859627 | lr 2.1315e-04 | norm: 1.1646 | dt: 85427.32ms | tok/sec: 61372.40
2024-06-15 00:46:25,169 train.py step   254 | loss: 5.818544 | lr 2.1399e-04 | norm: 1.0246 | dt: 85397.34ms | tok/sec: 61393.95
2024-06-15 00:47:50,570 train.py step   255 | loss: 5.772171 | lr 2.1483e-04 | norm: 1.0725 | dt: 85400.94ms | tok/sec: 61391.36
2024-06-15 00:49:15,967 train.py step   256 | loss: 5.728577 | lr 2.1566e-04 | norm: 1.3264 | dt: 85396.61ms | tok/sec: 61394.47
2024-06-15 00:50:41,373 train.py step   257 | loss: 5.825152 | lr 2.1650e-04 | norm: 0.9281 | dt: 85405.34ms | tok/sec: 61388.20
2024-06-15 00:52:06,805 train.py step   258 | loss: 5.816020 | lr 2.1734e-04 | norm: 1.2709 | dt: 85431.37ms | tok/sec: 61369.49
2024-06-15 00:53:32,214 train.py step   259 | loss: 5.773928 | lr 2.1818e-04 | norm: 0.8479 | dt: 85408.56ms | tok/sec: 61385.88
2024-06-15 00:54:57,630 train.py step   260 | loss: 5.730053 | lr 2.1902e-04 | norm: 1.0179 | dt: 85415.33ms | tok/sec: 61381.02
2024-06-15 00:56:23,033 train.py step   261 | loss: 5.723118 | lr 2.1986e-04 | norm: 1.0676 | dt: 85402.92ms | tok/sec: 61389.94
2024-06-15 00:57:48,457 train.py step   262 | loss: 5.829847 | lr 2.2070e-04 | norm: 1.1666 | dt: 85423.23ms | tok/sec: 61375.34
2024-06-15 00:59:13,884 train.py step   263 | loss: 5.792052 | lr 2.2154e-04 | norm: 1.2196 | dt: 85426.60ms | tok/sec: 61372.92
2024-06-15 01:00:39,313 train.py step   264 | loss: 5.746277 | lr 2.2238e-04 | norm: 1.4643 | dt: 85428.98ms | tok/sec: 61371.21
2024-06-15 01:02:04,757 train.py step   265 | loss: 5.685862 | lr 2.2322e-04 | norm: 0.9970 | dt: 85442.95ms | tok/sec: 61361.18
2024-06-15 01:03:30,210 train.py step   266 | loss: 5.750841 | lr 2.2406e-04 | norm: 1.0338 | dt: 85453.50ms | tok/sec: 61353.60
2024-06-15 01:04:55,665 train.py step   267 | loss: 5.817646 | lr 2.2490e-04 | norm: 1.0905 | dt: 85454.53ms | tok/sec: 61352.87
2024-06-15 01:06:21,102 train.py step   268 | loss: 5.784352 | lr 2.2573e-04 | norm: 1.1076 | dt: 85436.09ms | tok/sec: 61366.10
2024-06-15 01:07:46,543 train.py step   269 | loss: 5.705576 | lr 2.2657e-04 | norm: 0.7462 | dt: 85440.29ms | tok/sec: 61363.09
2024-06-15 01:09:11,984 train.py step   270 | loss: 5.675879 | lr 2.2741e-04 | norm: 0.8824 | dt: 85441.04ms | tok/sec: 61362.55
2024-06-15 01:10:37,421 train.py step   271 | loss: 5.694204 | lr 2.2825e-04 | norm: 1.0212 | dt: 85436.79ms | tok/sec: 61365.60
2024-06-15 01:12:02,841 train.py step   272 | loss: 5.764726 | lr 2.2909e-04 | norm: 0.7968 | dt: 85419.50ms | tok/sec: 61378.02
2024-06-15 01:13:28,255 train.py step   273 | loss: 5.740364 | lr 2.2993e-04 | norm: 1.0124 | dt: 85413.43ms | tok/sec: 61382.39
2024-06-15 01:14:53,682 train.py step   274 | loss: 5.692022 | lr 2.3077e-04 | norm: 1.3281 | dt: 85426.12ms | tok/sec: 61373.26
2024-06-15 01:16:19,106 train.py step   275 | loss: 5.654080 | lr 2.3161e-04 | norm: 1.3978 | dt: 85423.77ms | tok/sec: 61374.96
2024-06-15 01:17:44,531 train.py step   276 | loss: 5.731161 | lr 2.3245e-04 | norm: 1.0252 | dt: 85424.46ms | tok/sec: 61374.46
2024-06-15 01:19:09,986 train.py step   277 | loss: 5.740468 | lr 2.3329e-04 | norm: 1.2975 | dt: 85454.40ms | tok/sec: 61352.95
2024-06-15 01:20:35,409 train.py step   278 | loss: 5.706266 | lr 2.3413e-04 | norm: 1.3124 | dt: 85422.52ms | tok/sec: 61375.85
2024-06-15 01:22:00,838 train.py step   279 | loss: 5.655239 | lr 2.3497e-04 | norm: 1.2647 | dt: 85429.26ms | tok/sec: 61371.01
2024-06-15 01:23:26,278 train.py step   280 | loss: 5.634132 | lr 2.3580e-04 | norm: 1.0537 | dt: 85439.30ms | tok/sec: 61363.80
2024-06-15 01:24:51,737 train.py step   281 | loss: 5.752036 | lr 2.3664e-04 | norm: 1.0327 | dt: 85458.73ms | tok/sec: 61349.85
2024-06-15 01:26:17,208 train.py step   282 | loss: 5.710914 | lr 2.3748e-04 | norm: 0.8600 | dt: 85470.06ms | tok/sec: 61341.72
2024-06-15 01:27:42,660 train.py step   283 | loss: 5.655680 | lr 2.3832e-04 | norm: 0.9863 | dt: 85451.94ms | tok/sec: 61354.72
2024-06-15 01:29:08,106 train.py step   284 | loss: 5.614707 | lr 2.3916e-04 | norm: 1.2311 | dt: 85446.00ms | tok/sec: 61358.99
2024-06-15 01:30:33,557 train.py step   285 | loss: 5.649313 | lr 2.4000e-04 | norm: 0.8354 | dt: 85449.64ms | tok/sec: 61356.37
2024-06-15 01:31:59,024 train.py step   286 | loss: 5.738291 | lr 2.4084e-04 | norm: 0.9514 | dt: 85466.88ms | tok/sec: 61344.00
2024-06-15 01:33:24,493 train.py step   287 | loss: 5.722024 | lr 2.4168e-04 | norm: 1.2185 | dt: 85468.95ms | tok/sec: 61342.51
2024-06-15 01:34:49,949 train.py step   288 | loss: 5.618732 | lr 2.4252e-04 | norm: 0.7671 | dt: 85455.16ms | tok/sec: 61352.41
2024-06-15 01:36:15,424 train.py step   289 | loss: 5.595423 | lr 2.4336e-04 | norm: 0.8636 | dt: 85474.45ms | tok/sec: 61338.57
2024-06-15 01:37:40,901 train.py step   290 | loss: 5.608848 | lr 2.4420e-04 | norm: 1.0832 | dt: 85477.02ms | tok/sec: 61336.72
2024-06-15 01:39:06,377 train.py step   291 | loss: 5.699819 | lr 2.4503e-04 | norm: 1.0969 | dt: 85474.89ms | tok/sec: 61338.25
2024-06-15 01:40:31,839 train.py step   292 | loss: 5.670077 | lr 2.4587e-04 | norm: 1.0183 | dt: 85462.24ms | tok/sec: 61347.33
2024-06-15 01:41:57,271 train.py step   293 | loss: 5.611248 | lr 2.4671e-04 | norm: 1.0528 | dt: 85431.68ms | tok/sec: 61369.27
2024-06-15 01:43:22,708 train.py step   294 | loss: 5.572860 | lr 2.4755e-04 | norm: 1.0645 | dt: 85436.26ms | tok/sec: 61365.98
2024-06-15 01:44:48,125 train.py step   295 | loss: 5.644319 | lr 2.4839e-04 | norm: 0.9383 | dt: 85416.35ms | tok/sec: 61380.28
2024-06-15 01:46:13,567 train.py step   296 | loss: 5.662298 | lr 2.4923e-04 | norm: 1.0340 | dt: 85442.00ms | tok/sec: 61361.86
2024-06-15 01:47:39,020 train.py step   297 | loss: 5.622267 | lr 2.5007e-04 | norm: 1.0226 | dt: 85452.71ms | tok/sec: 61354.17
2024-06-15 01:49:04,480 train.py step   298 | loss: 5.582136 | lr 2.5091e-04 | norm: 1.2004 | dt: 85458.77ms | tok/sec: 61349.82
2024-06-15 01:50:29,948 train.py step   299 | loss: 5.547699 | lr 2.5175e-04 | norm: 1.1767 | dt: 85468.21ms | tok/sec: 61343.04
2024-06-15 01:51:55,415 train.py step   300 | loss: 5.669892 | lr 2.5259e-04 | norm: 1.0318 | dt: 85466.62ms | tok/sec: 61344.18
2024-06-15 01:53:20,897 train.py step   301 | loss: 5.649297 | lr 2.5343e-04 | norm: 1.5252 | dt: 85481.55ms | tok/sec: 61333.47
2024-06-15 01:54:46,388 train.py step   302 | loss: 5.587524 | lr 2.5427e-04 | norm: 1.0101 | dt: 85490.17ms | tok/sec: 61327.29
2024-06-15 01:56:11,876 train.py step   303 | loss: 5.544393 | lr 2.5510e-04 | norm: 1.1916 | dt: 85487.87ms | tok/sec: 61328.93
2024-06-15 01:57:37,379 train.py step   304 | loss: 5.574697 | lr 2.5594e-04 | norm: 1.1025 | dt: 85502.69ms | tok/sec: 61318.30
2024-06-15 01:59:02,874 train.py step   305 | loss: 5.665682 | lr 2.5678e-04 | norm: 0.9880 | dt: 85494.21ms | tok/sec: 61324.39
2024-06-15 02:00:28,350 train.py step   306 | loss: 5.657670 | lr 2.5762e-04 | norm: 1.5083 | dt: 85475.85ms | tok/sec: 61337.56
2024-06-15 02:01:53,832 train.py step   307 | loss: 5.580181 | lr 2.5846e-04 | norm: 0.9862 | dt: 85481.25ms | tok/sec: 61333.69
2024-06-15 02:03:19,321 train.py step   308 | loss: 5.532022 | lr 2.5930e-04 | norm: 1.0625 | dt: 85488.61ms | tok/sec: 61328.40
2024-06-15 02:04:44,785 train.py step   309 | loss: 5.542213 | lr 2.6014e-04 | norm: 1.2072 | dt: 85463.48ms | tok/sec: 61346.44
2024-06-15 02:06:10,277 train.py step   310 | loss: 5.640172 | lr 2.6098e-04 | norm: 1.0462 | dt: 85491.69ms | tok/sec: 61326.19
2024-06-15 02:07:35,767 train.py step   311 | loss: 5.627093 | lr 2.6182e-04 | norm: 1.7858 | dt: 85490.04ms | tok/sec: 61327.38
2024-06-15 02:09:01,257 train.py step   312 | loss: 5.561973 | lr 2.6266e-04 | norm: 1.0788 | dt: 85489.04ms | tok/sec: 61328.10
2024-06-15 02:10:26,710 train.py step   313 | loss: 5.518466 | lr 2.6350e-04 | norm: 1.3049 | dt: 85453.27ms | tok/sec: 61353.76
2024-06-15 02:11:52,171 train.py step   314 | loss: 5.573227 | lr 2.6434e-04 | norm: 1.0306 | dt: 85459.73ms | tok/sec: 61349.13
2024-06-15 02:13:17,623 train.py step   315 | loss: 5.606650 | lr 2.6517e-04 | norm: 1.2840 | dt: 85451.83ms | tok/sec: 61354.80
2024-06-15 02:14:43,053 train.py step   316 | loss: 5.565478 | lr 2.6601e-04 | norm: 1.0460 | dt: 85429.81ms | tok/sec: 61370.62
2024-06-15 02:16:08,440 train.py step   317 | loss: 5.530547 | lr 2.6685e-04 | norm: 1.2349 | dt: 85387.03ms | tok/sec: 61401.37
2024-06-15 02:17:33,860 train.py step   318 | loss: 5.478631 | lr 2.6769e-04 | norm: 0.8781 | dt: 85418.84ms | tok/sec: 61378.50
2024-06-15 02:18:59,282 train.py step   319 | loss: 5.585184 | lr 2.6853e-04 | norm: 0.8659 | dt: 85421.43ms | tok/sec: 61376.63
2024-06-15 02:20:24,681 train.py step   320 | loss: 5.582087 | lr 2.6937e-04 | norm: 1.0616 | dt: 85398.62ms | tok/sec: 61393.03
2024-06-15 02:21:50,089 train.py step   321 | loss: 5.525541 | lr 2.7021e-04 | norm: 1.1442 | dt: 85407.80ms | tok/sec: 61386.43
2024-06-15 02:23:15,515 train.py step   322 | loss: 5.484124 | lr 2.7105e-04 | norm: 1.2887 | dt: 85425.85ms | tok/sec: 61373.46
2024-06-15 02:24:40,947 train.py step   323 | loss: 5.496834 | lr 2.7189e-04 | norm: 1.3330 | dt: 85431.21ms | tok/sec: 61369.61
2024-06-15 02:26:06,377 train.py step   324 | loss: 5.605716 | lr 2.7273e-04 | norm: 1.3912 | dt: 85430.42ms | tok/sec: 61370.17
2024-06-15 02:27:31,837 train.py step   325 | loss: 5.576870 | lr 2.7357e-04 | norm: 1.0498 | dt: 85459.53ms | tok/sec: 61349.28
2024-06-15 02:28:57,308 train.py step   326 | loss: 5.506765 | lr 2.7441e-04 | norm: 1.1382 | dt: 85470.61ms | tok/sec: 61341.32
2024-06-15 02:30:22,780 train.py step   327 | loss: 5.474793 | lr 2.7524e-04 | norm: 1.3162 | dt: 85471.05ms | tok/sec: 61341.00
2024-06-15 02:31:48,212 train.py step   328 | loss: 5.461963 | lr 2.7608e-04 | norm: 1.3610 | dt: 85431.64ms | tok/sec: 61369.30
2024-06-15 02:33:13,673 train.py step   329 | loss: 5.564812 | lr 2.7692e-04 | norm: 0.9272 | dt: 85460.36ms | tok/sec: 61348.67
2024-06-15 02:34:39,132 train.py step   330 | loss: 5.545485 | lr 2.7776e-04 | norm: 1.4474 | dt: 85458.83ms | tok/sec: 61349.78
2024-06-15 02:36:04,598 train.py step   331 | loss: 5.477758 | lr 2.7860e-04 | norm: 0.8474 | dt: 85465.90ms | tok/sec: 61344.70
2024-06-15 02:37:30,084 train.py step   332 | loss: 5.446398 | lr 2.7944e-04 | norm: 1.1879 | dt: 85485.23ms | tok/sec: 61330.83
2024-06-15 02:38:55,556 train.py step   333 | loss: 5.493365 | lr 2.8028e-04 | norm: 1.0866 | dt: 85471.30ms | tok/sec: 61340.82
2024-06-15 02:40:21,014 train.py step   334 | loss: 5.518594 | lr 2.8112e-04 | norm: 0.9177 | dt: 85457.76ms | tok/sec: 61350.54
2024-06-15 02:41:46,448 train.py step   335 | loss: 5.491543 | lr 2.8196e-04 | norm: 1.0745 | dt: 85433.95ms | tok/sec: 61367.64
2024-06-15 02:43:11,898 train.py step   336 | loss: 5.453555 | lr 2.8280e-04 | norm: 1.2730 | dt: 85448.95ms | tok/sec: 61356.87
2024-06-15 02:44:37,346 train.py step   337 | loss: 5.415954 | lr 2.8364e-04 | norm: 1.3949 | dt: 85448.25ms | tok/sec: 61357.37
2024-06-15 02:46:02,809 train.py step   338 | loss: 5.516467 | lr 2.8448e-04 | norm: 1.1794 | dt: 85461.81ms | tok/sec: 61347.64
2024-06-15 02:47:28,281 train.py step   339 | loss: 5.499681 | lr 2.8531e-04 | norm: 1.0358 | dt: 85471.67ms | tok/sec: 61340.56
2024-06-15 02:48:53,760 train.py step   340 | loss: 5.462909 | lr 2.8615e-04 | norm: 1.1369 | dt: 85478.72ms | tok/sec: 61335.50
2024-06-15 02:50:19,218 train.py step   341 | loss: 5.428230 | lr 2.8699e-04 | norm: 1.3641 | dt: 85457.77ms | tok/sec: 61350.54
2024-06-15 02:51:44,679 train.py step   342 | loss: 5.408971 | lr 2.8783e-04 | norm: 0.9527 | dt: 85460.78ms | tok/sec: 61348.37
2024-06-15 02:53:10,142 train.py step   343 | loss: 5.523087 | lr 2.8867e-04 | norm: 1.1040 | dt: 85462.06ms | tok/sec: 61347.46
2024-06-15 02:54:35,608 train.py step   344 | loss: 5.506678 | lr 2.8951e-04 | norm: 1.1902 | dt: 85466.30ms | tok/sec: 61344.41
2024-06-15 02:56:01,068 train.py step   345 | loss: 5.444395 | lr 2.9035e-04 | norm: 1.1090 | dt: 85459.33ms | tok/sec: 61349.42
2024-06-15 02:57:26,535 train.py step   346 | loss: 5.402883 | lr 2.9119e-04 | norm: 1.0584 | dt: 85466.18ms | tok/sec: 61344.50
2024-06-15 02:58:52,029 train.py step   347 | loss: 5.378656 | lr 2.9203e-04 | norm: 1.3567 | dt: 85494.43ms | tok/sec: 61324.23
2024-06-15 03:00:17,505 train.py step   348 | loss: 5.490646 | lr 2.9287e-04 | norm: 1.0286 | dt: 85475.11ms | tok/sec: 61338.09
2024-06-15 03:01:42,998 train.py step   349 | loss: 5.473695 | lr 2.9371e-04 | norm: 1.3707 | dt: 85492.30ms | tok/sec: 61325.76
2024-06-15 03:03:08,491 train.py step   350 | loss: 5.414478 | lr 2.9455e-04 | norm: 0.9800 | dt: 85492.96ms | tok/sec: 61325.28
2024-06-15 03:04:33,974 train.py step   351 | loss: 5.384384 | lr 2.9538e-04 | norm: 1.3892 | dt: 85482.78ms | tok/sec: 61332.58
2024-06-15 03:05:59,470 train.py step   352 | loss: 5.416830 | lr 2.9622e-04 | norm: 0.9654 | dt: 85495.33ms | tok/sec: 61323.58
2024-06-15 03:07:24,939 train.py step   353 | loss: 5.453933 | lr 2.9706e-04 | norm: 1.1065 | dt: 85468.00ms | tok/sec: 61343.19
2024-06-15 03:08:50,407 train.py step   354 | loss: 5.445349 | lr 2.9790e-04 | norm: 1.5039 | dt: 85468.43ms | tok/sec: 61342.88
2024-06-15 03:10:15,869 train.py step   355 | loss: 5.385890 | lr 2.9874e-04 | norm: 0.9511 | dt: 85461.62ms | tok/sec: 61347.77
2024-06-15 03:11:41,356 train.py step   356 | loss: 5.341429 | lr 2.9958e-04 | norm: 1.0622 | dt: 85486.03ms | tok/sec: 61330.25
2024-06-15 03:13:06,829 train.py step   357 | loss: 5.431213 | lr 3.0042e-04 | norm: 1.0562 | dt: 85473.10ms | tok/sec: 61339.53
2024-06-15 03:14:32,316 train.py step   358 | loss: 5.436570 | lr 3.0126e-04 | norm: 1.1412 | dt: 85486.30ms | tok/sec: 61330.06
2024-06-15 03:15:57,802 train.py step   359 | loss: 5.409625 | lr 3.0210e-04 | norm: 1.3571 | dt: 85485.42ms | tok/sec: 61330.70
2024-06-15 03:17:23,249 train.py step   360 | loss: 5.344992 | lr 3.0294e-04 | norm: 1.0817 | dt: 85446.72ms | tok/sec: 61358.47
2024-06-15 03:18:48,687 train.py step   361 | loss: 5.333970 | lr 3.0378e-04 | norm: 1.0659 | dt: 85437.51ms | tok/sec: 61365.08
2024-06-15 03:20:14,168 train.py step   362 | loss: 5.454730 | lr 3.0462e-04 | norm: 1.1552 | dt: 85480.75ms | tok/sec: 61334.04
2024-06-15 03:21:39,637 train.py step   363 | loss: 5.443153 | lr 3.0545e-04 | norm: 1.2299 | dt: 85468.56ms | tok/sec: 61342.79
2024-06-15 03:23:05,106 train.py step   364 | loss: 5.385318 | lr 3.0629e-04 | norm: 1.2658 | dt: 85468.62ms | tok/sec: 61342.75
2024-06-15 03:24:30,598 train.py step   365 | loss: 5.342373 | lr 3.0713e-04 | norm: 1.3328 | dt: 85491.48ms | tok/sec: 61326.35
2024-06-15 03:25:56,084 train.py step   366 | loss: 5.295437 | lr 3.0797e-04 | norm: 1.0150 | dt: 85486.19ms | tok/sec: 61330.14
2024-06-15 03:27:21,593 train.py step   367 | loss: 5.428206 | lr 3.0881e-04 | norm: 1.2376 | dt: 85508.32ms | tok/sec: 61314.27
2024-06-15 03:28:47,098 train.py step   368 | loss: 5.414424 | lr 3.0965e-04 | norm: 1.3713 | dt: 85504.11ms | tok/sec: 61317.28
2024-06-15 03:30:12,597 train.py step   369 | loss: 5.362935 | lr 3.1049e-04 | norm: 1.2361 | dt: 85498.33ms | tok/sec: 61321.43
2024-06-15 03:31:38,084 train.py step   370 | loss: 5.322338 | lr 3.1133e-04 | norm: 1.2397 | dt: 85486.82ms | tok/sec: 61329.69
2024-06-15 03:33:03,572 train.py step   371 | loss: 5.336205 | lr 3.1217e-04 | norm: 1.0843 | dt: 85488.12ms | tok/sec: 61328.75
2024-06-15 03:34:29,056 train.py step   372 | loss: 5.397445 | lr 3.1301e-04 | norm: 1.1868 | dt: 85483.12ms | tok/sec: 61332.34
2024-06-15 03:35:54,544 train.py step   373 | loss: 5.352651 | lr 3.1385e-04 | norm: 0.8422 | dt: 85487.77ms | tok/sec: 61329.01
2024-06-15 03:37:20,027 train.py step   374 | loss: 5.306581 | lr 3.1469e-04 | norm: 0.9961 | dt: 85482.93ms | tok/sec: 61332.48
2024-06-15 03:38:45,475 train.py step   375 | loss: 5.284036 | lr 3.1552e-04 | norm: 1.2583 | dt: 85447.15ms | tok/sec: 61358.16
2024-06-15 03:40:10,929 train.py step   376 | loss: 5.343318 | lr 3.1636e-04 | norm: 0.8952 | dt: 85453.30ms | tok/sec: 61353.74
2024-06-15 03:41:36,387 train.py step   377 | loss: 5.371870 | lr 3.1720e-04 | norm: 1.2427 | dt: 85457.96ms | tok/sec: 61350.40
2024-06-15 03:43:01,854 train.py step   378 | loss: 5.346513 | lr 3.1804e-04 | norm: 1.2494 | dt: 85466.58ms | tok/sec: 61344.21
2024-06-15 03:44:27,320 train.py step   379 | loss: 5.295986 | lr 3.1888e-04 | norm: 1.5580 | dt: 85466.05ms | tok/sec: 61344.59
2024-06-15 03:45:52,793 train.py step   380 | loss: 5.265564 | lr 3.1972e-04 | norm: 1.2684 | dt: 85472.69ms | tok/sec: 61339.83
2024-06-15 03:47:18,245 train.py step   381 | loss: 5.393695 | lr 3.2056e-04 | norm: 1.2787 | dt: 85451.30ms | tok/sec: 61355.18
2024-06-15 03:48:43,718 train.py step   382 | loss: 5.377767 | lr 3.2140e-04 | norm: 1.0421 | dt: 85472.56ms | tok/sec: 61339.92
2024-06-15 03:50:09,186 train.py step   383 | loss: 5.335527 | lr 3.2224e-04 | norm: 1.3315 | dt: 85467.95ms | tok/sec: 61343.23
2024-06-15 03:51:34,678 train.py step   384 | loss: 5.273231 | lr 3.2308e-04 | norm: 1.0534 | dt: 85491.15ms | tok/sec: 61326.58
2024-06-15 03:53:00,153 train.py step   385 | loss: 5.232607 | lr 3.2392e-04 | norm: 1.1850 | dt: 85475.02ms | tok/sec: 61338.15
2024-06-15 03:54:25,631 train.py step   386 | loss: 5.347901 | lr 3.2476e-04 | norm: 1.1045 | dt: 85477.53ms | tok/sec: 61336.35
2024-06-15 03:55:51,062 train.py step   387 | loss: 5.340063 | lr 3.2559e-04 | norm: 1.3037 | dt: 85430.16ms | tok/sec: 61370.36
2024-06-15 03:57:16,497 train.py step   388 | loss: 5.313551 | lr 3.2643e-04 | norm: 1.1612 | dt: 85434.73ms | tok/sec: 61367.08
2024-06-15 03:58:41,923 train.py step   389 | loss: 5.243445 | lr 3.2727e-04 | norm: 0.9517 | dt: 85425.61ms | tok/sec: 61373.63
2024-06-15 04:00:07,402 train.py step   390 | loss: 5.255707 | lr 3.2811e-04 | norm: 1.0901 | dt: 85478.60ms | tok/sec: 61335.58
2024-06-15 04:01:32,869 train.py step   391 | loss: 5.329498 | lr 3.2895e-04 | norm: 0.9510 | dt: 85466.94ms | tok/sec: 61343.96
2024-06-15 04:02:58,330 train.py step   392 | loss: 5.283421 | lr 3.2979e-04 | norm: 1.0565 | dt: 85460.41ms | tok/sec: 61348.64
2024-06-15 04:04:23,765 train.py step   393 | loss: 5.262589 | lr 3.3063e-04 | norm: 1.3080 | dt: 85434.63ms | tok/sec: 61367.16
2024-06-15 04:05:49,213 train.py step   394 | loss: 5.220896 | lr 3.3147e-04 | norm: 1.2044 | dt: 85447.44ms | tok/sec: 61357.96
2024-06-15 04:07:14,643 train.py step   395 | loss: 5.283299 | lr 3.3231e-04 | norm: 1.0828 | dt: 85429.18ms | tok/sec: 61371.07
2024-06-15 04:08:40,105 train.py step   396 | loss: 5.308640 | lr 3.3315e-04 | norm: 1.2065 | dt: 85461.89ms | tok/sec: 61347.58
2024-06-15 04:10:05,525 train.py step   397 | loss: 5.286332 | lr 3.3399e-04 | norm: 1.0958 | dt: 85420.02ms | tok/sec: 61377.65
2024-06-15 04:11:30,950 train.py step   398 | loss: 5.215752 | lr 3.3483e-04 | norm: 0.9955 | dt: 85424.19ms | tok/sec: 61374.65
2024-06-15 04:12:56,389 train.py step   399 | loss: 5.183768 | lr 3.3566e-04 | norm: 1.1364 | dt: 85438.48ms | tok/sec: 61364.39
2024-06-15 04:14:21,819 train.py step   400 | loss: 5.310032 | lr 3.3650e-04 | norm: 0.9989 | dt: 85429.38ms | tok/sec: 61370.92
2024-06-15 04:15:47,238 train.py step   401 | loss: 5.347828 | lr 3.3734e-04 | norm: 1.8737 | dt: 85419.11ms | tok/sec: 61378.31
2024-06-15 04:17:12,677 train.py step   402 | loss: 5.275754 | lr 3.3818e-04 | norm: 1.0971 | dt: 85438.08ms | tok/sec: 61364.67
2024-06-15 04:18:38,121 train.py step   403 | loss: 5.210360 | lr 3.3902e-04 | norm: 1.1194 | dt: 85443.70ms | tok/sec: 61360.64
2024-06-15 04:20:03,531 train.py step   404 | loss: 5.168500 | lr 3.3986e-04 | norm: 1.1040 | dt: 85409.84ms | tok/sec: 61384.96
2024-06-15 04:21:28,940 train.py step   405 | loss: 5.274428 | lr 3.4070e-04 | norm: 1.0793 | dt: 85408.89ms | tok/sec: 61385.65
2024-06-15 04:22:54,396 train.py step   406 | loss: 5.283744 | lr 3.4154e-04 | norm: 1.6216 | dt: 85455.00ms | tok/sec: 61352.53
2024-06-15 04:24:19,883 train.py step   407 | loss: 5.257524 | lr 3.4238e-04 | norm: 1.3760 | dt: 85487.45ms | tok/sec: 61329.24
2024-06-15 04:25:45,388 train.py step   408 | loss: 5.187096 | lr 3.4322e-04 | norm: 1.0691 | dt: 85504.14ms | tok/sec: 61317.26
2024-06-15 04:27:10,910 train.py step   409 | loss: 5.170547 | lr 3.4406e-04 | norm: 1.0080 | dt: 85521.72ms | tok/sec: 61304.66
2024-06-15 04:28:36,374 train.py step   410 | loss: 5.270344 | lr 3.4490e-04 | norm: 1.0041 | dt: 85463.55ms | tok/sec: 61346.39
2024-06-15 04:30:01,842 train.py step   411 | loss: 5.229250 | lr 3.4573e-04 | norm: 1.2881 | dt: 85467.44ms | tok/sec: 61343.59
2024-06-15 04:31:27,273 train.py step   412 | loss: 5.206972 | lr 3.4657e-04 | norm: 1.2070 | dt: 85430.51ms | tok/sec: 61370.11
2024-06-15 04:32:52,715 train.py step   413 | loss: 5.173355 | lr 3.4741e-04 | norm: 1.2813 | dt: 85441.66ms | tok/sec: 61362.11
2024-06-15 04:34:18,181 train.py step   414 | loss: 5.211452 | lr 3.4825e-04 | norm: 1.0140 | dt: 85465.48ms | tok/sec: 61345.00
2024-06-15 04:35:43,654 train.py step   415 | loss: 5.269195 | lr 3.4909e-04 | norm: 1.3230 | dt: 85472.91ms | tok/sec: 61339.67
2024-06-15 04:37:09,134 train.py step   416 | loss: 5.218535 | lr 3.4993e-04 | norm: 0.8877 | dt: 85479.22ms | tok/sec: 61335.14
2024-06-15 04:38:34,648 train.py step   417 | loss: 5.165161 | lr 3.5077e-04 | norm: 1.1418 | dt: 85514.18ms | tok/sec: 61310.07
2024-06-15 04:40:00,118 train.py step   418 | loss: 5.131692 | lr 3.5161e-04 | norm: 1.1858 | dt: 85469.01ms | tok/sec: 61342.47
2024-06-15 04:41:25,631 train.py step   419 | loss: 5.263787 | lr 3.5245e-04 | norm: 1.4583 | dt: 85513.17ms | tok/sec: 61310.79
2024-06-15 04:42:51,141 train.py step   420 | loss: 5.282610 | lr 3.5329e-04 | norm: 1.5029 | dt: 85509.75ms | tok/sec: 61313.25
2024-06-15 04:44:16,615 train.py step   421 | loss: 5.206416 | lr 3.5413e-04 | norm: 0.9389 | dt: 85473.43ms | tok/sec: 61339.30
2024-06-15 04:45:42,060 train.py step   422 | loss: 5.167824 | lr 3.5497e-04 | norm: 1.3621 | dt: 85444.09ms | tok/sec: 61360.36
2024-06-15 04:47:07,512 train.py step   423 | loss: 5.114480 | lr 3.5580e-04 | norm: 1.0994 | dt: 85451.48ms | tok/sec: 61355.05
2024-06-15 04:48:32,993 train.py step   424 | loss: 5.204144 | lr 3.5664e-04 | norm: 1.0221 | dt: 85480.73ms | tok/sec: 61334.06
2024-06-15 04:49:58,453 train.py step   425 | loss: 5.220090 | lr 3.5748e-04 | norm: 1.2526 | dt: 85459.39ms | tok/sec: 61349.37
2024-06-15 04:51:23,893 train.py step   426 | loss: 5.217958 | lr 3.5832e-04 | norm: 1.5162 | dt: 85440.12ms | tok/sec: 61363.21
2024-06-15 04:52:49,363 train.py step   427 | loss: 5.132220 | lr 3.5916e-04 | norm: 1.0158 | dt: 85469.11ms | tok/sec: 61342.39
2024-06-15 04:54:14,827 train.py step   428 | loss: 5.114600 | lr 3.6000e-04 | norm: 1.2032 | dt: 85464.45ms | tok/sec: 61345.74
2024-06-15 04:55:40,295 train.py step   429 | loss: 5.217340 | lr 3.6084e-04 | norm: 1.0514 | dt: 85467.26ms | tok/sec: 61343.72
2024-06-15 04:57:05,827 train.py step   430 | loss: 5.173563 | lr 3.6168e-04 | norm: 1.1137 | dt: 85531.81ms | tok/sec: 61297.43
2024-06-15 04:58:31,324 train.py step   431 | loss: 5.151350 | lr 3.6252e-04 | norm: 1.0652 | dt: 85496.30ms | tok/sec: 61322.88
2024-06-15 04:59:56,827 train.py step   432 | loss: 5.103022 | lr 3.6336e-04 | norm: 1.0716 | dt: 85503.02ms | tok/sec: 61318.07
2024-06-15 05:01:22,308 train.py step   433 | loss: 5.134430 | lr 3.6420e-04 | norm: 0.9755 | dt: 85479.84ms | tok/sec: 61334.69
2024-06-15 05:02:47,776 train.py step   434 | loss: 5.200823 | lr 3.6503e-04 | norm: 1.2693 | dt: 85467.83ms | tok/sec: 61343.31
2024-06-15 05:04:13,258 train.py step   435 | loss: 5.157274 | lr 3.6587e-04 | norm: 1.1903 | dt: 85481.22ms | tok/sec: 61333.70
2024-06-15 05:05:38,740 train.py step   436 | loss: 5.099761 | lr 3.6671e-04 | norm: 1.0038 | dt: 85481.71ms | tok/sec: 61333.35
2024-06-15 05:07:04,213 train.py step   437 | loss: 5.058756 | lr 3.6755e-04 | norm: 1.1517 | dt: 85472.94ms | tok/sec: 61339.65
2024-06-15 05:08:29,670 train.py step   438 | loss: 5.173880 | lr 3.6839e-04 | norm: 0.9967 | dt: 85456.12ms | tok/sec: 61351.72
2024-06-15 05:09:55,135 train.py step   439 | loss: 5.218791 | lr 3.6923e-04 | norm: 1.4051 | dt: 85464.55ms | tok/sec: 61345.67
2024-06-15 05:11:20,592 train.py step   440 | loss: 5.166962 | lr 3.7007e-04 | norm: 1.3508 | dt: 85457.14ms | tok/sec: 61350.99
2024-06-15 05:12:46,050 train.py step   441 | loss: 5.113665 | lr 3.7091e-04 | norm: 1.3209 | dt: 85457.82ms | tok/sec: 61350.50
2024-06-15 05:14:11,528 train.py step   442 | loss: 5.048917 | lr 3.7175e-04 | norm: 1.0580 | dt: 85476.92ms | tok/sec: 61336.79
2024-06-15 05:15:37,002 train.py step   443 | loss: 5.143086 | lr 3.7259e-04 | norm: 1.2431 | dt: 85474.28ms | tok/sec: 61338.69
2024-06-15 05:17:02,467 train.py step   444 | loss: 5.138374 | lr 3.7343e-04 | norm: 0.9380 | dt: 85464.50ms | tok/sec: 61345.71
2024-06-15 05:18:27,935 train.py step   445 | loss: 5.125246 | lr 3.7427e-04 | norm: 1.0272 | dt: 85467.87ms | tok/sec: 61343.29
2024-06-15 05:19:53,410 train.py step   446 | loss: 5.071500 | lr 3.7510e-04 | norm: 1.1985 | dt: 85474.23ms | tok/sec: 61338.72
2024-06-15 05:21:18,904 train.py step   447 | loss: 5.020418 | lr 3.7594e-04 | norm: 1.1394 | dt: 85493.44ms | tok/sec: 61324.94
2024-06-15 05:22:44,416 train.py step   448 | loss: 5.162369 | lr 3.7678e-04 | norm: 1.3367 | dt: 85512.07ms | tok/sec: 61311.58
2024-06-15 05:24:09,921 train.py step   449 | loss: 5.102740 | lr 3.7762e-04 | norm: 1.0115 | dt: 85504.32ms | tok/sec: 61317.13
2024-06-15 05:25:35,444 train.py step   450 | loss: 5.090188 | lr 3.7846e-04 | norm: 1.1955 | dt: 85522.23ms | tok/sec: 61304.30
2024-06-15 05:27:00,933 train.py step   451 | loss: 5.026301 | lr 3.7930e-04 | norm: 0.9904 | dt: 85488.95ms | tok/sec: 61328.16
2024-06-15 05:28:26,415 train.py step   452 | loss: 5.064610 | lr 3.8014e-04 | norm: 1.0997 | dt: 85481.91ms | tok/sec: 61333.21
2024-06-15 05:29:51,917 train.py step   453 | loss: 5.122456 | lr 3.8098e-04 | norm: 1.0115 | dt: 85501.24ms | tok/sec: 61319.34
2024-06-15 05:31:17,441 train.py step   454 | loss: 5.104749 | lr 3.8182e-04 | norm: 1.2183 | dt: 85523.61ms | tok/sec: 61303.31
2024-06-15 05:32:42,967 train.py step   455 | loss: 5.036146 | lr 3.8266e-04 | norm: 1.1292 | dt: 85525.72ms | tok/sec: 61301.80
2024-06-15 05:34:08,499 train.py step   456 | loss: 4.991187 | lr 3.8350e-04 | norm: 1.1902 | dt: 85532.07ms | tok/sec: 61297.24
2024-06-15 05:35:34,029 train.py step   457 | loss: 5.109185 | lr 3.8434e-04 | norm: 1.1633 | dt: 85528.90ms | tok/sec: 61299.51
2024-06-15 05:36:59,525 train.py step   458 | loss: 5.146127 | lr 3.8517e-04 | norm: 1.1486 | dt: 85495.66ms | tok/sec: 61323.35
2024-06-15 05:38:25,030 train.py step   459 | loss: 5.083976 | lr 3.8601e-04 | norm: 0.9683 | dt: 85505.07ms | tok/sec: 61316.60
2024-06-15 05:39:50,538 train.py step   460 | loss: 5.022576 | lr 3.8685e-04 | norm: 1.1591 | dt: 85507.17ms | tok/sec: 61315.09
2024-06-15 05:41:16,049 train.py step   461 | loss: 4.996639 | lr 3.8769e-04 | norm: 1.3153 | dt: 85510.78ms | tok/sec: 61312.50
2024-06-15 05:42:41,549 train.py step   462 | loss: 5.051033 | lr 3.8853e-04 | norm: 0.8818 | dt: 85499.66ms | tok/sec: 61320.48
2024-06-15 05:44:07,083 train.py step   463 | loss: 5.069004 | lr 3.8937e-04 | norm: 1.0432 | dt: 85533.96ms | tok/sec: 61295.89
2024-06-15 05:45:32,611 train.py step   464 | loss: 5.067754 | lr 3.9021e-04 | norm: 1.1955 | dt: 85527.19ms | tok/sec: 61300.74
2024-06-15 05:46:58,111 train.py step   465 | loss: 5.021658 | lr 3.9105e-04 | norm: 1.2765 | dt: 85499.76ms | tok/sec: 61320.41
2024-06-15 05:48:23,607 train.py step   466 | loss: 4.956186 | lr 3.9189e-04 | norm: 1.0235 | dt: 85495.53ms | tok/sec: 61323.44
2024-06-15 05:49:49,078 train.py step   467 | loss: 5.082934 | lr 3.9273e-04 | norm: 0.9670 | dt: 85471.06ms | tok/sec: 61340.99
2024-06-15 05:51:14,570 train.py step   468 | loss: 5.039117 | lr 3.9357e-04 | norm: 1.1872 | dt: 85491.13ms | tok/sec: 61326.60
2024-06-15 05:52:40,049 train.py step   469 | loss: 5.020871 | lr 3.9441e-04 | norm: 1.1400 | dt: 85478.60ms | tok/sec: 61335.58
2024-06-15 05:54:05,552 train.py step   470 | loss: 4.966652 | lr 3.9524e-04 | norm: 1.0037 | dt: 85502.68ms | tok/sec: 61318.31
2024-06-15 05:55:31,033 train.py step   471 | loss: 4.986431 | lr 3.9608e-04 | norm: 1.0815 | dt: 85480.62ms | tok/sec: 61334.14
2024-06-15 05:56:56,498 train.py step   472 | loss: 5.057073 | lr 3.9692e-04 | norm: 1.0508 | dt: 85464.99ms | tok/sec: 61345.36
2024-06-15 05:58:21,933 train.py step   473 | loss: 5.017533 | lr 3.9776e-04 | norm: 0.8522 | dt: 85433.90ms | tok/sec: 61367.67
2024-06-15 05:59:47,387 train.py step   474 | loss: 4.946282 | lr 3.9860e-04 | norm: 0.8125 | dt: 85453.71ms | tok/sec: 61353.45
2024-06-15 06:01:12,860 train.py step   475 | loss: 4.893420 | lr 3.9944e-04 | norm: 0.8355 | dt: 85472.75ms | tok/sec: 61339.78
2024-06-15 06:02:38,352 train.py step   476 | loss: 5.017439 | lr 4.0028e-04 | norm: 1.2569 | dt: 85491.80ms | tok/sec: 61326.12
2024-06-15 06:04:03,881 train.py step   477 | loss: 5.069695 | lr 4.0112e-04 | norm: 1.3146 | dt: 85528.52ms | tok/sec: 61299.79
2024-06-15 06:05:29,415 train.py step   478 | loss: 5.025701 | lr 4.0196e-04 | norm: 1.3412 | dt: 85533.42ms | tok/sec: 61296.27
2024-06-15 06:06:54,941 train.py step   479 | loss: 4.960326 | lr 4.0280e-04 | norm: 1.1162 | dt: 85525.90ms | tok/sec: 61301.67
2024-06-15 06:08:20,456 train.py step   480 | loss: 4.931734 | lr 4.0364e-04 | norm: 1.2811 | dt: 85513.93ms | tok/sec: 61310.25
2024-06-15 06:09:45,945 train.py step   481 | loss: 4.978551 | lr 4.0448e-04 | norm: 1.0749 | dt: 85488.46ms | tok/sec: 61328.51
2024-06-15 06:11:11,478 train.py step   482 | loss: 4.996468 | lr 4.0531e-04 | norm: 1.0070 | dt: 85533.10ms | tok/sec: 61296.51
2024-06-15 06:12:37,011 train.py step   483 | loss: 5.017135 | lr 4.0615e-04 | norm: 1.3779 | dt: 85532.67ms | tok/sec: 61296.81
2024-06-15 06:14:02,514 train.py step   484 | loss: 4.946594 | lr 4.0699e-04 | norm: 1.0640 | dt: 85502.85ms | tok/sec: 61318.19
2024-06-15 06:15:27,997 train.py step   485 | loss: 4.879118 | lr 4.0783e-04 | norm: 1.0787 | dt: 85482.60ms | tok/sec: 61332.72
2024-06-15 06:16:53,506 train.py step   486 | loss: 5.018906 | lr 4.0867e-04 | norm: 1.2523 | dt: 85508.58ms | tok/sec: 61314.08
2024-06-15 06:18:19,018 train.py step   487 | loss: 4.975764 | lr 4.0951e-04 | norm: 1.1427 | dt: 85511.43ms | tok/sec: 61312.04
2024-06-15 06:19:44,530 train.py step   488 | loss: 4.957154 | lr 4.1035e-04 | norm: 1.2742 | dt: 85510.99ms | tok/sec: 61312.35
2024-06-15 06:21:10,025 train.py step   489 | loss: 4.905732 | lr 4.1119e-04 | norm: 1.1485 | dt: 85495.45ms | tok/sec: 61323.50
2024-06-15 06:22:35,512 train.py step   490 | loss: 4.927969 | lr 4.1203e-04 | norm: 1.2989 | dt: 85486.42ms | tok/sec: 61329.98
2024-06-15 06:24:01,022 train.py step   491 | loss: 4.996438 | lr 4.1287e-04 | norm: 1.0293 | dt: 85509.12ms | tok/sec: 61313.69
2024-06-15 06:25:26,519 train.py step   492 | loss: 4.980981 | lr 4.1371e-04 | norm: 1.2919 | dt: 85496.65ms | tok/sec: 61322.63
2024-06-15 06:26:52,012 train.py step   493 | loss: 4.907532 | lr 4.1455e-04 | norm: 0.9795 | dt: 85492.86ms | tok/sec: 61325.35
2024-06-15 06:28:17,513 train.py step   494 | loss: 4.859913 | lr 4.1538e-04 | norm: 1.2560 | dt: 85500.22ms | tok/sec: 61320.07
2024-06-15 06:29:43,019 train.py step   495 | loss: 4.951780 | lr 4.1622e-04 | norm: 1.0733 | dt: 85506.42ms | tok/sec: 61315.63
2024-06-15 06:31:08,478 train.py step   496 | loss: 5.038208 | lr 4.1706e-04 | norm: 1.4633 | dt: 85458.35ms | tok/sec: 61350.12
2024-06-15 06:32:33,967 train.py step   497 | loss: 4.974673 | lr 4.1790e-04 | norm: 1.0990 | dt: 85488.43ms | tok/sec: 61328.53
2024-06-15 06:33:59,419 train.py step   498 | loss: 4.903253 | lr 4.1874e-04 | norm: 1.1336 | dt: 85452.27ms | tok/sec: 61354.49
2024-06-15 06:35:24,874 train.py step   499 | loss: 4.867119 | lr 4.1958e-04 | norm: 1.0566 | dt: 85454.16ms | tok/sec: 61353.13
2024-06-15 06:35:26,996 train.py validation loss: 5.0327
2024-06-15 06:36:53,491 train.py step   500 | loss: 4.912773 | lr 4.2042e-04 | norm: 1.1632 | dt: 88616.19ms | tok/sec: 59163.90
2024-06-15 06:38:18,981 train.py step   501 | loss: 4.947038 | lr 4.2126e-04 | norm: 0.8988 | dt: 85489.68ms | tok/sec: 61327.64
2024-06-15 06:39:44,477 train.py step   502 | loss: 4.959562 | lr 4.2210e-04 | norm: 1.3768 | dt: 85495.87ms | tok/sec: 61323.19
2024-06-15 06:41:09,965 train.py step   503 | loss: 4.894314 | lr 4.2294e-04 | norm: 1.1378 | dt: 85487.49ms | tok/sec: 61329.21
2024-06-15 06:42:35,447 train.py step   504 | loss: 4.832691 | lr 4.2378e-04 | norm: 1.1834 | dt: 85481.51ms | tok/sec: 61333.50
2024-06-15 06:44:00,938 train.py step   505 | loss: 4.948992 | lr 4.2462e-04 | norm: 1.1961 | dt: 85490.79ms | tok/sec: 61326.84
2024-06-15 06:45:26,443 train.py step   506 | loss: 4.930326 | lr 4.2545e-04 | norm: 1.2139 | dt: 85505.06ms | tok/sec: 61316.60
2024-06-15 06:46:51,932 train.py step   507 | loss: 4.890821 | lr 4.2629e-04 | norm: 1.0072 | dt: 85487.96ms | tok/sec: 61328.87
2024-06-15 06:48:17,431 train.py step   508 | loss: 4.843439 | lr 4.2713e-04 | norm: 1.1409 | dt: 85498.61ms | tok/sec: 61321.23
2024-06-15 06:49:42,916 train.py step   509 | loss: 4.838523 | lr 4.2797e-04 | norm: 0.9266 | dt: 85485.23ms | tok/sec: 61330.83
2024-06-15 06:51:08,393 train.py step   510 | loss: 4.936619 | lr 4.2881e-04 | norm: 1.0133 | dt: 85476.38ms | tok/sec: 61337.18
2024-06-15 06:52:33,823 train.py step   511 | loss: 4.907456 | lr 4.2965e-04 | norm: 1.2167 | dt: 85429.33ms | tok/sec: 61370.96
2024-06-15 06:53:59,276 train.py step   512 | loss: 4.850886 | lr 4.3049e-04 | norm: 1.0372 | dt: 85452.76ms | tok/sec: 61354.13
2024-06-15 06:55:24,678 train.py step   513 | loss: 4.789986 | lr 4.3133e-04 | norm: 1.0193 | dt: 85402.06ms | tok/sec: 61390.56
2024-06-15 06:56:50,102 train.py step   514 | loss: 4.872721 | lr 4.3217e-04 | norm: 1.0639 | dt: 85423.39ms | tok/sec: 61375.23
2024-06-15 06:58:15,578 train.py step   515 | loss: 4.949615 | lr 4.3301e-04 | norm: 0.9655 | dt: 85475.10ms | tok/sec: 61338.10
2024-06-15 06:59:41,028 train.py step   516 | loss: 4.894518 | lr 4.3385e-04 | norm: 1.1006 | dt: 85449.94ms | tok/sec: 61356.16
2024-06-15 07:01:06,485 train.py step   517 | loss: 4.827984 | lr 4.3469e-04 | norm: 0.9424 | dt: 85456.16ms | tok/sec: 61351.69
2024-06-15 07:02:31,958 train.py step   518 | loss: 4.799337 | lr 4.3552e-04 | norm: 1.1230 | dt: 85473.57ms | tok/sec: 61339.20
2024-06-15 07:03:57,410 train.py step   519 | loss: 4.828703 | lr 4.3636e-04 | norm: 1.1179 | dt: 85450.80ms | tok/sec: 61355.54
2024-06-15 07:05:22,810 train.py step   520 | loss: 4.886364 | lr 4.3720e-04 | norm: 0.9590 | dt: 85400.01ms | tok/sec: 61392.03
2024-06-15 07:06:48,240 train.py step   521 | loss: 4.879345 | lr 4.3804e-04 | norm: 1.0899 | dt: 85429.69ms | tok/sec: 61370.70
2024-06-15 07:08:13,692 train.py step   522 | loss: 4.811878 | lr 4.3888e-04 | norm: 0.9145 | dt: 85451.23ms | tok/sec: 61355.23
2024-06-15 07:09:39,142 train.py step   523 | loss: 4.750337 | lr 4.3972e-04 | norm: 1.0225 | dt: 85449.97ms | tok/sec: 61356.14
2024-06-15 07:11:04,632 train.py step   524 | loss: 4.872764 | lr 4.4056e-04 | norm: 1.0415 | dt: 85489.21ms | tok/sec: 61327.98
2024-06-15 07:12:30,067 train.py step   525 | loss: 4.854476 | lr 4.4140e-04 | norm: 1.0014 | dt: 85435.39ms | tok/sec: 61366.61
2024-06-15 07:13:55,495 train.py step   526 | loss: 4.828908 | lr 4.4224e-04 | norm: 1.1669 | dt: 85427.28ms | tok/sec: 61372.43
2024-06-15 07:15:20,951 train.py step   527 | loss: 4.778948 | lr 4.4308e-04 | norm: 1.0142 | dt: 85455.67ms | tok/sec: 61352.04
2024-06-15 07:16:46,406 train.py step   528 | loss: 4.757643 | lr 4.4392e-04 | norm: 1.0035 | dt: 85454.58ms | tok/sec: 61352.82
2024-06-15 07:18:11,847 train.py step   529 | loss: 4.876957 | lr 4.4476e-04 | norm: 0.9826 | dt: 85440.46ms | tok/sec: 61362.97
2024-06-15 07:19:37,326 train.py step   530 | loss: 4.831667 | lr 4.4559e-04 | norm: 0.9607 | dt: 85478.62ms | tok/sec: 61335.57
2024-06-15 07:21:02,794 train.py step   531 | loss: 4.779665 | lr 4.4643e-04 | norm: 0.8603 | dt: 85467.23ms | tok/sec: 61343.75
2024-06-15 07:22:28,262 train.py step   532 | loss: 4.711198 | lr 4.4727e-04 | norm: 0.8575 | dt: 85467.95ms | tok/sec: 61343.23
2024-06-15 07:23:53,746 train.py step   533 | loss: 4.786053 | lr 4.4811e-04 | norm: 0.9140 | dt: 85483.09ms | tok/sec: 61332.36
2024-06-15 07:25:19,223 train.py step   534 | loss: 4.858251 | lr 4.4895e-04 | norm: 0.8290 | dt: 85477.52ms | tok/sec: 61336.36
2024-06-15 07:26:44,701 train.py step   535 | loss: 4.812604 | lr 4.4979e-04 | norm: 0.8187 | dt: 85477.49ms | tok/sec: 61336.39
2024-06-15 07:28:10,181 train.py step   536 | loss: 4.742620 | lr 4.5063e-04 | norm: 0.8361 | dt: 85479.76ms | tok/sec: 61334.75
2024-06-15 07:29:35,671 train.py step   537 | loss: 4.731847 | lr 4.5147e-04 | norm: 1.1716 | dt: 85489.44ms | tok/sec: 61327.81
2024-06-15 07:31:01,154 train.py step   538 | loss: 4.729531 | lr 4.5231e-04 | norm: 0.8559 | dt: 85481.83ms | tok/sec: 61333.27
2024-06-15 07:32:26,613 train.py step   539 | loss: 4.804359 | lr 4.5315e-04 | norm: 0.8692 | dt: 85459.43ms | tok/sec: 61349.34
2024-06-15 07:33:52,046 train.py step   540 | loss: 4.797828 | lr 4.5399e-04 | norm: 1.0153 | dt: 85432.17ms | tok/sec: 61368.92
2024-06-15 07:35:17,504 train.py step   541 | loss: 4.760828 | lr 4.5483e-04 | norm: 1.3081 | dt: 85457.24ms | tok/sec: 61350.91
2024-06-15 07:36:42,958 train.py step   542 | loss: 4.694995 | lr 4.5566e-04 | norm: 1.1436 | dt: 85453.65ms | tok/sec: 61353.49
2024-06-15 07:38:08,423 train.py step   543 | loss: 4.777093 | lr 4.5650e-04 | norm: 0.8718 | dt: 85464.87ms | tok/sec: 61345.44
2024-06-15 07:39:33,885 train.py step   544 | loss: 4.781272 | lr 4.5734e-04 | norm: 0.8877 | dt: 85461.96ms | tok/sec: 61347.53
2024-06-15 07:40:59,331 train.py step   545 | loss: 4.768969 | lr 4.5818e-04 | norm: 1.2223 | dt: 85445.05ms | tok/sec: 61359.67
2024-06-15 07:42:24,742 train.py step   546 | loss: 4.714963 | lr 4.5902e-04 | norm: 1.1137 | dt: 85410.90ms | tok/sec: 61384.20
2024-06-15 07:43:50,173 train.py step   547 | loss: 4.682287 | lr 4.5986e-04 | norm: 1.0195 | dt: 85430.32ms | tok/sec: 61370.25
2024-06-15 07:45:15,623 train.py step   548 | loss: 4.810468 | lr 4.6070e-04 | norm: 0.9954 | dt: 85449.97ms | tok/sec: 61356.13
2024-06-15 07:46:41,098 train.py step   549 | loss: 4.790734 | lr 4.6154e-04 | norm: 1.2371 | dt: 85475.02ms | tok/sec: 61338.15
2024-06-15 07:48:06,593 train.py step   550 | loss: 4.740934 | lr 4.6238e-04 | norm: 1.3099 | dt: 85494.16ms | tok/sec: 61324.42
2024-06-15 07:49:32,071 train.py step   551 | loss: 4.678833 | lr 4.6322e-04 | norm: 1.0624 | dt: 85478.00ms | tok/sec: 61336.02
2024-06-15 07:50:57,580 train.py step   552 | loss: 4.721101 | lr 4.6406e-04 | norm: 1.0367 | dt: 85508.81ms | tok/sec: 61313.92
2024-06-15 07:52:23,092 train.py step   553 | loss: 4.831423 | lr 4.6490e-04 | norm: 1.1456 | dt: 85511.34ms | tok/sec: 61312.11
2024-06-15 07:53:48,595 train.py step   554 | loss: 4.815881 | lr 4.6573e-04 | norm: 1.3905 | dt: 85502.37ms | tok/sec: 61318.53
2024-06-15 07:55:14,091 train.py step   555 | loss: 4.717324 | lr 4.6657e-04 | norm: 1.0210 | dt: 85495.85ms | tok/sec: 61323.21
2024-06-15 07:56:39,600 train.py step   556 | loss: 4.685470 | lr 4.6741e-04 | norm: 0.9679 | dt: 85508.58ms | tok/sec: 61314.08
2024-06-15 07:58:05,076 train.py step   557 | loss: 4.684435 | lr 4.6825e-04 | norm: 1.0493 | dt: 85474.95ms | tok/sec: 61338.20
2024-06-15 07:59:30,582 train.py step   558 | loss: 4.780819 | lr 4.6909e-04 | norm: 1.0704 | dt: 85506.07ms | tok/sec: 61315.88
2024-06-15 08:00:56,068 train.py step   559 | loss: 4.777203 | lr 4.6993e-04 | norm: 1.1297 | dt: 85485.74ms | tok/sec: 61330.46
2024-06-15 08:02:21,560 train.py step   560 | loss: 4.708419 | lr 4.7077e-04 | norm: 0.9246 | dt: 85491.54ms | tok/sec: 61326.30
2024-06-15 08:03:47,068 train.py step   561 | loss: 4.647310 | lr 4.7161e-04 | norm: 0.9726 | dt: 85507.84ms | tok/sec: 61314.62
2024-06-15 08:05:12,592 train.py step   562 | loss: 4.727240 | lr 4.7245e-04 | norm: 1.1285 | dt: 85523.43ms | tok/sec: 61303.43
2024-06-15 08:06:38,147 train.py step   563 | loss: 4.745938 | lr 4.7329e-04 | norm: 0.8785 | dt: 85554.21ms | tok/sec: 61281.38
2024-06-15 08:08:03,683 train.py step   564 | loss: 4.698948 | lr 4.7413e-04 | norm: 0.8694 | dt: 85535.52ms | tok/sec: 61294.77
2024-06-15 08:09:29,187 train.py step   565 | loss: 4.671739 | lr 4.7497e-04 | norm: 0.9930 | dt: 85504.46ms | tok/sec: 61317.04
2024-06-15 08:10:54,682 train.py step   566 | loss: 4.606658 | lr 4.7580e-04 | norm: 0.8314 | dt: 85493.81ms | tok/sec: 61324.67
2024-06-15 08:12:20,192 train.py step   567 | loss: 4.743824 | lr 4.7664e-04 | norm: 0.8049 | dt: 85509.90ms | tok/sec: 61313.13
2024-06-15 08:13:45,698 train.py step   568 | loss: 4.719791 | lr 4.7748e-04 | norm: 0.9189 | dt: 85505.42ms | tok/sec: 61316.35
2024-06-15 08:15:11,193 train.py step   569 | loss: 4.684072 | lr 4.7832e-04 | norm: 1.1322 | dt: 85494.52ms | tok/sec: 61324.16
2024-06-15 08:16:36,686 train.py step   570 | loss: 4.625929 | lr 4.7916e-04 | norm: 1.1679 | dt: 85493.31ms | tok/sec: 61325.03
2024-06-15 08:18:02,178 train.py step   571 | loss: 4.642111 | lr 4.8000e-04 | norm: 0.9973 | dt: 85491.60ms | tok/sec: 61326.26
2024-06-15 08:19:27,657 train.py step   572 | loss: 4.754334 | lr 4.8084e-04 | norm: 0.9396 | dt: 85478.48ms | tok/sec: 61335.67
2024-06-15 08:20:53,151 train.py step   573 | loss: 4.722991 | lr 4.8168e-04 | norm: 0.9122 | dt: 85493.28ms | tok/sec: 61325.05
2024-06-15 08:22:18,605 train.py step   574 | loss: 4.646285 | lr 4.8252e-04 | norm: 0.8747 | dt: 85453.96ms | tok/sec: 61353.27
2024-06-15 08:23:44,087 train.py step   575 | loss: 4.608209 | lr 4.8336e-04 | norm: 0.9094 | dt: 85481.34ms | tok/sec: 61333.62
2024-06-15 08:25:09,582 train.py step   576 | loss: 4.587995 | lr 4.8420e-04 | norm: 0.7430 | dt: 85494.47ms | tok/sec: 61324.20
2024-06-15 08:26:35,051 train.py step   577 | loss: 4.688053 | lr 4.8503e-04 | norm: 0.6481 | dt: 85469.14ms | tok/sec: 61342.38
2024-06-15 08:28:00,527 train.py step   578 | loss: 4.664897 | lr 4.8587e-04 | norm: 0.7029 | dt: 85475.51ms | tok/sec: 61337.80
2024-06-15 08:29:26,029 train.py step   579 | loss: 4.614719 | lr 4.8671e-04 | norm: 0.7478 | dt: 85501.50ms | tok/sec: 61319.16
2024-06-15 08:30:51,519 train.py step   580 | loss: 4.556314 | lr 4.8755e-04 | norm: 0.9154 | dt: 85490.08ms | tok/sec: 61327.35
2024-06-15 08:32:17,032 train.py step   581 | loss: 4.645801 | lr 4.8839e-04 | norm: 1.1083 | dt: 85512.32ms | tok/sec: 61311.40
2024-06-15 08:33:42,552 train.py step   582 | loss: 4.678220 | lr 4.8923e-04 | norm: 1.0385 | dt: 85518.98ms | tok/sec: 61306.63
2024-06-15 08:35:08,079 train.py step   583 | loss: 4.641645 | lr 4.9007e-04 | norm: 1.1130 | dt: 85527.05ms | tok/sec: 61300.84
2024-06-15 08:36:33,608 train.py step   584 | loss: 4.594404 | lr 4.9091e-04 | norm: 0.8752 | dt: 85528.40ms | tok/sec: 61299.88
2024-06-15 08:37:59,132 train.py step   585 | loss: 4.543750 | lr 4.9175e-04 | norm: 0.9788 | dt: 85523.52ms | tok/sec: 61303.37
2024-06-15 08:39:24,649 train.py step   586 | loss: 4.662280 | lr 4.9259e-04 | norm: 0.8885 | dt: 85517.23ms | tok/sec: 61307.88
2024-06-15 08:40:50,151 train.py step   587 | loss: 4.657093 | lr 4.9343e-04 | norm: 0.9320 | dt: 85501.47ms | tok/sec: 61319.18
2024-06-15 08:42:15,643 train.py step   588 | loss: 4.609241 | lr 4.9427e-04 | norm: 0.8799 | dt: 85491.03ms | tok/sec: 61326.67
2024-06-15 08:43:41,119 train.py step   589 | loss: 4.559747 | lr 4.9510e-04 | norm: 1.0725 | dt: 85475.89ms | tok/sec: 61337.53
2024-06-15 08:45:06,629 train.py step   590 | loss: 4.567578 | lr 4.9594e-04 | norm: 1.0625 | dt: 85509.35ms | tok/sec: 61313.53
2024-06-15 08:46:32,127 train.py step   591 | loss: 4.686121 | lr 4.9678e-04 | norm: 0.8607 | dt: 85498.33ms | tok/sec: 61321.43
2024-06-15 08:47:57,600 train.py step   592 | loss: 4.658126 | lr 4.9762e-04 | norm: 0.8527 | dt: 85472.45ms | tok/sec: 61340.00
2024-06-15 08:49:23,046 train.py step   593 | loss: 4.599569 | lr 4.9846e-04 | norm: 1.0088 | dt: 85445.98ms | tok/sec: 61359.00
2024-06-15 08:50:48,544 train.py step   594 | loss: 4.564362 | lr 4.9930e-04 | norm: 0.9910 | dt: 85496.95ms | tok/sec: 61322.42
2024-06-15 08:52:14,053 train.py step   595 | loss: 4.528966 | lr 5.0014e-04 | norm: 0.9785 | dt: 85508.44ms | tok/sec: 61314.18
2024-06-15 08:53:39,551 train.py step   596 | loss: 4.662465 | lr 5.0098e-04 | norm: 0.9506 | dt: 85497.48ms | tok/sec: 61322.04
2024-06-15 08:55:05,002 train.py step   597 | loss: 4.628554 | lr 5.0182e-04 | norm: 0.9909 | dt: 85451.39ms | tok/sec: 61355.12
2024-06-15 08:56:30,452 train.py step   598 | loss: 4.596036 | lr 5.0266e-04 | norm: 1.1276 | dt: 85449.01ms | tok/sec: 61356.82
2024-06-15 08:57:55,904 train.py step   599 | loss: 4.536193 | lr 5.0350e-04 | norm: 0.9791 | dt: 85451.77ms | tok/sec: 61354.85
2024-06-15 08:59:21,373 train.py step   600 | loss: 4.586615 | lr 5.0434e-04 | norm: 0.9700 | dt: 85468.62ms | tok/sec: 61342.74
2024-06-15 09:00:46,844 train.py step   601 | loss: 4.624855 | lr 5.0517e-04 | norm: 0.9639 | dt: 85470.69ms | tok/sec: 61341.26
2024-06-15 09:02:12,293 train.py step   602 | loss: 4.595963 | lr 5.0601e-04 | norm: 0.9848 | dt: 85449.09ms | tok/sec: 61356.77
2024-06-15 09:03:37,727 train.py step   603 | loss: 4.559981 | lr 5.0685e-04 | norm: 0.9481 | dt: 85433.13ms | tok/sec: 61368.23
2024-06-15 09:05:03,180 train.py step   604 | loss: 4.504454 | lr 5.0769e-04 | norm: 1.1006 | dt: 85452.51ms | tok/sec: 61354.31
2024-06-15 09:06:28,625 train.py step   605 | loss: 4.618251 | lr 5.0853e-04 | norm: 0.8984 | dt: 85444.69ms | tok/sec: 61359.93
2024-06-15 09:07:54,080 train.py step   606 | loss: 4.610244 | lr 5.0937e-04 | norm: 0.9064 | dt: 85454.82ms | tok/sec: 61352.65
2024-06-15 09:09:19,475 train.py step   607 | loss: 4.576872 | lr 5.1021e-04 | norm: 0.8914 | dt: 85394.36ms | tok/sec: 61396.09
2024-06-15 09:10:44,887 train.py step   608 | loss: 4.516246 | lr 5.1105e-04 | norm: 0.9696 | dt: 85411.42ms | tok/sec: 61383.83
2024-06-15 09:12:10,318 train.py step   609 | loss: 4.517576 | lr 5.1189e-04 | norm: 1.0406 | dt: 85431.15ms | tok/sec: 61369.65
2024-06-15 09:13:35,775 train.py step   610 | loss: 4.639310 | lr 5.1273e-04 | norm: 0.8577 | dt: 85456.35ms | tok/sec: 61351.56
2024-06-15 09:15:01,263 train.py step   611 | loss: 4.602134 | lr 5.1357e-04 | norm: 0.8034 | dt: 85487.52ms | tok/sec: 61329.18
2024-06-15 09:16:26,771 train.py step   612 | loss: 4.546630 | lr 5.1441e-04 | norm: 0.8172 | dt: 85508.01ms | tok/sec: 61314.49
2024-06-15 09:17:52,277 train.py step   613 | loss: 4.494745 | lr 5.1524e-04 | norm: 0.6634 | dt: 85505.78ms | tok/sec: 61316.09
2024-06-15 09:19:17,771 train.py step   614 | loss: 4.437215 | lr 5.1608e-04 | norm: 0.6992 | dt: 85493.74ms | tok/sec: 61324.72
2024-06-15 09:20:43,245 train.py step   615 | loss: 4.591613 | lr 5.1692e-04 | norm: 0.8361 | dt: 85472.82ms | tok/sec: 61339.74
2024-06-15 09:22:08,714 train.py step   616 | loss: 4.554818 | lr 5.1776e-04 | norm: 0.8189 | dt: 85468.74ms | tok/sec: 61342.66
2024-06-15 09:23:34,187 train.py step   617 | loss: 4.523838 | lr 5.1860e-04 | norm: 0.7482 | dt: 85472.80ms | tok/sec: 61339.75
2024-06-15 09:24:59,662 train.py step   618 | loss: 4.459019 | lr 5.1944e-04 | norm: 0.8430 | dt: 85475.17ms | tok/sec: 61338.05
2024-06-15 09:26:25,184 train.py step   619 | loss: 4.512337 | lr 5.2028e-04 | norm: 0.9853 | dt: 85521.44ms | tok/sec: 61304.86
2024-06-15 09:27:50,730 train.py step   620 | loss: 4.564234 | lr 5.2112e-04 | norm: 0.9230 | dt: 85544.78ms | tok/sec: 61288.13
2024-06-15 09:29:16,209 train.py step   621 | loss: 4.515797 | lr 5.2196e-04 | norm: 0.7790 | dt: 85479.40ms | tok/sec: 61335.01
2024-06-15 09:30:41,740 train.py step   622 | loss: 4.494311 | lr 5.2280e-04 | norm: 0.8714 | dt: 85530.24ms | tok/sec: 61298.55
2024-06-15 09:32:07,252 train.py step   623 | loss: 4.435884 | lr 5.2364e-04 | norm: 0.9467 | dt: 85511.38ms | tok/sec: 61312.07
2024-06-15 09:33:32,765 train.py step   624 | loss: 4.536515 | lr 5.2448e-04 | norm: 0.9396 | dt: 85513.17ms | tok/sec: 61310.79
2024-06-15 09:34:58,312 train.py step   625 | loss: 4.551354 | lr 5.2531e-04 | norm: 0.9787 | dt: 85545.96ms | tok/sec: 61287.29
2024-06-15 09:36:23,802 train.py step   626 | loss: 4.515944 | lr 5.2615e-04 | norm: 0.8669 | dt: 85489.57ms | tok/sec: 61327.72
2024-06-15 09:37:49,284 train.py step   627 | loss: 4.444840 | lr 5.2699e-04 | norm: 0.7654 | dt: 85482.28ms | tok/sec: 61332.94
2024-06-15 09:39:14,751 train.py step   628 | loss: 4.424314 | lr 5.2783e-04 | norm: 0.7758 | dt: 85466.36ms | tok/sec: 61344.37
2024-06-15 09:40:40,259 train.py step   629 | loss: 4.566473 | lr 5.2867e-04 | norm: 0.8289 | dt: 85508.10ms | tok/sec: 61314.42
2024-06-15 09:42:05,744 train.py step   630 | loss: 4.548063 | lr 5.2951e-04 | norm: 0.8779 | dt: 85483.99ms | tok/sec: 61331.71
2024-06-15 09:43:31,244 train.py step   631 | loss: 4.496582 | lr 5.3035e-04 | norm: 0.8665 | dt: 85499.98ms | tok/sec: 61320.25
2024-06-15 09:44:56,727 train.py step   632 | loss: 4.441772 | lr 5.3119e-04 | norm: 0.7901 | dt: 85481.86ms | tok/sec: 61333.25
2024-06-15 09:46:22,245 train.py step   633 | loss: 4.392444 | lr 5.3203e-04 | norm: 0.9315 | dt: 85518.10ms | tok/sec: 61307.26
2024-06-15 09:47:47,731 train.py step   634 | loss: 4.547436 | lr 5.3287e-04 | norm: 1.0150 | dt: 85486.00ms | tok/sec: 61330.27
2024-06-15 09:49:13,233 train.py step   635 | loss: 4.525941 | lr 5.3371e-04 | norm: 0.9652 | dt: 85501.31ms | tok/sec: 61319.29
2024-06-15 09:50:38,723 train.py step   636 | loss: 4.495361 | lr 5.3455e-04 | norm: 0.9533 | dt: 85489.84ms | tok/sec: 61327.52
2024-06-15 09:52:04,215 train.py step   637 | loss: 4.435274 | lr 5.3538e-04 | norm: 0.9207 | dt: 85491.34ms | tok/sec: 61326.44
2024-06-15 09:53:29,667 train.py step   638 | loss: 4.456882 | lr 5.3622e-04 | norm: 1.0234 | dt: 85451.34ms | tok/sec: 61355.15
2024-06-15 09:54:55,134 train.py step   639 | loss: 4.529236 | lr 5.3706e-04 | norm: 0.8775 | dt: 85467.10ms | tok/sec: 61343.84
2024-06-15 09:56:20,572 train.py step   640 | loss: 4.485215 | lr 5.3790e-04 | norm: 0.9753 | dt: 85437.49ms | tok/sec: 61365.10
2024-06-15 09:57:46,031 train.py step   641 | loss: 4.472363 | lr 5.3874e-04 | norm: 1.1331 | dt: 85458.79ms | tok/sec: 61349.80
2024-06-15 09:59:11,482 train.py step   642 | loss: 4.413580 | lr 5.3958e-04 | norm: 0.9704 | dt: 85450.44ms | tok/sec: 61355.80
2024-06-15 10:00:36,977 train.py step   643 | loss: 4.495610 | lr 5.4042e-04 | norm: 0.9711 | dt: 85494.92ms | tok/sec: 61323.88
2024-06-15 10:02:02,467 train.py step   644 | loss: 4.510827 | lr 5.4126e-04 | norm: 0.8915 | dt: 85489.40ms | tok/sec: 61327.84
2024-06-15 10:03:27,919 train.py step   645 | loss: 4.475482 | lr 5.4210e-04 | norm: 0.8171 | dt: 85451.26ms | tok/sec: 61355.21
2024-06-15 10:04:53,338 train.py step   646 | loss: 4.404317 | lr 5.4294e-04 | norm: 0.8077 | dt: 85419.13ms | tok/sec: 61378.29
2024-06-15 10:06:18,807 train.py step   647 | loss: 4.379992 | lr 5.4378e-04 | norm: 0.9093 | dt: 85468.44ms | tok/sec: 61342.87
2024-06-15 10:07:44,289 train.py step   648 | loss: 4.528462 | lr 5.4462e-04 | norm: 0.9323 | dt: 85481.34ms | tok/sec: 61333.62
2024-06-15 10:09:09,776 train.py step   649 | loss: 4.513923 | lr 5.4545e-04 | norm: 0.8323 | dt: 85486.83ms | tok/sec: 61329.68
2024-06-15 10:10:35,246 train.py step   650 | loss: 4.455426 | lr 5.4629e-04 | norm: 0.8235 | dt: 85469.72ms | tok/sec: 61341.96
2024-06-15 10:12:00,713 train.py step   651 | loss: 4.402910 | lr 5.4713e-04 | norm: 0.8050 | dt: 85466.00ms | tok/sec: 61344.63
2024-06-15 10:13:26,172 train.py step   652 | loss: 4.341210 | lr 5.4797e-04 | norm: 0.8596 | dt: 85458.73ms | tok/sec: 61349.85
2024-06-15 10:14:51,639 train.py step   653 | loss: 4.485268 | lr 5.4881e-04 | norm: 0.9345 | dt: 85466.58ms | tok/sec: 61344.21
2024-06-15 10:16:17,133 train.py step   654 | loss: 4.461298 | lr 5.4965e-04 | norm: 0.8922 | dt: 85493.64ms | tok/sec: 61324.80
2024-06-15 10:17:42,595 train.py step   655 | loss: 4.445718 | lr 5.5049e-04 | norm: 0.8899 | dt: 85462.32ms | tok/sec: 61347.27
2024-06-15 10:19:08,041 train.py step   656 | loss: 4.380711 | lr 5.5133e-04 | norm: 0.9077 | dt: 85445.52ms | tok/sec: 61359.33
2024-06-15 10:20:33,480 train.py step   657 | loss: 4.381248 | lr 5.5217e-04 | norm: 0.8310 | dt: 85438.02ms | tok/sec: 61364.72
2024-06-15 10:21:58,930 train.py step   658 | loss: 4.469526 | lr 5.5301e-04 | norm: 0.7806 | dt: 85450.18ms | tok/sec: 61355.99
2024-06-15 10:23:24,425 train.py step   659 | loss: 4.419451 | lr 5.5385e-04 | norm: 0.7583 | dt: 85494.22ms | tok/sec: 61324.38
2024-06-15 10:24:49,884 train.py step   660 | loss: 4.395822 | lr 5.5469e-04 | norm: 0.7301 | dt: 85458.21ms | tok/sec: 61350.22
2024-06-15 10:26:15,345 train.py step   661 | loss: 4.327780 | lr 5.5552e-04 | norm: 0.6988 | dt: 85460.91ms | tok/sec: 61348.28
2024-06-15 10:27:40,808 train.py step   662 | loss: 4.393319 | lr 5.5636e-04 | norm: 0.6520 | dt: 85462.74ms | tok/sec: 61346.97
2024-06-15 10:29:06,284 train.py step   663 | loss: 4.425136 | lr 5.5720e-04 | norm: 0.5836 | dt: 85475.41ms | tok/sec: 61337.87
2024-06-15 10:30:31,737 train.py step   664 | loss: 4.386085 | lr 5.5804e-04 | norm: 0.5445 | dt: 85452.50ms | tok/sec: 61354.32
2024-06-15 10:31:57,187 train.py step   665 | loss: 4.320455 | lr 5.5888e-04 | norm: 0.5739 | dt: 85450.34ms | tok/sec: 61355.87
2024-06-15 10:33:22,677 train.py step   666 | loss: 4.283525 | lr 5.5972e-04 | norm: 0.7385 | dt: 85489.63ms | tok/sec: 61327.67
2024-06-15 10:34:48,177 train.py step   667 | loss: 4.446968 | lr 5.6056e-04 | norm: 0.9840 | dt: 85498.88ms | tok/sec: 61321.04
2024-06-15 10:36:13,648 train.py step   668 | loss: 4.461537 | lr 5.6140e-04 | norm: 1.1017 | dt: 85470.97ms | tok/sec: 61341.06
2024-06-15 10:37:39,112 train.py step   669 | loss: 4.418055 | lr 5.6224e-04 | norm: 1.0069 | dt: 85464.07ms | tok/sec: 61346.01
2024-06-15 10:39:04,561 train.py step   670 | loss: 4.377043 | lr 5.6308e-04 | norm: 1.0112 | dt: 85448.64ms | tok/sec: 61357.09
2024-06-15 10:40:29,992 train.py step   671 | loss: 4.329167 | lr 5.6392e-04 | norm: 1.1227 | dt: 85430.35ms | tok/sec: 61370.23
2024-06-15 10:41:55,422 train.py step   672 | loss: 4.444787 | lr 5.6476e-04 | norm: 0.9966 | dt: 85429.50ms | tok/sec: 61370.84
2024-06-15 10:43:20,860 train.py step   673 | loss: 4.432052 | lr 5.6559e-04 | norm: 1.0581 | dt: 85437.13ms | tok/sec: 61365.36
2024-06-15 10:44:46,255 train.py step   674 | loss: 4.432293 | lr 5.6643e-04 | norm: 1.0061 | dt: 85395.53ms | tok/sec: 61395.25
2024-06-15 10:46:11,685 train.py step   675 | loss: 4.369000 | lr 5.6727e-04 | norm: 0.9916 | dt: 85429.23ms | tok/sec: 61371.04
2024-06-15 10:47:37,082 train.py step   676 | loss: 4.352243 | lr 5.6811e-04 | norm: 1.0413 | dt: 85396.41ms | tok/sec: 61394.62
2024-06-15 10:49:02,479 train.py step   677 | loss: 4.459949 | lr 5.6895e-04 | norm: 0.9473 | dt: 85396.84ms | tok/sec: 61394.31
2024-06-15 10:50:27,871 train.py step   678 | loss: 4.420028 | lr 5.6979e-04 | norm: 1.1533 | dt: 85391.64ms | tok/sec: 61398.05
2024-06-15 10:51:53,252 train.py step   679 | loss: 4.412016 | lr 5.7063e-04 | norm: 1.0790 | dt: 85380.70ms | tok/sec: 61405.91
2024-06-15 10:53:18,674 train.py step   680 | loss: 4.362930 | lr 5.7147e-04 | norm: 1.2644 | dt: 85421.08ms | tok/sec: 61376.89
2024-06-15 10:54:44,133 train.py step   681 | loss: 4.412273 | lr 5.7231e-04 | norm: 1.0612 | dt: 85458.90ms | tok/sec: 61349.73
2024-06-15 10:56:09,580 train.py step   682 | loss: 4.449695 | lr 5.7315e-04 | norm: 0.9551 | dt: 85446.68ms | tok/sec: 61358.50
2024-06-15 10:57:35,009 train.py step   683 | loss: 4.410053 | lr 5.7399e-04 | norm: 0.8561 | dt: 85428.81ms | tok/sec: 61371.33
2024-06-15 10:59:00,446 train.py step   684 | loss: 4.337346 | lr 5.7483e-04 | norm: 0.7363 | dt: 85436.43ms | tok/sec: 61365.86
2024-06-15 11:00:25,887 train.py step   685 | loss: 4.272280 | lr 5.7566e-04 | norm: 0.7050 | dt: 85440.25ms | tok/sec: 61363.12
2024-06-15 11:01:51,317 train.py step   686 | loss: 4.413028 | lr 5.7650e-04 | norm: 0.6838 | dt: 85430.51ms | tok/sec: 61370.11
2024-06-15 11:03:16,764 train.py step   687 | loss: 4.415467 | lr 5.7734e-04 | norm: 0.6766 | dt: 85446.40ms | tok/sec: 61358.70
2024-06-15 11:04:42,195 train.py step   688 | loss: 4.361402 | lr 5.7818e-04 | norm: 0.6919 | dt: 85430.62ms | tok/sec: 61370.03
2024-06-15 11:06:07,608 train.py step   689 | loss: 4.308159 | lr 5.7902e-04 | norm: 0.6569 | dt: 85412.74ms | tok/sec: 61382.88
2024-06-15 11:07:33,030 train.py step   690 | loss: 4.244348 | lr 5.7986e-04 | norm: 0.7118 | dt: 85420.96ms | tok/sec: 61376.97
2024-06-15 11:08:58,449 train.py step   691 | loss: 4.363495 | lr 5.8070e-04 | norm: 0.8267 | dt: 85418.70ms | tok/sec: 61378.60
2024-06-15 11:10:23,858 train.py step   692 | loss: 4.354997 | lr 5.8154e-04 | norm: 0.7926 | dt: 85408.88ms | tok/sec: 61385.66
2024-06-15 11:11:49,267 train.py step   693 | loss: 4.356276 | lr 5.8238e-04 | norm: 0.7832 | dt: 85408.85ms | tok/sec: 61385.68
2024-06-15 11:13:14,703 train.py step   694 | loss: 4.291639 | lr 5.8322e-04 | norm: 0.7682 | dt: 85435.10ms | tok/sec: 61366.82
2024-06-15 11:14:40,127 train.py step   695 | loss: 4.243768 | lr 5.8406e-04 | norm: 0.7568 | dt: 85424.02ms | tok/sec: 61374.78
2024-06-15 11:16:05,564 train.py step   696 | loss: 4.368741 | lr 5.8490e-04 | norm: 0.6971 | dt: 85436.36ms | tok/sec: 61365.91
2024-06-15 11:17:30,991 train.py step   697 | loss: 4.321287 | lr 5.8573e-04 | norm: 0.6766 | dt: 85426.64ms | tok/sec: 61372.89
2024-06-15 11:18:56,447 train.py step   698 | loss: 4.297683 | lr 5.8657e-04 | norm: 0.7030 | dt: 85455.35ms | tok/sec: 61352.27
2024-06-15 11:20:21,890 train.py step   699 | loss: 4.256233 | lr 5.8741e-04 | norm: 0.8349 | dt: 85442.85ms | tok/sec: 61361.25
2024-06-15 11:21:47,352 train.py step   700 | loss: 4.303021 | lr 5.8825e-04 | norm: 0.8487 | dt: 85461.95ms | tok/sec: 61347.54
2024-06-15 11:23:12,837 train.py step   701 | loss: 4.364387 | lr 5.8909e-04 | norm: 0.8769 | dt: 85484.31ms | tok/sec: 61331.49
2024-06-15 11:24:38,261 train.py step   702 | loss: 4.340950 | lr 5.8993e-04 | norm: 0.9460 | dt: 85423.73ms | tok/sec: 61374.98
2024-06-15 11:26:03,710 train.py step   703 | loss: 4.291212 | lr 5.9077e-04 | norm: 0.9901 | dt: 85448.50ms | tok/sec: 61357.19
2024-06-15 11:27:29,177 train.py step   704 | loss: 4.240433 | lr 5.9161e-04 | norm: 1.0713 | dt: 85466.78ms | tok/sec: 61344.07
2024-06-15 11:28:54,635 train.py step   705 | loss: 4.364287 | lr 5.9245e-04 | norm: 0.8967 | dt: 85457.73ms | tok/sec: 61350.56
2024-06-15 11:30:20,113 train.py step   706 | loss: 4.374821 | lr 5.9329e-04 | norm: 0.7129 | dt: 85477.75ms | tok/sec: 61336.20
2024-06-15 11:31:45,586 train.py step   707 | loss: 4.329872 | lr 5.9413e-04 | norm: 0.7941 | dt: 85471.98ms | tok/sec: 61340.34
2024-06-15 11:33:11,050 train.py step   708 | loss: 4.281768 | lr 5.9497e-04 | norm: 0.9836 | dt: 85464.35ms | tok/sec: 61345.81
2024-06-15 11:34:36,529 train.py step   709 | loss: 4.254586 | lr 5.9580e-04 | norm: 1.1015 | dt: 85478.59ms | tok/sec: 61335.59
2024-06-15 11:36:02,004 train.py step   710 | loss: 4.333348 | lr 5.9664e-04 | norm: 0.9039 | dt: 85474.05ms | tok/sec: 61338.85
2024-06-15 11:37:27,478 train.py step   711 | loss: 4.343783 | lr 5.9748e-04 | norm: 0.9412 | dt: 85473.96ms | tok/sec: 61338.92
2024-06-15 11:38:52,946 train.py step   712 | loss: 4.333430 | lr 5.9832e-04 | norm: 0.8358 | dt: 85467.57ms | tok/sec: 61343.50
2024-06-15 11:40:18,439 train.py step   713 | loss: 4.284400 | lr 5.9916e-04 | norm: 0.8606 | dt: 85492.60ms | tok/sec: 61325.54
2024-06-15 11:41:43,950 train.py step   714 | loss: 4.217067 | lr 6.0000e-04 | norm: 0.8295 | dt: 85510.46ms | tok/sec: 61312.73
2024-06-15 11:43:09,431 train.py step   715 | loss: 4.361297 | lr 6.0000e-04 | norm: 0.8609 | dt: 85480.86ms | tok/sec: 61333.96
2024-06-15 11:44:34,928 train.py step   716 | loss: 4.309791 | lr 6.0000e-05 | norm: 0.8240 | dt: 85496.31ms | tok/sec: 61322.88
2024-06-15 11:46:00,436 train.py step   717 | loss: 4.280128 | lr 6.0000e-05 | norm: 0.6794 | dt: 85507.59ms | tok/sec: 61314.79
2024-06-15 11:47:25,959 train.py step   718 | loss: 4.197175 | lr 6.0000e-05 | norm: 0.4513 | dt: 85522.74ms | tok/sec: 61303.93
2024-06-15 11:48:51,488 train.py step   719 | loss: 4.219168 | lr 6.0000e-05 | norm: 0.3020 | dt: 85528.35ms | tok/sec: 61299.91
2024-06-15 11:50:17,029 train.py step   720 | loss: 4.277564 | lr 6.0000e-05 | norm: 0.3778 | dt: 85541.02ms | tok/sec: 61290.83
2024-06-15 11:51:42,560 train.py step   721 | loss: 4.254111 | lr 6.0000e-05 | norm: 0.4108 | dt: 85530.11ms | tok/sec: 61298.65
2024-06-15 11:53:08,090 train.py step   722 | loss: 4.185894 | lr 6.0000e-05 | norm: 0.4076 | dt: 85529.56ms | tok/sec: 61299.04
2024-06-15 11:54:33,628 train.py step   723 | loss: 4.120842 | lr 6.0000e-05 | norm: 0.3627 | dt: 85538.26ms | tok/sec: 61292.80
2024-06-15 11:55:59,145 train.py step   724 | loss: 4.238279 | lr 6.0000e-05 | norm: 0.3300 | dt: 85516.83ms | tok/sec: 61308.17
2024-06-15 11:57:24,638 train.py step   725 | loss: 4.277940 | lr 6.0000e-05 | norm: 0.3101 | dt: 85492.63ms | tok/sec: 61325.52
2024-06-15 11:58:50,128 train.py step   726 | loss: 4.221678 | lr 6.0000e-05 | norm: 0.3016 | dt: 85488.84ms | tok/sec: 61328.24
2024-06-15 12:00:15,595 train.py step   727 | loss: 4.155742 | lr 6.0000e-05 | norm: 0.2892 | dt: 85467.14ms | tok/sec: 61343.81
2024-06-15 12:01:41,100 train.py step   728 | loss: 4.120114 | lr 6.0000e-05 | norm: 0.2745 | dt: 85504.58ms | tok/sec: 61316.95
2024-06-15 12:03:06,604 train.py step   729 | loss: 4.188868 | lr 6.0000e-05 | norm: 0.2690 | dt: 85503.43ms | tok/sec: 61317.77
2024-06-15 12:04:32,130 train.py step   730 | loss: 4.205224 | lr 6.0000e-05 | norm: 0.2517 | dt: 85525.93ms | tok/sec: 61301.64
2024-06-15 12:05:57,636 train.py step   731 | loss: 4.215408 | lr 6.0000e-05 | norm: 0.2305 | dt: 85505.94ms | tok/sec: 61315.97
2024-06-15 12:07:23,145 train.py step   732 | loss: 4.161861 | lr 6.0000e-05 | norm: 0.2137 | dt: 85507.97ms | tok/sec: 61314.52
2024-06-15 12:08:48,648 train.py step   733 | loss: 4.089341 | lr 6.0000e-05 | norm: 0.2124 | dt: 85502.79ms | tok/sec: 61318.23
2024-06-15 12:10:14,152 train.py step   734 | loss: 4.236193 | lr 6.0000e-05 | norm: 0.2207 | dt: 85503.88ms | tok/sec: 61317.45
2024-06-15 12:11:39,654 train.py step   735 | loss: 4.205379 | lr 6.0000e-05 | norm: 0.2078 | dt: 85500.97ms | tok/sec: 61319.54
2024-06-15 12:13:05,161 train.py step   736 | loss: 4.176103 | lr 6.0000e-05 | norm: 0.1907 | dt: 85506.55ms | tok/sec: 61315.54
2024-06-15 12:14:30,647 train.py step   737 | loss: 4.120577 | lr 6.0000e-05 | norm: 0.1966 | dt: 85486.21ms | tok/sec: 61330.12
2024-06-15 12:15:56,148 train.py step   738 | loss: 4.152631 | lr 6.0000e-05 | norm: 0.1765 | dt: 85500.84ms | tok/sec: 61319.63
2024-06-15 12:17:21,617 train.py step   739 | loss: 4.220323 | lr 6.0000e-05 | norm: 0.1813 | dt: 85468.19ms | tok/sec: 61343.05
2024-06-15 12:18:47,117 train.py step   740 | loss: 4.196492 | lr 6.0000e-05 | norm: 0.1644 | dt: 85499.70ms | tok/sec: 61320.45
2024-06-15 12:20:12,581 train.py step   741 | loss: 4.130476 | lr 6.0000e-05 | norm: 0.1647 | dt: 85463.22ms | tok/sec: 61346.62
2024-06-15 12:21:38,026 train.py step   742 | loss: 4.072083 | lr 6.0000e-05 | norm: 0.1748 | dt: 85444.95ms | tok/sec: 61359.74
2024-06-15 12:23:03,500 train.py step   743 | loss: 4.175472 | lr 6.0000e-05 | norm: 0.1578 | dt: 85473.59ms | tok/sec: 61339.18
2024-06-15 12:24:28,991 train.py step   744 | loss: 4.234398 | lr 6.0000e-05 | norm: 0.1641 | dt: 85490.94ms | tok/sec: 61326.74
2024-06-15 12:25:54,473 train.py step   745 | loss: 4.174689 | lr 6.0000e-05 | norm: 0.1581 | dt: 85481.74ms | tok/sec: 61333.33
2024-06-15 12:27:19,931 train.py step   746 | loss: 4.124117 | lr 6.0000e-05 | norm: 0.1537 | dt: 85457.44ms | tok/sec: 61350.77
2024-06-15 12:28:45,385 train.py step   747 | loss: 4.085532 | lr 6.0000e-05 | norm: 0.1688 | dt: 85453.01ms | tok/sec: 61353.96
2024-06-15 12:30:10,821 train.py step   748 | loss: 4.137108 | lr 6.0000e-05 | norm: 0.1498 | dt: 85436.20ms | tok/sec: 61366.03
2024-06-15 12:31:36,252 train.py step   749 | loss: 4.175887 | lr 6.0000e-05 | norm: 0.1521 | dt: 85430.17ms | tok/sec: 61370.36
2024-06-15 12:31:38,512 train.py validation loss: 4.3328
2024-06-15 12:33:04,953 train.py step   750 | loss: 4.182088 | lr 6.0000e-05 | norm: 0.1445 | dt: 88701.33ms | tok/sec: 59107.12
2024-06-15 12:34:30,397 train.py step   751 | loss: 4.128869 | lr 6.0000e-05 | norm: 0.1338 | dt: 85443.14ms | tok/sec: 61361.04
2024-06-15 12:35:55,873 train.py step   752 | loss: 4.058372 | lr 6.0000e-05 | norm: 0.1509 | dt: 85476.15ms | tok/sec: 61337.35
2024-06-15 12:37:21,360 train.py step   753 | loss: 4.194180 | lr 6.0000e-05 | norm: 0.1433 | dt: 85485.94ms | tok/sec: 61330.32
2024-06-15 12:38:46,829 train.py step   754 | loss: 4.172822 | lr 6.0000e-05 | norm: 0.1371 | dt: 85468.64ms | tok/sec: 61342.73
2024-06-15 12:40:12,305 train.py step   755 | loss: 4.146314 | lr 6.0000e-05 | norm: 0.1216 | dt: 85475.57ms | tok/sec: 61337.76
2024-06-15 12:41:37,759 train.py step   756 | loss: 4.093528 | lr 6.0000e-05 | norm: 0.1409 | dt: 85453.54ms | tok/sec: 61353.57
2024-06-15 12:43:03,228 train.py step   757 | loss: 4.109880 | lr 6.0000e-05 | norm: 0.1323 | dt: 85468.83ms | tok/sec: 61342.60
2024-06-15 12:44:28,679 train.py step   758 | loss: 4.194651 | lr 6.0000e-05 | norm: 0.1463 | dt: 85450.54ms | tok/sec: 61355.73
2024-06-15 12:45:54,097 train.py step   759 | loss: 4.169298 | lr 6.0000e-05 | norm: 0.1299 | dt: 85417.34ms | tok/sec: 61379.58
2024-06-15 12:47:19,522 train.py step   760 | loss: 4.112284 | lr 6.0000e-05 | norm: 0.1324 | dt: 85424.49ms | tok/sec: 61374.44
2024-06-15 12:48:44,982 train.py step   761 | loss: 4.044180 | lr 6.0000e-05 | norm: 0.1520 | dt: 85459.87ms | tok/sec: 61349.03
2024-06-15 12:50:10,442 train.py step   762 | loss: 4.138775 | lr 6.0000e-05 | norm: 0.1299 | dt: 85459.37ms | tok/sec: 61349.38
2024-06-15 12:51:35,921 train.py step   763 | loss: 4.213630 | lr 6.0000e-05 | norm: 0.1642 | dt: 85479.24ms | tok/sec: 61335.12
2024-06-15 12:53:01,371 train.py step   764 | loss: 4.151909 | lr 6.0000e-05 | norm: 0.1413 | dt: 85449.03ms | tok/sec: 61356.81
2024-06-15 12:54:26,813 train.py step   765 | loss: 4.100480 | lr 6.0000e-05 | norm: 0.1566 | dt: 85442.09ms | tok/sec: 61361.79
2024-06-15 12:55:52,288 train.py step   766 | loss: 4.062909 | lr 6.0000e-05 | norm: 0.1745 | dt: 85474.64ms | tok/sec: 61338.43
2024-06-15 12:57:17,733 train.py step   767 | loss: 4.102144 | lr 6.0000e-05 | norm: 0.1485 | dt: 85444.45ms | tok/sec: 61360.10
2024-06-15 12:58:43,152 train.py step   768 | loss: 4.163249 | lr 6.0000e-05 | norm: 0.1760 | dt: 85418.84ms | tok/sec: 61378.50
2024-06-15 13:00:08,554 train.py step   769 | loss: 4.156019 | lr 6.0000e-05 | norm: 0.1496 | dt: 85401.83ms | tok/sec: 61390.73
2024-06-15 13:01:34,013 train.py step   770 | loss: 4.109112 | lr 6.0000e-05 | norm: 0.1610 | dt: 85458.19ms | tok/sec: 61350.23
2024-06-15 13:02:59,464 train.py step   771 | loss: 4.034140 | lr 6.0000e-05 | norm: 0.1779 | dt: 85450.42ms | tok/sec: 61355.82
2024-06-15 13:04:24,911 train.py step   772 | loss: 4.160903 | lr 6.0000e-05 | norm: 0.1731 | dt: 85447.04ms | tok/sec: 61358.24
2024-06-15 13:05:50,384 train.py step   773 | loss: 4.153718 | lr 6.0000e-05 | norm: 0.1870 | dt: 85473.00ms | tok/sec: 61339.60
2024-06-15 13:07:15,840 train.py step   774 | loss: 4.126736 | lr 6.0000e-05 | norm: 0.1505 | dt: 85454.88ms | tok/sec: 61352.61
2024-06-15 13:08:41,269 train.py step   775 | loss: 4.075017 | lr 6.0000e-05 | norm: 0.2009 | dt: 85429.24ms | tok/sec: 61371.02
2024-06-15 13:10:06,707 train.py step   776 | loss: 4.073805 | lr 6.0000e-05 | norm: 0.1503 | dt: 85437.49ms | tok/sec: 61365.10
2024-06-15 13:11:32,141 train.py step   777 | loss: 4.178961 | lr 6.0000e-05 | norm: 0.2053 | dt: 85433.63ms | tok/sec: 61367.87
2024-06-15 13:12:57,567 train.py step   778 | loss: 4.140167 | lr 6.0000e-05 | norm: 0.1586 | dt: 85425.15ms | tok/sec: 61373.96
2024-06-15 13:14:23,003 train.py step   779 | loss: 4.096288 | lr 6.0000e-05 | norm: 0.1890 | dt: 85436.16ms | tok/sec: 61366.06
2024-06-15 13:15:48,458 train.py step   780 | loss: 4.028924 | lr 6.0000e-05 | norm: 0.1964 | dt: 85454.80ms | tok/sec: 61352.67
2024-06-15 13:17:13,932 train.py step   781 | loss: 4.108380 | lr 6.0000e-05 | norm: 0.1751 | dt: 85473.53ms | tok/sec: 61339.22
2024-06-15 13:18:39,425 train.py step   782 | loss: 4.189336 | lr 6.0000e-05 | norm: 0.2119 | dt: 85492.01ms | tok/sec: 61325.96
2024-06-15 13:20:04,891 train.py step   783 | loss: 4.131828 | lr 6.0000e-05 | norm: 0.1635 | dt: 85466.21ms | tok/sec: 61344.48
2024-06-15 13:21:30,383 train.py step   784 | loss: 4.083544 | lr 6.0000e-05 | norm: 0.2100 | dt: 85491.61ms | tok/sec: 61326.25
2024-06-15 13:22:55,810 train.py step   785 | loss: 4.043166 | lr 6.0000e-05 | norm: 0.1885 | dt: 85425.94ms | tok/sec: 61373.40
2024-06-15 13:24:21,246 train.py step   786 | loss: 4.071621 | lr 6.0000e-05 | norm: 0.1875 | dt: 85435.95ms | tok/sec: 61366.21
2024-06-15 13:25:46,704 train.py step   787 | loss: 4.146455 | lr 6.0000e-05 | norm: 0.2139 | dt: 85457.80ms | tok/sec: 61350.52
2024-06-15 13:27:12,194 train.py step   788 | loss: 4.132063 | lr 6.0000e-05 | norm: 0.1690 | dt: 85489.68ms | tok/sec: 61327.64
2024-06-15 13:28:37,683 train.py step   789 | loss: 4.093264 | lr 6.0000e-05 | norm: 0.2138 | dt: 85488.23ms | tok/sec: 61328.68
2024-06-15 13:30:03,153 train.py step   790 | loss: 4.012403 | lr 6.0000e-05 | norm: 0.1887 | dt: 85470.05ms | tok/sec: 61341.72
2024-06-15 13:31:28,613 train.py step   791 | loss: 4.127863 | lr 6.0000e-05 | norm: 0.2215 | dt: 85459.07ms | tok/sec: 61349.60
2024-06-15 13:32:54,078 train.py step   792 | loss: 4.135952 | lr 6.0000e-05 | norm: 0.2127 | dt: 85465.33ms | tok/sec: 61345.11
2024-06-15 13:34:19,529 train.py step   793 | loss: 4.103658 | lr 6.0000e-05 | norm: 0.1912 | dt: 85449.86ms | tok/sec: 61356.21
2024-06-15 13:35:44,952 train.py step   794 | loss: 4.062827 | lr 6.0000e-05 | norm: 0.2298 | dt: 85422.49ms | tok/sec: 61375.87
2024-06-15 13:37:10,408 train.py step   795 | loss: 4.036216 | lr 6.0000e-05 | norm: 0.1829 | dt: 85456.34ms | tok/sec: 61351.56
2024-06-15 13:38:35,850 train.py step   796 | loss: 4.161670 | lr 6.0000e-05 | norm: 0.2485 | dt: 85441.62ms | tok/sec: 61362.13
2024-06-15 13:40:01,268 train.py step   797 | loss: 4.118268 | lr 6.0000e-05 | norm: 0.1929 | dt: 85417.51ms | tok/sec: 61379.45
2024-06-15 13:41:26,723 train.py step   798 | loss: 4.082708 | lr 6.0000e-05 | norm: 0.2093 | dt: 85454.76ms | tok/sec: 61352.70
2024-06-15 13:42:52,210 train.py step   799 | loss: 4.010005 | lr 6.0000e-05 | norm: 0.2202 | dt: 85485.92ms | tok/sec: 61330.34
2024-06-15 13:44:17,671 train.py step   800 | loss: 4.075294 | lr 6.0000e-05 | norm: 0.1882 | dt: 85460.96ms | tok/sec: 61348.25
2024-06-15 13:45:43,146 train.py step   801 | loss: 4.163331 | lr 6.0000e-05 | norm: 0.2236 | dt: 85474.22ms | tok/sec: 61338.73
2024-06-15 13:47:08,652 train.py step   802 | loss: 4.114552 | lr 6.0000e-05 | norm: 0.1924 | dt: 85506.34ms | tok/sec: 61315.68
2024-06-15 13:48:34,170 train.py step   803 | loss: 4.067438 | lr 6.0000e-05 | norm: 0.2113 | dt: 85517.39ms | tok/sec: 61307.76
2024-06-15 13:49:59,646 train.py step   804 | loss: 4.026395 | lr 6.0000e-05 | norm: 0.2128 | dt: 85475.48ms | tok/sec: 61337.82
2024-06-15 13:51:25,117 train.py step   805 | loss: 4.039622 | lr 6.0000e-05 | norm: 0.1958 | dt: 85470.36ms | tok/sec: 61341.50
2024-06-15 13:52:50,576 train.py step   806 | loss: 4.124649 | lr 6.0000e-05 | norm: 0.2250 | dt: 85459.55ms | tok/sec: 61349.26
2024-06-15 13:54:16,042 train.py step   807 | loss: 4.114276 | lr 6.0000e-05 | norm: 0.1910 | dt: 85464.97ms | tok/sec: 61345.36
2024-06-15 13:55:41,497 train.py step   808 | loss: 4.069767 | lr 6.0000e-05 | norm: 0.2173 | dt: 85454.97ms | tok/sec: 61352.55
2024-06-15 13:57:06,938 train.py step   809 | loss: 4.000926 | lr 6.0000e-05 | norm: 0.2162 | dt: 85440.49ms | tok/sec: 61362.94
2024-06-15 13:58:32,405 train.py step   810 | loss: 4.091870 | lr 6.0000e-05 | norm: 0.2050 | dt: 85466.58ms | tok/sec: 61344.21
2024-06-15 13:59:57,875 train.py step   811 | loss: 4.117848 | lr 6.0000e-05 | norm: 0.2363 | dt: 85469.28ms | tok/sec: 61342.28
2024-06-15 14:01:23,339 train.py step   812 | loss: 4.082162 | lr 6.0000e-05 | norm: 0.2014 | dt: 85463.63ms | tok/sec: 61346.33
2024-06-15 14:02:48,800 train.py step   813 | loss: 4.042470 | lr 6.0000e-05 | norm: 0.2212 | dt: 85460.31ms | tok/sec: 61348.71
2024-06-15 14:04:14,250 train.py step   814 | loss: 4.008112 | lr 6.0000e-05 | norm: 0.2067 | dt: 85450.06ms | tok/sec: 61356.07
2024-06-15 14:05:39,673 train.py step   815 | loss: 4.140258 | lr 6.0000e-05 | norm: 0.2344 | dt: 85422.21ms | tok/sec: 61376.08
2024-06-15 14:07:05,080 train.py step   816 | loss: 4.102242 | lr 6.0000e-05 | norm: 0.2098 | dt: 85407.01ms | tok/sec: 61387.00
2024-06-15 14:08:30,505 train.py step   817 | loss: 4.060776 | lr 6.0000e-05 | norm: 0.2040 | dt: 85424.85ms | tok/sec: 61374.18
2024-06-15 14:09:55,986 train.py step   818 | loss: 3.997577 | lr 6.0000e-05 | norm: 0.2314 | dt: 85480.92ms | tok/sec: 61333.92
2024-06-15 14:11:21,467 train.py step   819 | loss: 4.034166 | lr 6.0000e-05 | norm: 0.1989 | dt: 85480.17ms | tok/sec: 61334.46
2024-06-15 14:12:46,925 train.py step   820 | loss: 4.146399 | lr 6.0000e-05 | norm: 0.2111 | dt: 85457.47ms | tok/sec: 61350.75
2024-06-15 14:14:12,363 train.py step   821 | loss: 4.108690 | lr 6.0000e-05 | norm: 0.2231 | dt: 85437.95ms | tok/sec: 61364.77
2024-06-15 14:15:37,858 train.py step   822 | loss: 4.036669 | lr 6.0000e-05 | norm: 0.1956 | dt: 85494.36ms | tok/sec: 61324.28
2024-06-15 14:17:03,324 train.py step   823 | loss: 4.009017 | lr 6.0000e-05 | norm: 0.2150 | dt: 85465.29ms | tok/sec: 61345.14
2024-06-15 14:18:28,808 train.py step   824 | loss: 4.007849 | lr 6.0000e-05 | norm: 0.2129 | dt: 85484.00ms | tok/sec: 61331.71
2024-06-15 14:19:54,323 train.py step   825 | loss: 4.106762 | lr 6.0000e-05 | norm: 0.2146 | dt: 85514.55ms | tok/sec: 61309.80
2024-06-15 14:21:19,817 train.py step   826 | loss: 4.094934 | lr 6.0000e-05 | norm: 0.2195 | dt: 85493.55ms | tok/sec: 61324.86
2024-06-15 14:22:45,300 train.py step   827 | loss: 4.050423 | lr 6.0000e-05 | norm: 0.2225 | dt: 85482.39ms | tok/sec: 61332.86
2024-06-15 14:24:10,763 train.py step   828 | loss: 3.985549 | lr 6.0000e-05 | norm: 0.2269 | dt: 85462.90ms | tok/sec: 61346.85
2024-06-15 14:25:36,249 train.py step   829 | loss: 4.057116 | lr 6.0000e-05 | norm: 0.2166 | dt: 85485.28ms | tok/sec: 61330.79
2024-06-15 14:27:01,722 train.py step   830 | loss: 4.102271 | lr 6.0000e-05 | norm: 0.2250 | dt: 85472.73ms | tok/sec: 61339.80
2024-06-15 14:28:27,218 train.py step   831 | loss: 4.061560 | lr 6.0000e-05 | norm: 0.2387 | dt: 85495.54ms | tok/sec: 61323.43
2024-06-15 14:29:52,685 train.py step   832 | loss: 4.029830 | lr 6.0000e-05 | norm: 0.2142 | dt: 85467.21ms | tok/sec: 61343.76
2024-06-15 14:31:18,161 train.py step   833 | loss: 3.975855 | lr 6.0000e-05 | norm: 0.2135 | dt: 85474.68ms | tok/sec: 61338.40
2024-06-15 14:32:43,639 train.py step   834 | loss: 4.114981 | lr 6.0000e-05 | norm: 0.2504 | dt: 85478.01ms | tok/sec: 61336.01
2024-06-15 14:34:09,122 train.py step   835 | loss: 4.084729 | lr 6.0000e-05 | norm: 0.2157 | dt: 85482.75ms | tok/sec: 61332.60
2024-06-15 14:35:34,647 train.py step   836 | loss: 4.046970 | lr 6.0000e-05 | norm: 0.2321 | dt: 85524.69ms | tok/sec: 61302.53
2024-06-15 14:37:00,216 train.py step   837 | loss: 3.981072 | lr 6.0000e-05 | norm: 0.2476 | dt: 85568.60ms | tok/sec: 61271.07
2024-06-15 14:38:26,003 train.py step   838 | loss: 4.003613 | lr 6.0000e-05 | norm: 0.2203 | dt: 85786.73ms | tok/sec: 61115.28
2024-06-15 14:39:51,820 train.py step   839 | loss: 4.121425 | lr 6.0000e-05 | norm: 0.2314 | dt: 85815.86ms | tok/sec: 61094.53
2024-06-15 14:41:17,311 train.py step   840 | loss: 4.088212 | lr 6.0000e-05 | norm: 0.2341 | dt: 85491.40ms | tok/sec: 61326.40
2024-06-15 14:42:42,775 train.py step   841 | loss: 4.027043 | lr 6.0000e-05 | norm: 0.2260 | dt: 85463.64ms | tok/sec: 61346.32
2024-06-15 14:44:08,270 train.py step   842 | loss: 3.991881 | lr 6.0000e-05 | norm: 0.2268 | dt: 85494.06ms | tok/sec: 61324.49
2024-06-15 14:45:33,796 train.py step   843 | loss: 3.978420 | lr 6.0000e-05 | norm: 0.2352 | dt: 85525.43ms | tok/sec: 61302.00
2024-06-15 14:46:59,343 train.py step   844 | loss: 4.090049 | lr 6.0000e-05 | norm: 0.2405 | dt: 85546.71ms | tok/sec: 61286.75
2024-06-15 14:48:24,893 train.py step   845 | loss: 4.073082 | lr 6.0000e-05 | norm: 0.2489 | dt: 85550.16ms | tok/sec: 61284.28
2024-06-15 14:49:50,453 train.py step   846 | loss: 4.034737 | lr 6.0000e-05 | norm: 0.2616 | dt: 85559.43ms | tok/sec: 61277.64
2024-06-15 14:51:15,995 train.py step   847 | loss: 3.971756 | lr 6.0000e-05 | norm: 0.2482 | dt: 85541.30ms | tok/sec: 61290.63
2024-06-15 14:52:41,498 train.py step   848 | loss: 4.034641 | lr 6.0000e-05 | norm: 0.2463 | dt: 85502.92ms | tok/sec: 61318.14
2024-06-15 14:54:07,009 train.py step   849 | loss: 4.080472 | lr 6.0000e-05 | norm: 0.2425 | dt: 85509.71ms | tok/sec: 61313.27
2024-06-15 14:55:32,510 train.py step   850 | loss: 4.039844 | lr 6.0000e-05 | norm: 0.2477 | dt: 85501.06ms | tok/sec: 61319.47
2024-06-15 14:56:58,058 train.py step   851 | loss: 4.015562 | lr 6.0000e-05 | norm: 0.2406 | dt: 85547.39ms | tok/sec: 61286.26
2024-06-15 14:58:23,568 train.py step   852 | loss: 3.954395 | lr 6.0000e-05 | norm: 0.2462 | dt: 85509.31ms | tok/sec: 61313.56
2024-06-15 14:59:49,082 train.py step   853 | loss: 4.083106 | lr 6.0000e-05 | norm: 0.2711 | dt: 85513.84ms | tok/sec: 61310.31
2024-06-15 15:01:14,663 train.py step   854 | loss: 4.070107 | lr 6.0000e-05 | norm: 0.2460 | dt: 85580.85ms | tok/sec: 61262.30
2024-06-15 15:02:40,226 train.py step   855 | loss: 4.032748 | lr 6.0000e-05 | norm: 0.2706 | dt: 85561.98ms | tok/sec: 61275.81
2024-06-15 15:04:05,772 train.py step   856 | loss: 3.971966 | lr 6.0000e-05 | norm: 0.2465 | dt: 85545.72ms | tok/sec: 61287.46
2024-06-15 15:05:31,304 train.py step   857 | loss: 3.971621 | lr 6.0000e-05 | norm: 0.2532 | dt: 85531.25ms | tok/sec: 61297.83
2024-06-15 15:06:56,876 train.py step   858 | loss: 4.099800 | lr 6.0000e-05 | norm: 0.2622 | dt: 85571.61ms | tok/sec: 61268.92
2024-06-15 15:08:22,415 train.py step   859 | loss: 4.077080 | lr 6.0000e-05 | norm: 0.2724 | dt: 85538.38ms | tok/sec: 61292.72
2024-06-15 15:09:48,004 train.py step   860 | loss: 4.007868 | lr 6.0000e-05 | norm: 0.2541 | dt: 85588.77ms | tok/sec: 61256.63
2024-06-15 15:11:14,935 train.py step   861 | loss: 3.985064 | lr 6.0000e-05 | norm: 0.2466 | dt: 86930.04ms | tok/sec: 60311.48
2024-06-15 15:12:41,127 train.py step   862 | loss: 3.943733 | lr 6.0000e-05 | norm: 0.2616 | dt: 86191.70ms | tok/sec: 60828.13
2024-06-15 15:14:06,669 train.py step   863 | loss: 4.076254 | lr 6.0000e-05 | norm: 0.2580 | dt: 85541.69ms | tok/sec: 61290.35
2024-06-15 15:15:32,236 train.py step   864 | loss: 4.050070 | lr 6.0000e-05 | norm: 0.2707 | dt: 85566.68ms | tok/sec: 61272.45
2024-06-15 15:16:57,786 train.py step   865 | loss: 4.020296 | lr 6.0000e-05 | norm: 0.2791 | dt: 85549.54ms | tok/sec: 61284.72
2024-06-15 15:18:23,351 train.py step   866 | loss: 3.960411 | lr 6.0000e-05 | norm: 0.2565 | dt: 85565.23ms | tok/sec: 61273.49
2024-06-15 15:19:48,887 train.py step   867 | loss: 4.008237 | lr 6.0000e-05 | norm: 0.2519 | dt: 85535.73ms | tok/sec: 61294.62
2024-06-15 15:21:14,369 train.py step   868 | loss: 4.057840 | lr 6.0000e-05 | norm: 0.2767 | dt: 85480.99ms | tok/sec: 61333.87
2024-06-15 15:22:39,881 train.py step   869 | loss: 4.024544 | lr 6.0000e-05 | norm: 0.2633 | dt: 85511.31ms | tok/sec: 61312.13
2024-06-15 15:24:05,368 train.py step   870 | loss: 4.002391 | lr 6.0000e-05 | norm: 0.2690 | dt: 85487.16ms | tok/sec: 61329.44
2024-06-15 15:25:30,886 train.py step   871 | loss: 3.938079 | lr 6.0000e-05 | norm: 0.2577 | dt: 85517.80ms | tok/sec: 61307.47
2024-06-15 15:26:56,427 train.py step   872 | loss: 4.054724 | lr 6.0000e-05 | norm: 0.2816 | dt: 85540.37ms | tok/sec: 61291.30
2024-06-15 15:28:21,896 train.py step   873 | loss: 4.050097 | lr 6.0000e-05 | norm: 0.2486 | dt: 85469.03ms | tok/sec: 61342.45
2024-06-15 15:29:47,404 train.py step   874 | loss: 4.021604 | lr 6.0000e-05 | norm: 0.2923 | dt: 85507.22ms | tok/sec: 61315.06
2024-06-15 15:31:12,872 train.py step   875 | loss: 3.957687 | lr 6.0000e-05 | norm: 0.2530 | dt: 85467.84ms | tok/sec: 61343.30
2024-06-15 15:32:38,339 train.py step   876 | loss: 3.947043 | lr 6.0000e-05 | norm: 0.2463 | dt: 85465.87ms | tok/sec: 61344.72
2024-06-15 15:34:03,806 train.py step   877 | loss: 4.079907 | lr 6.0000e-05 | norm: 0.2903 | dt: 85467.32ms | tok/sec: 61343.68
2024-06-15 15:35:29,272 train.py step   878 | loss: 4.056495 | lr 6.0000e-05 | norm: 0.2377 | dt: 85465.59ms | tok/sec: 61344.92
2024-06-15 15:36:54,697 train.py step   879 | loss: 4.000515 | lr 6.0000e-05 | norm: 0.2712 | dt: 85424.50ms | tok/sec: 61374.43
2024-06-15 15:38:20,116 train.py step   880 | loss: 3.974328 | lr 6.0000e-05 | norm: 0.2608 | dt: 85418.16ms | tok/sec: 61378.99
2024-06-15 15:39:45,547 train.py step   881 | loss: 3.911149 | lr 6.0000e-05 | norm: 0.2475 | dt: 85430.48ms | tok/sec: 61370.13
2024-06-15 15:41:10,958 train.py step   882 | loss: 4.060533 | lr 6.0000e-05 | norm: 0.3046 | dt: 85411.22ms | tok/sec: 61383.97
2024-06-15 15:42:36,352 train.py step   883 | loss: 4.028454 | lr 6.0000e-05 | norm: 0.2823 | dt: 85392.82ms | tok/sec: 61397.20
2024-06-15 15:44:01,736 train.py step   884 | loss: 4.013313 | lr 6.0000e-05 | norm: 0.2880 | dt: 85384.30ms | tok/sec: 61403.33
2024-06-15 15:45:27,146 train.py step   885 | loss: 3.945019 | lr 6.0000e-05 | norm: 0.2792 | dt: 85409.11ms | tok/sec: 61385.49
2024-06-15 15:46:52,598 train.py step   886 | loss: 3.981061 | lr 6.0000e-05 | norm: 0.2714 | dt: 85451.69ms | tok/sec: 61354.90
2024-06-15 15:48:18,071 train.py step   887 | loss: 4.045618 | lr 6.0000e-05 | norm: 0.3037 | dt: 85472.16ms | tok/sec: 61340.21
2024-06-15 15:49:43,529 train.py step   888 | loss: 4.006797 | lr 6.0000e-05 | norm: 0.2832 | dt: 85458.22ms | tok/sec: 61350.22
2024-06-15 15:51:08,962 train.py step   889 | loss: 3.987225 | lr 6.0000e-05 | norm: 0.2900 | dt: 85432.15ms | tok/sec: 61368.93
2024-06-15 15:52:34,382 train.py step   890 | loss: 3.926793 | lr 6.0000e-05 | norm: 0.2887 | dt: 85419.70ms | tok/sec: 61377.88
2024-06-15 15:53:59,753 train.py step   891 | loss: 4.019999 | lr 6.0000e-05 | norm: 0.2663 | dt: 85370.27ms | tok/sec: 61413.42
2024-06-15 15:55:25,174 train.py step   892 | loss: 4.035495 | lr 6.0000e-05 | norm: 0.2768 | dt: 85421.13ms | tok/sec: 61376.85
2024-06-15 15:56:50,595 train.py step   893 | loss: 4.009108 | lr 6.0000e-05 | norm: 0.2762 | dt: 85420.77ms | tok/sec: 61377.11
2024-06-15 15:58:16,032 train.py step   894 | loss: 3.943304 | lr 6.0000e-05 | norm: 0.2697 | dt: 85436.61ms | tok/sec: 61365.73
2024-06-15 15:59:41,479 train.py step   895 | loss: 3.926698 | lr 6.0000e-05 | norm: 0.2880 | dt: 85445.83ms | tok/sec: 61359.11
2024-06-15 16:01:06,947 train.py step   896 | loss: 4.056895 | lr 6.0000e-05 | norm: 0.2594 | dt: 85468.19ms | tok/sec: 61343.05
2024-06-15 16:02:32,422 train.py step   897 | loss: 4.046787 | lr 6.0000e-05 | norm: 0.2673 | dt: 85474.16ms | tok/sec: 61338.77
2024-06-15 16:03:57,895 train.py step   898 | loss: 3.988087 | lr 6.0000e-05 | norm: 0.2858 | dt: 85472.74ms | tok/sec: 61339.79
2024-06-15 16:05:23,350 train.py step   899 | loss: 3.956242 | lr 6.0000e-05 | norm: 0.2554 | dt: 85454.83ms | tok/sec: 61352.65
2024-06-15 16:06:48,837 train.py step   900 | loss: 3.893460 | lr 6.0000e-05 | norm: 0.2806 | dt: 85486.05ms | tok/sec: 61330.24
2024-06-15 16:08:14,315 train.py step   901 | loss: 4.037498 | lr 6.0000e-05 | norm: 0.2970 | dt: 85478.33ms | tok/sec: 61335.78
2024-06-15 16:09:39,782 train.py step   902 | loss: 4.013229 | lr 6.0000e-05 | norm: 0.2780 | dt: 85466.86ms | tok/sec: 61344.01
2024-06-15 16:11:05,240 train.py step   903 | loss: 3.996710 | lr 6.0000e-05 | norm: 0.2982 | dt: 85457.27ms | tok/sec: 61350.89
2024-06-15 16:12:30,698 train.py step   904 | loss: 3.937605 | lr 6.0000e-05 | norm: 0.2891 | dt: 85457.00ms | tok/sec: 61351.09
2024-06-15 16:13:56,166 train.py step   905 | loss: 3.949808 | lr 6.0000e-05 | norm: 0.2776 | dt: 85468.21ms | tok/sec: 61343.04
2024-06-15 16:15:21,648 train.py step   906 | loss: 4.034720 | lr 6.0000e-05 | norm: 0.2852 | dt: 85481.38ms | tok/sec: 61333.59
2024-06-15 16:16:47,090 train.py step   907 | loss: 3.990026 | lr 6.0000e-05 | norm: 0.2991 | dt: 85442.05ms | tok/sec: 61361.82
2024-06-15 16:18:12,536 train.py step   908 | loss: 3.972408 | lr 6.0000e-05 | norm: 0.3109 | dt: 85444.84ms | tok/sec: 61359.82
2024-06-15 16:19:37,992 train.py step   909 | loss: 3.916507 | lr 6.0000e-05 | norm: 0.2708 | dt: 85455.87ms | tok/sec: 61351.90
2024-06-15 16:21:03,465 train.py step   910 | loss: 3.992149 | lr 6.0000e-05 | norm: 0.2912 | dt: 85472.66ms | tok/sec: 61339.85
2024-06-15 16:22:28,949 train.py step   911 | loss: 4.025168 | lr 6.0000e-05 | norm: 0.3102 | dt: 85483.98ms | tok/sec: 61331.73
2024-06-15 16:23:54,434 train.py step   912 | loss: 3.995643 | lr 6.0000e-05 | norm: 0.3250 | dt: 85484.18ms | tok/sec: 61331.58
2024-06-15 16:25:19,914 train.py step   913 | loss: 3.930825 | lr 6.0000e-05 | norm: 0.3013 | dt: 85479.94ms | tok/sec: 61334.63
2024-06-15 16:26:45,404 train.py step   914 | loss: 3.897300 | lr 6.0000e-05 | norm: 0.2876 | dt: 85489.61ms | tok/sec: 61327.69
2024-06-15 16:28:10,875 train.py step   915 | loss: 4.036374 | lr 6.0000e-05 | norm: 0.3064 | dt: 85469.73ms | tok/sec: 61341.95
2024-06-15 16:29:36,381 train.py step   916 | loss: 4.037315 | lr 6.0000e-05 | norm: 0.3141 | dt: 85506.58ms | tok/sec: 61315.51
2024-06-15 16:31:01,871 train.py step   917 | loss: 3.979971 | lr 6.0000e-05 | norm: 0.3051 | dt: 85488.66ms | tok/sec: 61328.37
2024-06-15 16:32:27,342 train.py step   918 | loss: 3.943734 | lr 6.0000e-05 | norm: 0.3164 | dt: 85470.84ms | tok/sec: 61341.16
2024-06-15 16:33:52,810 train.py step   919 | loss: 3.876220 | lr 6.0000e-05 | norm: 0.2978 | dt: 85467.91ms | tok/sec: 61343.26
2024-06-15 16:35:18,298 train.py step   920 | loss: 4.013530 | lr 6.0000e-05 | norm: 0.3139 | dt: 85487.40ms | tok/sec: 61329.27
2024-06-15 16:36:43,782 train.py step   921 | loss: 3.990384 | lr 6.0000e-05 | norm: 0.3207 | dt: 85483.80ms | tok/sec: 61331.86
2024-06-15 16:38:09,262 train.py step   922 | loss: 3.993204 | lr 6.0000e-05 | norm: 0.3100 | dt: 85479.90ms | tok/sec: 61334.65
2024-06-15 16:39:34,718 train.py step   923 | loss: 3.926039 | lr 6.0000e-05 | norm: 0.3014 | dt: 85455.09ms | tok/sec: 61352.46
2024-06-15 16:41:00,177 train.py step   924 | loss: 3.921940 | lr 6.0000e-05 | norm: 0.2752 | dt: 85458.59ms | tok/sec: 61349.95
2024-06-15 16:42:25,663 train.py step   925 | loss: 4.018412 | lr 6.0000e-05 | norm: 0.3193 | dt: 85485.34ms | tok/sec: 61330.75
2024-06-15 16:43:51,151 train.py step   926 | loss: 3.976505 | lr 6.0000e-05 | norm: 0.3424 | dt: 85487.62ms | tok/sec: 61329.11
2024-06-15 16:45:16,625 train.py step   927 | loss: 3.960353 | lr 6.0000e-05 | norm: 0.2808 | dt: 85473.94ms | tok/sec: 61338.93
2024-06-15 16:46:42,079 train.py step   928 | loss: 3.903972 | lr 6.0000e-05 | norm: 0.2726 | dt: 85453.39ms | tok/sec: 61353.68
2024-06-15 16:48:07,515 train.py step   929 | loss: 3.970286 | lr 6.0000e-05 | norm: 0.3091 | dt: 85435.86ms | tok/sec: 61366.27
2024-06-15 16:49:32,958 train.py step   930 | loss: 4.009033 | lr 6.0000e-05 | norm: 0.2878 | dt: 85442.86ms | tok/sec: 61361.24
2024-06-15 16:50:58,400 train.py step   931 | loss: 3.979907 | lr 6.0000e-05 | norm: 0.3214 | dt: 85441.22ms | tok/sec: 61362.42
2024-06-15 16:52:23,853 train.py step   932 | loss: 3.922866 | lr 6.0000e-05 | norm: 0.3155 | dt: 85452.40ms | tok/sec: 61354.39
2024-06-15 16:53:49,340 train.py step   933 | loss: 3.874698 | lr 6.0000e-05 | norm: 0.3039 | dt: 85486.69ms | tok/sec: 61329.78
2024-06-15 16:55:14,832 train.py step   934 | loss: 4.017259 | lr 6.0000e-05 | norm: 0.3166 | dt: 85491.38ms | tok/sec: 61326.42
2024-06-15 16:56:40,295 train.py step   935 | loss: 4.022103 | lr 6.0000e-05 | norm: 0.3228 | dt: 85462.94ms | tok/sec: 61346.83
2024-06-15 16:58:05,761 train.py step   936 | loss: 3.967865 | lr 6.0000e-05 | norm: 0.3602 | dt: 85465.24ms | tok/sec: 61345.17
2024-06-15 16:59:31,209 train.py step   937 | loss: 3.933016 | lr 6.0000e-05 | norm: 0.3066 | dt: 85448.07ms | tok/sec: 61357.50
2024-06-15 17:00:56,686 train.py step   938 | loss: 3.863549 | lr 6.0000e-05 | norm: 0.3026 | dt: 85477.10ms | tok/sec: 61336.66
2024-06-15 17:02:22,144 train.py step   939 | loss: 3.986689 | lr 6.0000e-05 | norm: 0.3564 | dt: 85457.18ms | tok/sec: 61350.96
2024-06-15 17:03:47,595 train.py step   940 | loss: 3.975001 | lr 6.0000e-05 | norm: 0.3270 | dt: 85450.28ms | tok/sec: 61355.92
2024-06-15 17:05:13,069 train.py step   941 | loss: 3.981404 | lr 6.0000e-05 | norm: 0.3316 | dt: 85473.89ms | tok/sec: 61338.97
2024-06-15 17:06:38,558 train.py step   942 | loss: 3.919365 | lr 6.0000e-05 | norm: 0.3115 | dt: 85487.80ms | tok/sec: 61328.99
2024-06-15 17:08:04,040 train.py step   943 | loss: 3.891356 | lr 6.0000e-05 | norm: 0.3057 | dt: 85481.60ms | tok/sec: 61333.43
2024-06-15 17:09:29,505 train.py step   944 | loss: 4.007353 | lr 6.0000e-05 | norm: 0.3379 | dt: 85465.23ms | tok/sec: 61345.18
2024-06-15 17:10:54,964 train.py step   945 | loss: 3.963313 | lr 6.0000e-05 | norm: 0.3003 | dt: 85458.58ms | tok/sec: 61349.96
2024-06-15 17:12:20,454 train.py step   946 | loss: 3.946402 | lr 6.0000e-05 | norm: 0.3058 | dt: 85489.85ms | tok/sec: 61327.51
2024-06-15 17:13:45,923 train.py step   947 | loss: 3.894265 | lr 6.0000e-05 | norm: 0.3144 | dt: 85468.20ms | tok/sec: 61343.05
2024-06-15 17:15:11,397 train.py step   948 | loss: 3.949691 | lr 6.0000e-05 | norm: 0.3462 | dt: 85473.27ms | tok/sec: 61339.41
2024-06-15 17:16:36,863 train.py step   949 | loss: 3.992868 | lr 6.0000e-05 | norm: 0.3197 | dt: 85466.17ms | tok/sec: 61344.51
2024-06-15 17:18:02,328 train.py step   950 | loss: 3.969600 | lr 6.0000e-05 | norm: 0.3283 | dt: 85464.19ms | tok/sec: 61345.93
2024-06-15 17:19:27,748 train.py step   951 | loss: 3.914530 | lr 6.0000e-05 | norm: 0.3442 | dt: 85419.34ms | tok/sec: 61378.14
2024-06-15 17:20:53,209 train.py step   952 | loss: 3.855790 | lr 6.0000e-05 | norm: 0.3192 | dt: 85460.31ms | tok/sec: 61348.71
2024-06-15 17:22:18,666 train.py step   953 | loss: 3.996449 | lr 6.0000e-05 | norm: 0.3597 | dt: 85456.94ms | tok/sec: 61351.13
2024-06-15 17:23:44,087 train.py step   954 | loss: 4.007768 | lr 6.0000e-05 | norm: 0.3265 | dt: 85420.46ms | tok/sec: 61377.34
2024-06-15 17:25:09,536 train.py step   955 | loss: 3.953835 | lr 6.0000e-05 | norm: 0.3312 | dt: 85447.92ms | tok/sec: 61357.61
2024-06-15 17:26:34,987 train.py step   956 | loss: 3.922801 | lr 6.0000e-05 | norm: 0.3078 | dt: 85451.24ms | tok/sec: 61355.22
2024-06-15 17:28:00,473 train.py step   957 | loss: 3.853598 | lr 6.0000e-05 | norm: 0.3426 | dt: 85485.08ms | tok/sec: 61330.94
2024-06-15 17:29:25,962 train.py step   958 | loss: 3.964362 | lr 6.0000e-05 | norm: 0.3572 | dt: 85488.45ms | tok/sec: 61328.52
2024-06-15 17:30:51,466 train.py step   959 | loss: 3.959087 | lr 6.0000e-05 | norm: 0.3194 | dt: 85502.94ms | tok/sec: 61318.12
2024-06-15 17:32:16,967 train.py step   960 | loss: 3.970330 | lr 6.0000e-05 | norm: 0.3351 | dt: 85500.70ms | tok/sec: 61319.73
2024-06-15 17:33:42,454 train.py step   961 | loss: 3.910639 | lr 6.0000e-05 | norm: 0.3067 | dt: 85486.34ms | tok/sec: 61330.03
2024-06-15 17:35:07,890 train.py step   962 | loss: 3.864644 | lr 6.0000e-05 | norm: 0.3270 | dt: 85436.38ms | tok/sec: 61365.89
2024-06-15 17:36:33,349 train.py step   963 | loss: 3.993798 | lr 6.0000e-05 | norm: 0.3564 | dt: 85458.32ms | tok/sec: 61350.14
2024-06-15 17:37:58,826 train.py step   964 | loss: 3.950934 | lr 6.0000e-05 | norm: 0.3044 | dt: 85476.59ms | tok/sec: 61337.03
2024-06-15 17:39:24,252 train.py step   965 | loss: 3.936748 | lr 6.0000e-05 | norm: 0.3370 | dt: 85425.63ms | tok/sec: 61373.62
2024-06-15 17:40:49,693 train.py step   966 | loss: 3.880428 | lr 6.0000e-05 | norm: 0.3186 | dt: 85439.71ms | tok/sec: 61363.50
2024-06-15 17:42:15,172 train.py step   967 | loss: 3.928336 | lr 6.0000e-05 | norm: 0.3291 | dt: 85479.29ms | tok/sec: 61335.09
2024-06-15 17:43:40,647 train.py step   968 | loss: 3.984348 | lr 6.0000e-05 | norm: 0.3401 | dt: 85474.61ms | tok/sec: 61338.45
2024-06-15 17:45:06,118 train.py step   969 | loss: 3.960248 | lr 6.0000e-05 | norm: 0.3212 | dt: 85470.54ms | tok/sec: 61341.37
2024-06-15 17:46:31,608 train.py step   970 | loss: 3.901397 | lr 6.0000e-05 | norm: 0.3170 | dt: 85488.85ms | tok/sec: 61328.23
2024-06-15 17:47:57,113 train.py step   971 | loss: 3.839188 | lr 6.0000e-05 | norm: 0.3242 | dt: 85504.52ms | tok/sec: 61316.99
2024-06-15 17:49:22,587 train.py step   972 | loss: 3.968607 | lr 6.0000e-05 | norm: 0.3360 | dt: 85474.05ms | tok/sec: 61338.85
2024-06-15 17:50:48,058 train.py step   973 | loss: 3.999829 | lr 6.0000e-05 | norm: 0.3252 | dt: 85470.01ms | tok/sec: 61341.75
2024-06-15 17:52:13,514 train.py step   974 | loss: 3.948656 | lr 6.0000e-05 | norm: 0.3095 | dt: 85455.51ms | tok/sec: 61352.16
2024-06-15 17:53:38,979 train.py step   975 | loss: 3.902814 | lr 6.0000e-05 | norm: 0.3024 | dt: 85464.13ms | tok/sec: 61345.97
2024-06-15 17:55:04,470 train.py step   976 | loss: 3.847218 | lr 6.0000e-05 | norm: 0.3308 | dt: 85491.15ms | tok/sec: 61326.58
2024-06-15 17:56:29,969 train.py step   977 | loss: 3.936218 | lr 6.0000e-05 | norm: 0.3268 | dt: 85497.84ms | tok/sec: 61321.78
2024-06-15 17:57:55,448 train.py step   978 | loss: 3.946368 | lr 6.0000e-05 | norm: 0.3488 | dt: 85478.90ms | tok/sec: 61335.37
2024-06-15 17:59:20,930 train.py step   979 | loss: 3.955465 | lr 6.0000e-05 | norm: 0.3661 | dt: 85481.09ms | tok/sec: 61333.80
2024-06-15 18:00:46,453 train.py step   980 | loss: 3.904119 | lr 6.0000e-05 | norm: 0.3930 | dt: 85522.66ms | tok/sec: 61303.99
2024-06-15 18:02:11,987 train.py step   981 | loss: 3.844632 | lr 6.0000e-05 | norm: 0.4313 | dt: 85534.10ms | tok/sec: 61295.79
2024-06-15 18:03:37,512 train.py step   982 | loss: 3.979528 | lr 6.0000e-05 | norm: 0.4336 | dt: 85523.73ms | tok/sec: 61303.22
2024-06-15 18:05:03,080 train.py step   983 | loss: 3.938712 | lr 6.0000e-05 | norm: 0.3823 | dt: 85567.90ms | tok/sec: 61271.58
2024-06-15 18:06:28,643 train.py step   984 | loss: 3.924022 | lr 6.0000e-05 | norm: 0.3469 | dt: 85562.20ms | tok/sec: 61275.66
2024-06-15 18:07:54,153 train.py step   985 | loss: 3.867707 | lr 6.0000e-05 | norm: 0.3358 | dt: 85509.17ms | tok/sec: 61313.66
2024-06-15 18:09:19,667 train.py step   986 | loss: 3.907803 | lr 6.0000e-05 | norm: 0.3511 | dt: 85513.93ms | tok/sec: 61310.24
2024-06-15 18:10:45,156 train.py step   987 | loss: 3.969708 | lr 6.0000e-05 | norm: 0.3321 | dt: 85488.19ms | tok/sec: 61328.70
2024-06-15 18:12:10,662 train.py step   988 | loss: 3.951635 | lr 6.0000e-05 | norm: 0.3524 | dt: 85505.08ms | tok/sec: 61316.59
2024-06-15 18:13:36,181 train.py step   989 | loss: 3.889250 | lr 6.0000e-05 | norm: 0.3172 | dt: 85519.05ms | tok/sec: 61306.57
2024-06-15 18:15:01,722 train.py step   990 | loss: 3.825458 | lr 6.0000e-05 | norm: 0.3169 | dt: 85539.80ms | tok/sec: 61291.70
2024-06-15 18:16:27,234 train.py step   991 | loss: 3.943552 | lr 6.0000e-05 | norm: 0.3759 | dt: 85512.32ms | tok/sec: 61311.40
2024-06-15 18:17:52,763 train.py step   992 | loss: 3.992648 | lr 6.0000e-05 | norm: 0.3154 | dt: 85527.95ms | tok/sec: 61300.20
2024-06-15 18:19:18,254 train.py step   993 | loss: 3.935551 | lr 6.0000e-05 | norm: 0.3539 | dt: 85490.79ms | tok/sec: 61326.84
2024-06-15 18:20:43,747 train.py step   994 | loss: 3.882721 | lr 6.0000e-05 | norm: 0.3490 | dt: 85491.78ms | tok/sec: 61326.13
2024-06-15 18:22:09,252 train.py step   995 | loss: 3.845505 | lr 6.0000e-05 | norm: 0.3458 | dt: 85504.70ms | tok/sec: 61316.86
2024-06-15 18:23:34,775 train.py step   996 | loss: 3.911913 | lr 6.0000e-05 | norm: 0.3560 | dt: 85523.29ms | tok/sec: 61303.53
2024-06-15 18:25:00,298 train.py step   997 | loss: 3.931655 | lr 6.0000e-05 | norm: 0.3360 | dt: 85522.41ms | tok/sec: 61304.16
2024-06-15 18:26:25,829 train.py step   998 | loss: 3.947439 | lr 6.0000e-05 | norm: 0.3537 | dt: 85530.36ms | tok/sec: 61298.47
2024-06-15 18:27:51,335 train.py step   999 | loss: 3.897397 | lr 6.0000e-05 | norm: 0.3625 | dt: 85505.96ms | tok/sec: 61315.96
2024-06-15 18:27:53,515 train.py validation loss: 4.1223
2024-06-15 18:29:19,969 train.py step  1000 | loss: 3.818489 | lr 6.0000e-05 | norm: 0.3013 | dt: 88632.53ms | tok/sec: 59153.00
2024-06-15 18:30:45,478 train.py step  1001 | loss: 3.962817 | lr 6.0000e-05 | norm: 0.3719 | dt: 85508.93ms | tok/sec: 61313.83
2024-06-15 18:32:10,973 train.py step  1002 | loss: 3.934810 | lr 6.0000e-05 | norm: 0.3517 | dt: 85494.88ms | tok/sec: 61323.90
2024-06-15 18:33:36,450 train.py step  1003 | loss: 3.908986 | lr 6.0000e-05 | norm: 0.3683 | dt: 85476.72ms | tok/sec: 61336.93
2024-06-15 18:35:01,939 train.py step  1004 | loss: 3.854499 | lr 6.0000e-05 | norm: 0.3623 | dt: 85487.73ms | tok/sec: 61329.03
2024-06-15 18:36:27,422 train.py step  1005 | loss: 3.889000 | lr 6.0000e-05 | norm: 0.3602 | dt: 85483.20ms | tok/sec: 61332.28
2024-06-15 18:37:52,940 train.py step  1006 | loss: 3.960855 | lr 6.0000e-05 | norm: 0.4096 | dt: 85517.77ms | tok/sec: 61307.49
2024-06-15 18:39:18,401 train.py step  1007 | loss: 3.939979 | lr 6.0000e-05 | norm: 0.3938 | dt: 85460.05ms | tok/sec: 61348.90
2024-06-15 18:40:43,844 train.py step  1008 | loss: 3.877797 | lr 6.0000e-05 | norm: 0.3882 | dt: 85442.68ms | tok/sec: 61361.37
2024-06-15 18:42:09,308 train.py step  1009 | loss: 3.818446 | lr 6.0000e-05 | norm: 0.4521 | dt: 85463.81ms | tok/sec: 61346.20
2024-06-15 18:43:34,765 train.py step  1010 | loss: 3.918821 | lr 6.0000e-05 | norm: 0.4476 | dt: 85456.49ms | tok/sec: 61351.46
2024-06-15 18:45:00,219 train.py step  1011 | loss: 3.982906 | lr 6.0000e-05 | norm: 0.4232 | dt: 85453.43ms | tok/sec: 61353.65
2024-06-15 18:46:25,702 train.py step  1012 | loss: 3.920552 | lr 6.0000e-05 | norm: 0.3949 | dt: 85482.47ms | tok/sec: 61332.81
2024-06-15 18:47:51,185 train.py step  1013 | loss: 3.879505 | lr 6.0000e-05 | norm: 0.3502 | dt: 85483.42ms | tok/sec: 61332.13
2024-06-15 18:49:16,659 train.py step  1014 | loss: 3.833295 | lr 6.0000e-05 | norm: 0.3620 | dt: 85472.87ms | tok/sec: 61339.70
2024-06-15 18:50:42,123 train.py step  1015 | loss: 3.888264 | lr 6.0000e-05 | norm: 0.3719 | dt: 85463.84ms | tok/sec: 61346.18
2024-06-15 18:52:07,572 train.py step  1016 | loss: 3.925552 | lr 6.0000e-05 | norm: 0.3504 | dt: 85448.91ms | tok/sec: 61356.90
2024-06-15 18:53:33,015 train.py step  1017 | loss: 3.934444 | lr 6.0000e-05 | norm: 0.3765 | dt: 85442.28ms | tok/sec: 61361.66
2024-06-15 18:54:58,482 train.py step  1018 | loss: 3.884913 | lr 6.0000e-05 | norm: 0.3408 | dt: 85466.45ms | tok/sec: 61344.30
2024-06-15 18:56:23,936 train.py step  1019 | loss: 3.810293 | lr 6.0000e-05 | norm: 0.3226 | dt: 85453.53ms | tok/sec: 61353.58
2024-06-15 18:57:49,408 train.py step  1020 | loss: 3.940247 | lr 6.0000e-05 | norm: 0.3560 | dt: 85471.99ms | tok/sec: 61340.33
2024-06-15 18:59:14,824 train.py step  1021 | loss: 3.922802 | lr 6.0000e-05 | norm: 0.3297 | dt: 85415.44ms | tok/sec: 61380.94
2024-06-15 19:00:40,273 train.py step  1022 | loss: 3.898710 | lr 6.0000e-05 | norm: 0.3528 | dt: 85448.35ms | tok/sec: 61357.30
2024-06-15 19:02:05,732 train.py step  1023 | loss: 3.847427 | lr 6.0000e-05 | norm: 0.3861 | dt: 85459.54ms | tok/sec: 61349.26
2024-06-15 19:03:31,174 train.py step  1024 | loss: 3.863861 | lr 6.0000e-05 | norm: 0.3946 | dt: 85440.77ms | tok/sec: 61362.74
2024-06-15 19:04:56,600 train.py step  1025 | loss: 3.950804 | lr 6.0000e-05 | norm: 0.4082 | dt: 85425.94ms | tok/sec: 61373.40
2024-06-15 19:06:22,046 train.py step  1026 | loss: 3.926068 | lr 6.0000e-05 | norm: 0.3738 | dt: 85446.15ms | tok/sec: 61358.88
2024-06-15 19:07:47,487 train.py step  1027 | loss: 3.874289 | lr 6.0000e-05 | norm: 0.3382 | dt: 85440.51ms | tok/sec: 61362.93
2024-06-15 19:09:12,898 train.py step  1028 | loss: 3.803735 | lr 6.0000e-05 | norm: 0.3354 | dt: 85410.40ms | tok/sec: 61384.56
2024-06-15 19:10:38,320 train.py step  1029 | loss: 3.893702 | lr 6.0000e-05 | norm: 0.3533 | dt: 85421.96ms | tok/sec: 61376.26
2024-06-15 19:12:03,758 train.py step  1030 | loss: 3.973302 | lr 6.0000e-05 | norm: 0.3857 | dt: 85437.07ms | tok/sec: 61365.40
2024-06-15 19:13:29,226 train.py step  1031 | loss: 3.908027 | lr 6.0000e-05 | norm: 0.3624 | dt: 85468.17ms | tok/sec: 61343.07
2024-06-15 19:14:54,707 train.py step  1032 | loss: 3.866829 | lr 6.0000e-05 | norm: 0.3681 | dt: 85480.09ms | tok/sec: 61334.52
2024-06-15 19:16:20,175 train.py step  1033 | loss: 3.824864 | lr 6.0000e-05 | norm: 0.3593 | dt: 85468.03ms | tok/sec: 61343.17
2024-06-15 19:17:45,637 train.py step  1034 | loss: 3.863690 | lr 6.0000e-05 | norm: 0.3783 | dt: 85461.80ms | tok/sec: 61347.65
2024-06-15 19:19:11,102 train.py step  1035 | loss: 3.923587 | lr 6.0000e-05 | norm: 0.3435 | dt: 85464.54ms | tok/sec: 61345.68
2024-06-15 19:20:36,581 train.py step  1036 | loss: 3.917306 | lr 6.0000e-05 | norm: 0.3137 | dt: 85478.82ms | tok/sec: 61335.43
2024-06-15 19:22:02,065 train.py step  1037 | loss: 3.876739 | lr 6.0000e-05 | norm: 0.3518 | dt: 85482.79ms | tok/sec: 61332.58
2024-06-15 19:23:27,536 train.py step  1038 | loss: 3.797534 | lr 6.0000e-05 | norm: 0.4132 | dt: 85471.21ms | tok/sec: 61340.89
2024-06-15 19:24:53,015 train.py step  1039 | loss: 3.919873 | lr 6.0000e-05 | norm: 0.4160 | dt: 85478.45ms | tok/sec: 61335.69
2024-06-15 19:26:18,502 train.py step  1040 | loss: 3.914341 | lr 6.0000e-05 | norm: 0.4648 | dt: 85486.16ms | tok/sec: 61330.16
2024-06-15 19:27:43,983 train.py step  1041 | loss: 3.891191 | lr 6.0000e-05 | norm: 0.4865 | dt: 85480.66ms | tok/sec: 61334.11
2024-06-15 19:29:09,433 train.py step  1042 | loss: 3.840865 | lr 6.0000e-05 | norm: 0.4032 | dt: 85450.37ms | tok/sec: 61355.85
2024-06-15 19:30:34,908 train.py step  1043 | loss: 3.838057 | lr 6.0000e-05 | norm: 0.3633 | dt: 85474.36ms | tok/sec: 61338.63
2024-06-15 19:32:00,389 train.py step  1044 | loss: 3.944047 | lr 6.0000e-05 | norm: 0.4119 | dt: 85480.60ms | tok/sec: 61334.15
2024-06-15 19:33:25,874 train.py step  1045 | loss: 3.908395 | lr 6.0000e-05 | norm: 0.4314 | dt: 85484.72ms | tok/sec: 61331.20
2024-06-15 19:34:51,375 train.py step  1046 | loss: 3.867879 | lr 6.0000e-05 | norm: 0.4278 | dt: 85499.99ms | tok/sec: 61320.24
2024-06-15 19:36:16,885 train.py step  1047 | loss: 3.799631 | lr 6.0000e-05 | norm: 0.4644 | dt: 85510.20ms | tok/sec: 61312.92
2024-06-15 19:37:42,391 train.py step  1048 | loss: 3.875114 | lr 6.0000e-05 | norm: 0.4448 | dt: 85505.28ms | tok/sec: 61316.45
2024-06-15 19:39:07,887 train.py step  1049 | loss: 3.956210 | lr 6.0000e-05 | norm: 0.4222 | dt: 85495.62ms | tok/sec: 61323.37
2024-06-15 19:40:33,371 train.py step  1050 | loss: 3.898951 | lr 6.0000e-05 | norm: 0.4039 | dt: 85483.81ms | tok/sec: 61331.85
2024-06-15 19:41:58,869 train.py step  1051 | loss: 3.858525 | lr 6.0000e-05 | norm: 0.3983 | dt: 85497.68ms | tok/sec: 61321.90
2024-06-15 19:43:24,402 train.py step  1052 | loss: 3.816585 | lr 6.0000e-05 | norm: 0.3813 | dt: 85532.62ms | tok/sec: 61296.85
2024-06-15 19:44:49,948 train.py step  1053 | loss: 3.840344 | lr 6.0000e-05 | norm: 0.3603 | dt: 85545.46ms | tok/sec: 61287.65
2024-06-15 19:46:15,471 train.py step  1054 | loss: 3.915818 | lr 6.0000e-05 | norm: 0.3549 | dt: 85523.03ms | tok/sec: 61303.72
2024-06-15 19:47:40,986 train.py step  1055 | loss: 3.905629 | lr 6.0000e-05 | norm: 0.4179 | dt: 85514.18ms | tok/sec: 61310.06
2024-06-15 19:49:06,469 train.py step  1056 | loss: 3.868292 | lr 6.0000e-05 | norm: 0.4023 | dt: 85482.69ms | tok/sec: 61332.65
2024-06-15 19:50:31,985 train.py step  1057 | loss: 3.787992 | lr 6.0000e-05 | norm: 0.3995 | dt: 85515.90ms | tok/sec: 61308.83
2024-06-15 19:51:57,484 train.py step  1058 | loss: 3.895755 | lr 6.0000e-05 | norm: 0.3958 | dt: 85498.49ms | tok/sec: 61321.31
2024-06-15 19:53:22,990 train.py step  1059 | loss: 3.906332 | lr 6.0000e-05 | norm: 0.3969 | dt: 85505.36ms | tok/sec: 61316.39
2024-06-15 19:54:48,459 train.py step  1060 | loss: 3.876778 | lr 6.0000e-05 | norm: 0.3836 | dt: 85469.22ms | tok/sec: 61342.32
2024-06-15 19:56:13,975 train.py step  1061 | loss: 3.836878 | lr 6.0000e-05 | norm: 0.4358 | dt: 85514.83ms | tok/sec: 61309.60
2024-06-15 19:57:39,465 train.py step  1062 | loss: 3.812008 | lr 6.0000e-05 | norm: 0.4472 | dt: 85489.48ms | tok/sec: 61327.78
2024-06-15 19:59:04,951 train.py step  1063 | loss: 3.935058 | lr 6.0000e-05 | norm: 0.4500 | dt: 85486.50ms | tok/sec: 61329.92
2024-06-15 20:00:30,461 train.py step  1064 | loss: 3.896763 | lr 6.0000e-05 | norm: 0.4478 | dt: 85509.70ms | tok/sec: 61313.27
2024-06-15 20:01:55,942 train.py step  1065 | loss: 3.863235 | lr 6.0000e-05 | norm: 0.3838 | dt: 85480.40ms | tok/sec: 61334.30
2024-06-15 20:03:21,418 train.py step  1066 | loss: 3.790135 | lr 6.0000e-05 | norm: 0.3648 | dt: 85475.15ms | tok/sec: 61338.06
2024-06-15 20:04:47,194 train.py step  1067 | loss: 3.851992 | lr 6.0000e-05 | norm: 0.3992 | dt: 85775.90ms | tok/sec: 61123.00
2024-06-15 20:06:12,680 train.py step  1068 | loss: 3.941572 | lr 6.0000e-05 | norm: 0.3913 | dt: 85485.38ms | tok/sec: 61330.72
2024-06-15 20:07:38,165 train.py step  1069 | loss: 3.889901 | lr 6.0000e-05 | norm: 0.3941 | dt: 85484.56ms | tok/sec: 61331.31
2024-06-15 20:09:03,657 train.py step  1070 | loss: 3.852309 | lr 6.0000e-05 | norm: 0.4078 | dt: 85491.51ms | tok/sec: 61326.32
2024-06-15 20:10:29,146 train.py step  1071 | loss: 3.807610 | lr 6.0000e-05 | norm: 0.3256 | dt: 85489.26ms | tok/sec: 61327.94
2024-06-15 20:11:54,609 train.py step  1072 | loss: 3.821485 | lr 6.0000e-05 | norm: 0.3714 | dt: 85462.35ms | tok/sec: 61347.25
2024-06-15 20:13:20,063 train.py step  1073 | loss: 3.903632 | lr 6.0000e-05 | norm: 0.4246 | dt: 85453.83ms | tok/sec: 61353.36
2024-06-15 20:14:45,531 train.py step  1074 | loss: 3.895697 | lr 6.0000e-05 | norm: 0.4417 | dt: 85466.70ms | tok/sec: 61344.13
2024-06-15 20:16:10,962 train.py step  1075 | loss: 3.857503 | lr 6.0000e-05 | norm: 0.4592 | dt: 85430.59ms | tok/sec: 61370.06
2024-06-15 20:17:36,403 train.py step  1076 | loss: 3.788021 | lr 6.0000e-05 | norm: 0.4192 | dt: 85441.32ms | tok/sec: 61362.35
2024-06-15 20:19:01,840 train.py step  1077 | loss: 3.869039 | lr 6.0000e-05 | norm: 0.4414 | dt: 85436.40ms | tok/sec: 61365.88
2024-06-15 20:20:27,267 train.py step  1078 | loss: 3.898943 | lr 6.0000e-05 | norm: 0.4904 | dt: 85426.28ms | tok/sec: 61373.15
2024-06-15 20:21:52,681 train.py step  1079 | loss: 3.866614 | lr 6.0000e-05 | norm: 0.5186 | dt: 85413.52ms | tok/sec: 61382.32
2024-06-15 20:23:18,115 train.py step  1080 | loss: 3.830049 | lr 6.0000e-05 | norm: 0.4488 | dt: 85433.90ms | tok/sec: 61367.68
2024-06-15 20:24:43,575 train.py step  1081 | loss: 3.792256 | lr 6.0000e-05 | norm: 0.4373 | dt: 85459.59ms | tok/sec: 61349.23
2024-06-15 20:26:09,001 train.py step  1082 | loss: 3.926692 | lr 6.0000e-05 | norm: 0.4754 | dt: 85425.81ms | tok/sec: 61373.49
2024-06-15 20:27:34,453 train.py step  1083 | loss: 3.888239 | lr 6.0000e-05 | norm: 0.4347 | dt: 85451.31ms | tok/sec: 61355.17
2024-06-15 20:28:59,905 train.py step  1084 | loss: 3.853305 | lr 6.0000e-05 | norm: 0.4459 | dt: 85451.51ms | tok/sec: 61355.03
2024-06-15 20:30:25,359 train.py step  1085 | loss: 3.787839 | lr 6.0000e-05 | norm: 0.4276 | dt: 85453.95ms | tok/sec: 61353.28
2024-06-15 20:31:50,816 train.py step  1086 | loss: 3.820995 | lr 6.0000e-05 | norm: 0.4193 | dt: 85456.89ms | tok/sec: 61351.17
2024-06-15 20:33:16,248 train.py step  1087 | loss: 3.934813 | lr 6.0000e-05 | norm: 0.4471 | dt: 85431.56ms | tok/sec: 61369.36
2024-06-15 20:34:41,711 train.py step  1088 | loss: 3.893718 | lr 6.0000e-05 | norm: 0.4373 | dt: 85462.13ms | tok/sec: 61347.40
2024-06-15 20:36:07,179 train.py step  1089 | loss: 3.832285 | lr 6.0000e-05 | norm: 0.4077 | dt: 85467.74ms | tok/sec: 61343.38
2024-06-15 20:37:32,651 train.py step  1090 | loss: 3.800656 | lr 6.0000e-05 | norm: 0.3879 | dt: 85471.64ms | tok/sec: 61340.58
2024-06-15 20:38:58,124 train.py step  1091 | loss: 3.800393 | lr 6.0000e-05 | norm: 0.3993 | dt: 85472.66ms | tok/sec: 61339.85
2024-06-15 20:40:23,571 train.py step  1092 | loss: 3.895182 | lr 6.0000e-05 | norm: 0.4155 | dt: 85446.46ms | tok/sec: 61358.66
2024-06-15 20:41:49,029 train.py step  1093 | loss: 3.884665 | lr 6.0000e-05 | norm: 0.3921 | dt: 85457.20ms | tok/sec: 61350.95
2024-06-15 20:43:14,477 train.py step  1094 | loss: 3.846463 | lr 6.0000e-05 | norm: 0.3993 | dt: 85448.42ms | tok/sec: 61357.25
2024-06-15 20:44:39,976 train.py step  1095 | loss: 3.782620 | lr 6.0000e-05 | norm: 0.3870 | dt: 85498.14ms | tok/sec: 61321.57
2024-06-15 20:46:05,458 train.py step  1096 | loss: 3.845501 | lr 6.0000e-05 | norm: 0.3635 | dt: 85481.64ms | tok/sec: 61333.41
2024-06-15 20:47:30,901 train.py step  1097 | loss: 3.893091 | lr 6.0000e-05 | norm: 0.3950 | dt: 85443.01ms | tok/sec: 61361.13
2024-06-15 20:48:56,316 train.py step  1098 | loss: 3.852975 | lr 6.0000e-05 | norm: 0.3904 | dt: 85413.74ms | tok/sec: 61382.17
2024-06-15 20:50:21,753 train.py step  1099 | loss: 3.825291 | lr 6.0000e-05 | norm: 0.4121 | dt: 85437.36ms | tok/sec: 61365.19
2024-06-15 20:51:47,204 train.py step  1100 | loss: 3.774236 | lr 6.0000e-05 | norm: 0.4739 | dt: 85450.64ms | tok/sec: 61355.66
2024-06-15 20:53:12,656 train.py step  1101 | loss: 3.907848 | lr 6.0000e-05 | norm: 0.5281 | dt: 85450.82ms | tok/sec: 61355.52
2024-06-15 20:54:38,078 train.py step  1102 | loss: 3.881714 | lr 6.0000e-05 | norm: 0.5037 | dt: 85422.35ms | tok/sec: 61375.97
2024-06-15 20:56:03,561 train.py step  1103 | loss: 3.848726 | lr 6.0000e-05 | norm: 0.4949 | dt: 85481.72ms | tok/sec: 61333.35
2024-06-15 20:57:29,003 train.py step  1104 | loss: 3.781859 | lr 6.0000e-05 | norm: 0.4623 | dt: 85441.70ms | tok/sec: 61362.08
2024-06-15 20:58:54,435 train.py step  1105 | loss: 3.799129 | lr 6.0000e-05 | norm: 0.4443 | dt: 85432.17ms | tok/sec: 61368.92
2024-06-15 21:00:19,895 train.py step  1106 | loss: 3.918097 | lr 6.0000e-05 | norm: 0.4451 | dt: 85459.46ms | tok/sec: 61349.32
2024-06-15 21:01:45,346 train.py step  1107 | loss: 3.887835 | lr 6.0000e-05 | norm: 0.4833 | dt: 85450.09ms | tok/sec: 61356.05
2024-06-15 21:03:10,797 train.py step  1108 | loss: 3.825408 | lr 6.0000e-05 | norm: 0.4788 | dt: 85451.43ms | tok/sec: 61355.09
2024-06-15 21:04:36,242 train.py step  1109 | loss: 3.795843 | lr 6.0000e-05 | norm: 0.4838 | dt: 85444.27ms | tok/sec: 61360.23
2024-06-15 21:06:01,733 train.py step  1110 | loss: 3.778899 | lr 6.0000e-05 | norm: 0.4253 | dt: 85490.95ms | tok/sec: 61326.73
2024-06-15 21:07:27,189 train.py step  1111 | loss: 3.887815 | lr 6.0000e-05 | norm: 0.3793 | dt: 85455.23ms | tok/sec: 61352.36
2024-06-15 21:08:52,621 train.py step  1112 | loss: 3.872460 | lr 6.0000e-05 | norm: 0.4549 | dt: 85431.89ms | tok/sec: 61369.12
2024-06-15 21:10:18,090 train.py step  1113 | loss: 3.838297 | lr 6.0000e-05 | norm: 0.4584 | dt: 85467.71ms | tok/sec: 61343.40
2024-06-15 21:11:43,585 train.py step  1114 | loss: 3.777330 | lr 6.0000e-05 | norm: 0.4449 | dt: 85495.19ms | tok/sec: 61323.68
2024-06-15 21:13:09,036 train.py step  1115 | loss: 3.833076 | lr 6.0000e-05 | norm: 0.4066 | dt: 85450.18ms | tok/sec: 61355.98
2024-06-15 21:14:34,479 train.py step  1116 | loss: 3.881341 | lr 6.0000e-05 | norm: 0.4066 | dt: 85443.33ms | tok/sec: 61360.90
2024-06-15 21:15:59,933 train.py step  1117 | loss: 3.837923 | lr 6.0000e-05 | norm: 0.3769 | dt: 85453.05ms | tok/sec: 61353.92
2024-06-15 21:17:25,357 train.py step  1118 | loss: 3.821799 | lr 6.0000e-05 | norm: 0.4342 | dt: 85424.13ms | tok/sec: 61374.70
2024-06-15 21:18:50,767 train.py step  1119 | loss: 3.758923 | lr 6.0000e-05 | norm: 0.4321 | dt: 85409.34ms | tok/sec: 61385.33
2024-06-15 21:20:16,198 train.py step  1120 | loss: 3.884574 | lr 6.0000e-05 | norm: 0.4845 | dt: 85430.71ms | tok/sec: 61369.97
2024-06-15 21:21:41,639 train.py step  1121 | loss: 3.873783 | lr 6.0000e-05 | norm: 0.4291 | dt: 85440.70ms | tok/sec: 61362.79
2024-06-15 21:23:07,050 train.py step  1122 | loss: 3.841446 | lr 6.0000e-05 | norm: 0.4535 | dt: 85410.38ms | tok/sec: 61384.58
2024-06-15 21:24:32,464 train.py step  1123 | loss: 3.782277 | lr 6.0000e-05 | norm: 0.5182 | dt: 85413.31ms | tok/sec: 61382.47
2024-06-15 21:25:57,874 train.py step  1124 | loss: 3.776560 | lr 6.0000e-05 | norm: 0.5174 | dt: 85410.06ms | tok/sec: 61384.81
2024-06-15 21:27:23,282 train.py step  1125 | loss: 3.904061 | lr 6.0000e-05 | norm: 0.4642 | dt: 85407.59ms | tok/sec: 61386.58
2024-06-15 21:28:48,701 train.py step  1126 | loss: 3.882517 | lr 6.0000e-05 | norm: 0.4425 | dt: 85417.81ms | tok/sec: 61379.24
2024-06-15 21:30:14,106 train.py step  1127 | loss: 3.815954 | lr 6.0000e-05 | norm: 0.4295 | dt: 85405.03ms | tok/sec: 61388.42
2024-06-15 21:31:39,565 train.py step  1128 | loss: 3.794660 | lr 6.0000e-05 | norm: 0.4342 | dt: 85458.13ms | tok/sec: 61350.27
2024-06-15 21:33:04,991 train.py step  1129 | loss: 3.751748 | lr 6.0000e-05 | norm: 0.4147 | dt: 85425.58ms | tok/sec: 61373.66
2024-06-15 21:34:30,414 train.py step  1130 | loss: 3.882658 | lr 6.0000e-05 | norm: 0.4409 | dt: 85422.96ms | tok/sec: 61375.54
2024-06-15 21:35:55,858 train.py step  1131 | loss: 3.857545 | lr 6.0000e-05 | norm: 0.4609 | dt: 85443.28ms | tok/sec: 61360.94
2024-06-15 21:37:21,295 train.py step  1132 | loss: 3.832008 | lr 6.0000e-05 | norm: 0.4849 | dt: 85437.28ms | tok/sec: 61365.25
2024-06-15 21:38:46,735 train.py step  1133 | loss: 3.774813 | lr 6.0000e-05 | norm: 0.4903 | dt: 85438.84ms | tok/sec: 61364.13
2024-06-15 21:40:12,149 train.py step  1134 | loss: 3.814329 | lr 6.0000e-05 | norm: 0.4827 | dt: 85413.82ms | tok/sec: 61382.10
2024-06-15 21:41:37,550 train.py step  1135 | loss: 3.866058 | lr 6.0000e-05 | norm: 0.4198 | dt: 85400.37ms | tok/sec: 61391.77
2024-06-15 21:43:02,972 train.py step  1136 | loss: 3.832192 | lr 6.0000e-05 | norm: 0.3989 | dt: 85422.30ms | tok/sec: 61376.01
2024-06-15 21:44:28,395 train.py step  1137 | loss: 3.813338 | lr 6.0000e-05 | norm: 0.4079 | dt: 85422.26ms | tok/sec: 61376.04
2024-06-15 21:45:53,841 train.py step  1138 | loss: 3.751496 | lr 6.0000e-05 | norm: 0.4369 | dt: 85445.89ms | tok/sec: 61359.07
2024-06-15 21:47:19,271 train.py step  1139 | loss: 3.863380 | lr 6.0000e-05 | norm: 0.4484 | dt: 85429.43ms | tok/sec: 61370.89
2024-06-15 21:48:44,726 train.py step  1140 | loss: 3.863045 | lr 6.0000e-05 | norm: 0.4440 | dt: 85453.91ms | tok/sec: 61353.31
2024-06-15 21:50:10,179 train.py step  1141 | loss: 3.835397 | lr 6.0000e-05 | norm: 0.4594 | dt: 85452.40ms | tok/sec: 61354.39
2024-06-15 21:51:35,639 train.py step  1142 | loss: 3.774266 | lr 6.0000e-05 | norm: 0.4166 | dt: 85459.88ms | tok/sec: 61349.02
2024-06-15 21:53:01,098 train.py step  1143 | loss: 3.759932 | lr 6.0000e-05 | norm: 0.3943 | dt: 85458.51ms | tok/sec: 61350.00
2024-06-15 21:54:26,564 train.py step  1144 | loss: 3.891534 | lr 6.0000e-05 | norm: 0.4517 | dt: 85465.74ms | tok/sec: 61344.81
2024-06-15 21:55:52,008 train.py step  1145 | loss: 3.871512 | lr 6.0000e-05 | norm: 0.4534 | dt: 85443.32ms | tok/sec: 61360.91
2024-06-15 21:57:17,451 train.py step  1146 | loss: 3.812493 | lr 6.0000e-05 | norm: 0.4166 | dt: 85443.04ms | tok/sec: 61361.11
2024-06-15 21:58:42,903 train.py step  1147 | loss: 3.791726 | lr 6.0000e-05 | norm: 0.4390 | dt: 85451.60ms | tok/sec: 61354.97
2024-06-15 22:00:08,377 train.py step  1148 | loss: 3.726888 | lr 6.0000e-05 | norm: 0.5010 | dt: 85473.57ms | tok/sec: 61339.20
2024-06-15 22:01:33,852 train.py step  1149 | loss: 3.875732 | lr 6.0000e-05 | norm: 0.6166 | dt: 85474.62ms | tok/sec: 61338.44
2024-06-15 22:02:59,360 train.py step  1150 | loss: 3.847077 | lr 6.0000e-05 | norm: 0.7459 | dt: 85507.29ms | tok/sec: 61315.01
2024-06-15 22:04:24,881 train.py step  1151 | loss: 3.834723 | lr 6.0000e-05 | norm: 0.7061 | dt: 85520.33ms | tok/sec: 61305.66
2024-06-15 22:05:50,358 train.py step  1152 | loss: 3.767068 | lr 6.0000e-05 | norm: 0.5425 | dt: 85476.54ms | tok/sec: 61337.06
2024-06-15 22:07:15,837 train.py step  1153 | loss: 3.795127 | lr 6.0000e-05 | norm: 0.5796 | dt: 85479.14ms | tok/sec: 61335.20
2024-06-15 22:08:41,325 train.py step  1154 | loss: 3.864871 | lr 6.0000e-05 | norm: 0.6470 | dt: 85487.12ms | tok/sec: 61329.48
2024-06-15 22:10:06,823 train.py step  1155 | loss: 3.822210 | lr 6.0000e-05 | norm: 0.4832 | dt: 85498.01ms | tok/sec: 61321.66
2024-06-15 22:11:32,345 train.py step  1156 | loss: 3.807901 | lr 6.0000e-05 | norm: 0.5357 | dt: 85520.85ms | tok/sec: 61305.29
2024-06-15 22:12:57,867 train.py step  1157 | loss: 3.747910 | lr 6.0000e-05 | norm: 0.5256 | dt: 85521.79ms | tok/sec: 61304.61
2024-06-15 22:14:23,372 train.py step  1158 | loss: 3.837545 | lr 6.0000e-05 | norm: 0.4667 | dt: 85504.70ms | tok/sec: 61316.86
2024-06-15 22:15:48,866 train.py step  1159 | loss: 3.855328 | lr 6.0000e-05 | norm: 0.5111 | dt: 85493.43ms | tok/sec: 61324.95
2024-06-15 22:17:14,357 train.py step  1160 | loss: 3.831643 | lr 6.0000e-05 | norm: 0.4483 | dt: 85490.42ms | tok/sec: 61327.11
2024-06-15 22:18:39,835 train.py step  1161 | loss: 3.767503 | lr 6.0000e-05 | norm: 0.4793 | dt: 85477.87ms | tok/sec: 61336.11
2024-06-15 22:20:05,306 train.py step  1162 | loss: 3.746054 | lr 6.0000e-05 | norm: 0.4470 | dt: 85470.25ms | tok/sec: 61341.58
2024-06-15 22:21:30,745 train.py step  1163 | loss: 3.873990 | lr 6.0000e-05 | norm: 0.4591 | dt: 85439.09ms | tok/sec: 61363.95
2024-06-15 22:22:56,168 train.py step  1164 | loss: 3.869774 | lr 6.0000e-05 | norm: 0.4365 | dt: 85422.89ms | tok/sec: 61375.59
2024-06-15 22:24:21,605 train.py step  1165 | loss: 3.807147 | lr 6.0000e-05 | norm: 0.4196 | dt: 85436.70ms | tok/sec: 61365.67
2024-06-15 22:25:47,029 train.py step  1166 | loss: 3.780602 | lr 6.0000e-05 | norm: 0.4238 | dt: 85422.83ms | tok/sec: 61375.63
2024-06-15 22:27:12,455 train.py step  1167 | loss: 3.718033 | lr 6.0000e-05 | norm: 0.4264 | dt: 85425.66ms | tok/sec: 61373.60
2024-06-15 22:28:37,889 train.py step  1168 | loss: 3.858042 | lr 6.0000e-05 | norm: 0.4395 | dt: 85433.81ms | tok/sec: 61367.74
2024-06-15 22:30:03,332 train.py step  1169 | loss: 3.834127 | lr 6.0000e-05 | norm: 0.4410 | dt: 85442.71ms | tok/sec: 61361.35
2024-06-15 22:31:28,755 train.py step  1170 | loss: 3.824066 | lr 6.0000e-05 | norm: 0.4833 | dt: 85422.07ms | tok/sec: 61376.18
2024-06-15 22:32:54,181 train.py step  1171 | loss: 3.764277 | lr 6.0000e-05 | norm: 0.4942 | dt: 85426.05ms | tok/sec: 61373.32
2024-06-15 22:34:19,635 train.py step  1172 | loss: 3.771366 | lr 6.0000e-05 | norm: 0.4754 | dt: 85453.82ms | tok/sec: 61353.37
2024-06-15 22:35:45,088 train.py step  1173 | loss: 3.855180 | lr 6.0000e-05 | norm: 0.4657 | dt: 85452.47ms | tok/sec: 61354.34
2024-06-15 22:37:10,537 train.py step  1174 | loss: 3.813144 | lr 6.0000e-05 | norm: 0.4509 | dt: 85448.86ms | tok/sec: 61356.93
2024-06-15 22:38:36,000 train.py step  1175 | loss: 3.798428 | lr 6.0000e-05 | norm: 0.4541 | dt: 85461.73ms | tok/sec: 61347.69
2024-06-15 22:40:01,458 train.py step  1176 | loss: 3.743193 | lr 6.0000e-05 | norm: 0.4125 | dt: 85458.48ms | tok/sec: 61350.02
2024-06-15 22:41:26,900 train.py step  1177 | loss: 3.817274 | lr 6.0000e-05 | norm: 0.4866 | dt: 85441.35ms | tok/sec: 61362.33
2024-06-15 22:42:52,356 train.py step  1178 | loss: 3.849444 | lr 6.0000e-05 | norm: 0.4822 | dt: 85455.58ms | tok/sec: 61352.11
2024-06-15 22:44:17,800 train.py step  1179 | loss: 3.822347 | lr 6.0000e-05 | norm: 0.4178 | dt: 85443.11ms | tok/sec: 61361.06
2024-06-15 22:45:43,244 train.py step  1180 | loss: 3.763199 | lr 6.0000e-05 | norm: 0.4806 | dt: 85443.49ms | tok/sec: 61360.79
2024-06-15 22:47:08,673 train.py step  1181 | loss: 3.724472 | lr 6.0000e-05 | norm: 0.4798 | dt: 85428.89ms | tok/sec: 61371.27
2024-06-15 22:48:34,107 train.py step  1182 | loss: 3.860663 | lr 6.0000e-05 | norm: 0.4055 | dt: 85433.40ms | tok/sec: 61368.04
2024-06-15 22:49:59,548 train.py step  1183 | loss: 3.862557 | lr 6.0000e-05 | norm: 0.4276 | dt: 85440.73ms | tok/sec: 61362.77
2024-06-15 22:51:24,981 train.py step  1184 | loss: 3.803665 | lr 6.0000e-05 | norm: 0.4249 | dt: 85433.00ms | tok/sec: 61368.32
2024-06-15 22:52:50,461 train.py step  1185 | loss: 3.776486 | lr 6.0000e-05 | norm: 0.4184 | dt: 85478.75ms | tok/sec: 61335.48
2024-06-15 22:54:15,921 train.py step  1186 | loss: 3.703803 | lr 6.0000e-05 | norm: 0.3838 | dt: 85460.18ms | tok/sec: 61348.81
2024-06-15 22:55:41,361 train.py step  1187 | loss: 3.840224 | lr 6.0000e-05 | norm: 0.4414 | dt: 85440.05ms | tok/sec: 61363.26
2024-06-15 22:57:06,811 train.py step  1188 | loss: 3.817102 | lr 6.0000e-05 | norm: 0.4339 | dt: 85449.13ms | tok/sec: 61356.74
2024-06-15 22:58:32,233 train.py step  1189 | loss: 3.825145 | lr 6.0000e-05 | norm: 0.4310 | dt: 85421.14ms | tok/sec: 61376.85
2024-06-15 22:59:57,685 train.py step  1190 | loss: 3.760321 | lr 6.0000e-05 | norm: 0.4871 | dt: 85451.92ms | tok/sec: 61354.74
2024-06-15 23:01:23,122 train.py step  1191 | loss: 3.749727 | lr 6.0000e-05 | norm: 0.5220 | dt: 85436.28ms | tok/sec: 61365.97
2024-06-15 23:02:48,526 train.py step  1192 | loss: 3.847638 | lr 6.0000e-05 | norm: 0.5297 | dt: 85403.71ms | tok/sec: 61389.37
2024-06-15 23:04:13,958 train.py step  1193 | loss: 3.805715 | lr 6.0000e-05 | norm: 0.5024 | dt: 85431.62ms | tok/sec: 61369.31
2024-06-15 23:05:39,401 train.py step  1194 | loss: 3.791600 | lr 6.0000e-05 | norm: 0.4012 | dt: 85442.93ms | tok/sec: 61361.19
2024-06-15 23:07:04,793 train.py step  1195 | loss: 3.737139 | lr 6.0000e-05 | norm: 0.4353 | dt: 85391.58ms | tok/sec: 61398.09
2024-06-15 23:08:30,230 train.py step  1196 | loss: 3.801919 | lr 6.0000e-05 | norm: 0.4875 | dt: 85436.88ms | tok/sec: 61365.54
2024-06-15 23:09:55,681 train.py step  1197 | loss: 3.839032 | lr 6.0000e-05 | norm: 0.5058 | dt: 85450.57ms | tok/sec: 61355.71
2024-06-15 23:11:21,115 train.py step  1198 | loss: 3.814411 | lr 6.0000e-05 | norm: 0.5570 | dt: 85433.63ms | tok/sec: 61367.87
2024-06-15 23:12:46,587 train.py step  1199 | loss: 3.758586 | lr 6.0000e-05 | norm: 0.5646 | dt: 85470.84ms | tok/sec: 61341.15
2024-06-15 23:14:12,027 train.py step  1200 | loss: 3.710545 | lr 6.0000e-05 | norm: 0.6030 | dt: 85439.92ms | tok/sec: 61363.35
2024-06-15 23:15:37,513 train.py step  1201 | loss: 3.850404 | lr 6.0000e-05 | norm: 0.5977 | dt: 85485.74ms | tok/sec: 61330.46
2024-06-15 23:17:02,974 train.py step  1202 | loss: 3.853116 | lr 6.0000e-05 | norm: 0.5168 | dt: 85460.40ms | tok/sec: 61348.65
2024-06-15 23:18:28,437 train.py step  1203 | loss: 3.800212 | lr 6.0000e-05 | norm: 0.5183 | dt: 85463.23ms | tok/sec: 61346.61
2024-06-15 23:19:53,867 train.py step  1204 | loss: 3.769873 | lr 6.0000e-05 | norm: 0.5030 | dt: 85429.21ms | tok/sec: 61371.04
2024-06-15 23:21:19,328 train.py step  1205 | loss: 3.699815 | lr 6.0000e-05 | norm: 0.4718 | dt: 85460.29ms | tok/sec: 61348.73
2024-06-15 23:22:44,784 train.py step  1206 | loss: 3.820455 | lr 6.0000e-05 | norm: 0.4999 | dt: 85455.93ms | tok/sec: 61351.86
2024-06-15 23:24:10,240 train.py step  1207 | loss: 3.806157 | lr 6.0000e-05 | norm: 0.4667 | dt: 85455.43ms | tok/sec: 61352.22
2024-06-15 23:25:35,702 train.py step  1208 | loss: 3.817996 | lr 6.0000e-05 | norm: 0.4596 | dt: 85462.07ms | tok/sec: 61347.45
2024-06-15 23:27:01,177 train.py step  1209 | loss: 3.758452 | lr 6.0000e-05 | norm: 0.4259 | dt: 85474.22ms | tok/sec: 61338.73
2024-06-15 23:28:26,651 train.py step  1210 | loss: 3.724693 | lr 6.0000e-05 | norm: 0.3905 | dt: 85473.95ms | tok/sec: 61338.92
2024-06-15 23:29:52,119 train.py step  1211 | loss: 3.840208 | lr 6.0000e-05 | norm: 0.4459 | dt: 85467.62ms | tok/sec: 61343.47
2024-06-15 23:31:17,581 train.py step  1212 | loss: 3.798001 | lr 6.0000e-05 | norm: 0.4070 | dt: 85461.00ms | tok/sec: 61348.22
2024-06-15 23:32:43,040 train.py step  1213 | loss: 3.783474 | lr 6.0000e-05 | norm: 0.4139 | dt: 85459.19ms | tok/sec: 61349.52
2024-06-15 23:34:08,508 train.py step  1214 | loss: 3.730961 | lr 6.0000e-05 | norm: 0.4604 | dt: 85467.02ms | tok/sec: 61343.90
2024-06-15 23:35:33,950 train.py step  1215 | loss: 3.786486 | lr 6.0000e-05 | norm: 0.4934 | dt: 85442.05ms | tok/sec: 61361.83
2024-06-15 23:36:59,396 train.py step  1216 | loss: 3.829230 | lr 6.0000e-05 | norm: 0.5871 | dt: 85445.04ms | tok/sec: 61359.68
2024-06-15 23:38:24,842 train.py step  1217 | loss: 3.808910 | lr 6.0000e-05 | norm: 0.6564 | dt: 85445.85ms | tok/sec: 61359.10
2024-06-15 23:39:50,267 train.py step  1218 | loss: 3.758639 | lr 6.0000e-05 | norm: 0.7206 | dt: 85424.29ms | tok/sec: 61374.58
2024-06-15 23:41:15,685 train.py step  1219 | loss: 3.699809 | lr 6.0000e-05 | norm: 0.7372 | dt: 85418.19ms | tok/sec: 61378.97
2024-06-15 23:42:41,123 train.py step  1220 | loss: 3.832200 | lr 6.0000e-05 | norm: 0.6267 | dt: 85437.88ms | tok/sec: 61364.82
2024-06-15 23:44:06,569 train.py step  1221 | loss: 3.848327 | lr 6.0000e-05 | norm: 0.7137 | dt: 85445.61ms | tok/sec: 61359.27
2024-06-15 23:45:32,042 train.py step  1222 | loss: 3.792052 | lr 6.0000e-05 | norm: 0.6416 | dt: 85472.77ms | tok/sec: 61339.77
2024-06-15 23:46:57,515 train.py step  1223 | loss: 3.768368 | lr 6.0000e-05 | norm: 0.5856 | dt: 85471.86ms | tok/sec: 61340.42
2024-06-15 23:48:22,983 train.py step  1224 | loss: 3.694129 | lr 6.0000e-05 | norm: 0.5210 | dt: 85468.09ms | tok/sec: 61343.13
2024-06-15 23:49:48,437 train.py step  1225 | loss: 3.803314 | lr 6.0000e-05 | norm: 0.4686 | dt: 85453.62ms | tok/sec: 61353.51
2024-06-15 23:51:13,889 train.py step  1226 | loss: 3.796616 | lr 6.0000e-05 | norm: 0.5136 | dt: 85451.70ms | tok/sec: 61354.89
2024-06-15 23:52:39,322 train.py step  1227 | loss: 3.811876 | lr 6.0000e-05 | norm: 0.4955 | dt: 85432.81ms | tok/sec: 61368.46
2024-06-15 23:54:04,762 train.py step  1228 | loss: 3.754726 | lr 6.0000e-05 | norm: 0.4853 | dt: 85439.66ms | tok/sec: 61363.54
2024-06-15 23:55:30,210 train.py step  1229 | loss: 3.706263 | lr 6.0000e-05 | norm: 0.4424 | dt: 85446.71ms | tok/sec: 61358.47
2024-06-15 23:56:55,649 train.py step  1230 | loss: 3.830541 | lr 6.0000e-05 | norm: 0.4732 | dt: 85438.78ms | tok/sec: 61364.17
2024-06-15 23:58:21,098 train.py step  1231 | loss: 3.789876 | lr 6.0000e-05 | norm: 0.4840 | dt: 85448.48ms | tok/sec: 61357.21
2024-06-15 23:59:46,547 train.py step  1232 | loss: 3.779225 | lr 6.0000e-05 | norm: 0.4329 | dt: 85449.19ms | tok/sec: 61356.70
2024-06-16 00:01:11,995 train.py step  1233 | loss: 3.724392 | lr 6.0000e-05 | norm: 0.5041 | dt: 85447.33ms | tok/sec: 61358.03
2024-06-16 00:02:37,469 train.py step  1234 | loss: 3.769707 | lr 6.0000e-05 | norm: 0.4682 | dt: 85473.33ms | tok/sec: 61339.37
2024-06-16 00:04:02,942 train.py step  1235 | loss: 3.824238 | lr 6.0000e-05 | norm: 0.4312 | dt: 85472.52ms | tok/sec: 61339.95
2024-06-16 00:05:28,399 train.py step  1236 | loss: 3.805300 | lr 6.0000e-05 | norm: 0.4760 | dt: 85457.04ms | tok/sec: 61351.06
2024-06-16 00:06:53,857 train.py step  1237 | loss: 3.746719 | lr 6.0000e-05 | norm: 0.4431 | dt: 85457.52ms | tok/sec: 61350.71
2024-06-16 00:08:19,341 train.py step  1238 | loss: 3.684096 | lr 6.0000e-05 | norm: 0.4773 | dt: 85483.48ms | tok/sec: 61332.08
2024-06-16 00:09:44,799 train.py step  1239 | loss: 3.811063 | lr 6.0000e-05 | norm: 0.5686 | dt: 85458.19ms | tok/sec: 61350.24
2024-06-16 00:11:10,261 train.py step  1240 | loss: 3.844266 | lr 6.0000e-05 | norm: 0.5964 | dt: 85461.30ms | tok/sec: 61348.01
2024-06-16 00:12:35,722 train.py step  1241 | loss: 3.790699 | lr 6.0000e-05 | norm: 0.5280 | dt: 85460.46ms | tok/sec: 61348.60
2024-06-16 00:14:01,158 train.py step  1242 | loss: 3.750149 | lr 6.0000e-05 | norm: 0.4718 | dt: 85435.34ms | tok/sec: 61366.65
2024-06-16 00:15:26,578 train.py step  1243 | loss: 3.694924 | lr 6.0000e-05 | norm: 0.5263 | dt: 85419.70ms | tok/sec: 61377.88
2024-06-16 00:16:52,022 train.py step  1244 | loss: 3.779895 | lr 6.0000e-05 | norm: 0.5378 | dt: 85444.34ms | tok/sec: 61360.18
2024-06-16 00:18:17,494 train.py step  1245 | loss: 3.789714 | lr 6.0000e-05 | norm: 0.5173 | dt: 85471.36ms | tok/sec: 61340.78
2024-06-16 00:19:42,984 train.py step  1246 | loss: 3.802756 | lr 6.0000e-05 | norm: 0.5760 | dt: 85489.47ms | tok/sec: 61327.79
2024-06-16 00:21:08,432 train.py step  1247 | loss: 3.754081 | lr 6.0000e-05 | norm: 0.5376 | dt: 85447.64ms | tok/sec: 61357.81
2024-06-16 00:22:33,883 train.py step  1248 | loss: 3.690480 | lr 6.0000e-05 | norm: 0.4630 | dt: 85450.23ms | tok/sec: 61355.95
2024-06-16 00:23:59,343 train.py step  1249 | loss: 3.822705 | lr 6.0000e-05 | norm: 0.5031 | dt: 85460.56ms | tok/sec: 61348.53
2024-06-16 00:24:01,529 train.py validation loss: 4.0207
2024-06-16 00:25:27,984 train.py step  1250 | loss: 3.783102 | lr 6.0000e-05 | norm: 0.5146 | dt: 88640.20ms | tok/sec: 59147.88
2024-06-16 00:26:53,423 train.py step  1251 | loss: 3.771165 | lr 6.0000e-05 | norm: 0.5009 | dt: 85438.30ms | tok/sec: 61364.52
2024-06-16 00:28:18,878 train.py step  1252 | loss: 3.715893 | lr 6.0000e-05 | norm: 0.4712 | dt: 85454.82ms | tok/sec: 61352.65
2024-06-16 00:29:44,334 train.py step  1253 | loss: 3.753508 | lr 6.0000e-05 | norm: 0.4656 | dt: 85455.98ms | tok/sec: 61351.82
2024-06-16 00:31:09,783 train.py step  1254 | loss: 3.817106 | lr 6.0000e-05 | norm: 0.4648 | dt: 85448.23ms | tok/sec: 61357.38
2024-06-16 00:32:35,234 train.py step  1255 | loss: 3.799215 | lr 6.0000e-05 | norm: 0.4564 | dt: 85450.36ms | tok/sec: 61355.86
2024-06-16 00:34:00,701 train.py step  1256 | loss: 3.741552 | lr 6.0000e-05 | norm: 0.4818 | dt: 85467.38ms | tok/sec: 61343.64
2024-06-16 00:35:26,163 train.py step  1257 | loss: 3.677316 | lr 6.0000e-05 | norm: 0.4850 | dt: 85461.69ms | tok/sec: 61347.72
2024-06-16 00:36:51,646 train.py step  1258 | loss: 3.789447 | lr 6.0000e-05 | norm: 0.5361 | dt: 85482.21ms | tok/sec: 61333.00
2024-06-16 00:38:17,134 train.py step  1259 | loss: 3.842034 | lr 6.0000e-05 | norm: 0.5340 | dt: 85487.48ms | tok/sec: 61329.21
2024-06-16 00:39:42,628 train.py step  1260 | loss: 3.777919 | lr 6.0000e-05 | norm: 0.5175 | dt: 85493.92ms | tok/sec: 61324.60
2024-06-16 00:41:08,113 train.py step  1261 | loss: 3.737282 | lr 6.0000e-05 | norm: 0.5028 | dt: 85484.89ms | tok/sec: 61331.07
2024-06-16 00:42:33,605 train.py step  1262 | loss: 3.698425 | lr 6.0000e-05 | norm: 0.5636 | dt: 85491.64ms | tok/sec: 61326.23
2024-06-16 00:43:59,148 train.py step  1263 | loss: 3.761915 | lr 6.0000e-05 | norm: 0.6260 | dt: 85542.67ms | tok/sec: 61289.65
2024-06-16 00:45:24,687 train.py step  1264 | loss: 3.780321 | lr 6.0000e-05 | norm: 0.5385 | dt: 85537.83ms | tok/sec: 61293.11
2024-06-16 00:46:50,223 train.py step  1265 | loss: 3.796543 | lr 6.0000e-05 | norm: 0.4889 | dt: 85535.72ms | tok/sec: 61294.63
2024-06-16 00:48:15,761 train.py step  1266 | loss: 3.752611 | lr 6.0000e-05 | norm: 0.5154 | dt: 85537.71ms | tok/sec: 61293.20
2024-06-16 00:49:41,288 train.py step  1267 | loss: 3.671309 | lr 6.0000e-05 | norm: 0.5291 | dt: 85526.54ms | tok/sec: 61301.20
2024-06-16 00:51:06,779 train.py step  1268 | loss: 3.809920 | lr 6.0000e-05 | norm: 0.5097 | dt: 85491.15ms | tok/sec: 61326.58
2024-06-16 00:52:32,294 train.py step  1269 | loss: 3.785479 | lr 6.0000e-05 | norm: 0.5015 | dt: 85514.30ms | tok/sec: 61309.98
2024-06-16 00:53:57,840 train.py step  1270 | loss: 3.758363 | lr 6.0000e-05 | norm: 0.4764 | dt: 85546.14ms | tok/sec: 61287.16
2024-06-16 00:55:23,359 train.py step  1271 | loss: 3.708684 | lr 6.0000e-05 | norm: 0.5162 | dt: 85518.50ms | tok/sec: 61306.97
2024-06-16 00:56:48,846 train.py step  1272 | loss: 3.742214 | lr 6.0000e-05 | norm: 0.5544 | dt: 85486.44ms | tok/sec: 61329.96
2024-06-16 00:58:14,357 train.py step  1273 | loss: 3.810596 | lr 6.0000e-05 | norm: 0.5499 | dt: 85510.09ms | tok/sec: 61313.00
2024-06-16 00:59:39,878 train.py step  1274 | loss: 3.790556 | lr 6.0000e-05 | norm: 0.4491 | dt: 85520.95ms | tok/sec: 61305.21
2024-06-16 01:01:05,386 train.py step  1275 | loss: 3.733243 | lr 6.0000e-05 | norm: 0.4244 | dt: 85508.08ms | tok/sec: 61314.44
2024-06-16 01:02:30,877 train.py step  1276 | loss: 3.671985 | lr 6.0000e-05 | norm: 0.5166 | dt: 85489.90ms | tok/sec: 61327.48
2024-06-16 01:03:56,355 train.py step  1277 | loss: 3.768844 | lr 6.0000e-05 | norm: 0.5196 | dt: 85477.73ms | tok/sec: 61336.21
2024-06-16 01:05:21,819 train.py step  1278 | loss: 3.833480 | lr 6.0000e-05 | norm: 0.4940 | dt: 85463.41ms | tok/sec: 61346.49
2024-06-16 01:06:47,302 train.py step  1279 | loss: 3.769717 | lr 6.0000e-05 | norm: 0.4625 | dt: 85483.26ms | tok/sec: 61332.25
2024-06-16 01:08:12,816 train.py step  1280 | loss: 3.734980 | lr 6.0000e-05 | norm: 0.4449 | dt: 85513.75ms | tok/sec: 61310.37
2024-06-16 01:09:38,327 train.py step  1281 | loss: 3.688354 | lr 6.0000e-05 | norm: 0.4813 | dt: 85510.72ms | tok/sec: 61312.54
2024-06-16 01:11:03,821 train.py step  1282 | loss: 3.741273 | lr 6.0000e-05 | norm: 0.5404 | dt: 85492.87ms | tok/sec: 61325.35
2024-06-16 01:12:29,296 train.py step  1283 | loss: 3.778725 | lr 6.0000e-05 | norm: 0.5092 | dt: 85474.88ms | tok/sec: 61338.25
2024-06-16 01:13:54,783 train.py step  1284 | loss: 3.790015 | lr 6.0000e-05 | norm: 0.5237 | dt: 85486.29ms | tok/sec: 61330.07
2024-06-16 01:15:20,269 train.py step  1285 | loss: 3.741678 | lr 6.0000e-05 | norm: 0.5887 | dt: 85485.96ms | tok/sec: 61330.30
2024-06-16 01:16:45,771 train.py step  1286 | loss: 3.668253 | lr 6.0000e-05 | norm: 0.5527 | dt: 85501.38ms | tok/sec: 61319.24
2024-06-16 01:18:11,285 train.py step  1287 | loss: 3.791939 | lr 6.0000e-05 | norm: 0.5660 | dt: 85513.81ms | tok/sec: 61310.33
2024-06-16 01:19:36,822 train.py step  1288 | loss: 3.777857 | lr 6.0000e-05 | norm: 0.5670 | dt: 85536.59ms | tok/sec: 61294.00
2024-06-16 01:21:02,327 train.py step  1289 | loss: 3.757047 | lr 6.0000e-05 | norm: 0.6293 | dt: 85504.36ms | tok/sec: 61317.11
2024-06-16 01:22:27,791 train.py step  1290 | loss: 3.702024 | lr 6.0000e-05 | norm: 0.6176 | dt: 85463.82ms | tok/sec: 61346.20
2024-06-16 01:23:53,256 train.py step  1291 | loss: 3.721232 | lr 6.0000e-05 | norm: 0.5416 | dt: 85464.93ms | tok/sec: 61345.40
2024-06-16 01:25:18,706 train.py step  1292 | loss: 3.805326 | lr 6.0000e-05 | norm: 0.4806 | dt: 85449.20ms | tok/sec: 61356.69
2024-06-16 01:26:44,176 train.py step  1293 | loss: 3.781262 | lr 6.0000e-05 | norm: 0.5421 | dt: 85470.11ms | tok/sec: 61341.68
2024-06-16 01:28:09,620 train.py step  1294 | loss: 3.734176 | lr 6.0000e-05 | norm: 0.5717 | dt: 85443.49ms | tok/sec: 61360.79
2024-06-16 01:29:35,050 train.py step  1295 | loss: 3.664267 | lr 6.0000e-05 | norm: 0.5096 | dt: 85429.32ms | tok/sec: 61370.97
2024-06-16 01:31:00,443 train.py step  1296 | loss: 3.750062 | lr 6.0000e-05 | norm: 0.4867 | dt: 85392.67ms | tok/sec: 61397.31
2024-06-16 01:32:25,878 train.py step  1297 | loss: 3.826989 | lr 6.0000e-05 | norm: 0.5089 | dt: 85434.79ms | tok/sec: 61367.04
2024-06-16 01:33:51,290 train.py step  1298 | loss: 3.764817 | lr 6.0000e-05 | norm: 0.6017 | dt: 85411.91ms | tok/sec: 61383.48
2024-06-16 01:35:16,722 train.py step  1299 | loss: 3.727893 | lr 6.0000e-05 | norm: 0.6232 | dt: 85431.22ms | tok/sec: 61369.60
2024-06-16 01:36:42,178 train.py step  1300 | loss: 3.685673 | lr 6.0000e-05 | norm: 0.5526 | dt: 85455.87ms | tok/sec: 61351.90
2024-06-16 01:38:07,621 train.py step  1301 | loss: 3.721487 | lr 6.0000e-05 | norm: 0.5286 | dt: 85442.82ms | tok/sec: 61361.27
2024-06-16 01:39:33,105 train.py step  1302 | loss: 3.782027 | lr 6.0000e-05 | norm: 0.5667 | dt: 85483.46ms | tok/sec: 61332.10
2024-06-16 01:40:58,596 train.py step  1303 | loss: 3.775430 | lr 6.0000e-05 | norm: 0.5497 | dt: 85490.86ms | tok/sec: 61326.79
2024-06-16 01:42:24,047 train.py step  1304 | loss: 3.739666 | lr 6.0000e-05 | norm: 0.5378 | dt: 85449.91ms | tok/sec: 61356.18
2024-06-16 01:43:49,474 train.py step  1305 | loss: 3.658354 | lr 6.0000e-05 | norm: 0.5577 | dt: 85426.45ms | tok/sec: 61373.03
2024-06-16 01:45:14,901 train.py step  1306 | loss: 3.776016 | lr 6.0000e-05 | norm: 0.6054 | dt: 85426.95ms | tok/sec: 61372.67
2024-06-16 01:46:40,302 train.py step  1307 | loss: 3.773587 | lr 6.0000e-05 | norm: 0.5707 | dt: 85401.07ms | tok/sec: 61391.27
2024-06-16 01:48:05,712 train.py step  1308 | loss: 3.749283 | lr 6.0000e-05 | norm: 0.5355 | dt: 85409.43ms | tok/sec: 61385.26
2024-06-16 01:49:31,137 train.py step  1309 | loss: 3.702809 | lr 6.0000e-05 | norm: 0.5073 | dt: 85424.07ms | tok/sec: 61374.74
2024-06-16 01:50:56,565 train.py step  1310 | loss: 3.696947 | lr 6.0000e-05 | norm: 0.4786 | dt: 85428.30ms | tok/sec: 61371.70
2024-06-16 01:52:22,022 train.py step  1311 | loss: 3.803355 | lr 6.0000e-05 | norm: 0.5059 | dt: 85455.96ms | tok/sec: 61351.84
2024-06-16 01:53:47,476 train.py step  1312 | loss: 3.765065 | lr 6.0000e-05 | norm: 0.5079 | dt: 85453.82ms | tok/sec: 61353.37
2024-06-16 01:55:12,938 train.py step  1313 | loss: 3.733764 | lr 6.0000e-05 | norm: 0.5287 | dt: 85461.75ms | tok/sec: 61347.68
2024-06-16 01:56:38,373 train.py step  1314 | loss: 3.661489 | lr 6.0000e-05 | norm: 0.5239 | dt: 85434.40ms | tok/sec: 61367.32
2024-06-16 01:58:03,831 train.py step  1315 | loss: 3.733968 | lr 6.0000e-05 | norm: 0.5230 | dt: 85457.50ms | tok/sec: 61350.73
2024-06-16 01:59:29,310 train.py step  1316 | loss: 3.815189 | lr 6.0000e-05 | norm: 0.4988 | dt: 85478.77ms | tok/sec: 61335.46
2024-06-16 02:00:54,777 train.py step  1317 | loss: 3.757089 | lr 6.0000e-05 | norm: 0.5610 | dt: 85466.90ms | tok/sec: 61343.98
2024-06-16 02:02:20,250 train.py step  1318 | loss: 3.723574 | lr 6.0000e-05 | norm: 0.5890 | dt: 85472.86ms | tok/sec: 61339.71
2024-06-16 02:03:45,727 train.py step  1319 | loss: 3.682162 | lr 6.0000e-05 | norm: 0.5520 | dt: 85476.16ms | tok/sec: 61337.34
2024-06-16 02:05:11,188 train.py step  1320 | loss: 3.702657 | lr 6.0000e-05 | norm: 0.5203 | dt: 85460.86ms | tok/sec: 61348.32
2024-06-16 02:06:36,633 train.py step  1321 | loss: 3.775539 | lr 6.0000e-05 | norm: 0.5411 | dt: 85444.63ms | tok/sec: 61359.97
2024-06-16 02:08:02,094 train.py step  1322 | loss: 3.768157 | lr 6.0000e-05 | norm: 0.6382 | dt: 85460.32ms | tok/sec: 61348.70
2024-06-16 02:09:27,550 train.py step  1323 | loss: 3.733738 | lr 6.0000e-05 | norm: 0.5507 | dt: 85455.51ms | tok/sec: 61352.16
2024-06-16 02:10:53,002 train.py step  1324 | loss: 3.653523 | lr 6.0000e-05 | norm: 0.5380 | dt: 85452.32ms | tok/sec: 61354.45
2024-06-16 02:12:18,444 train.py step  1325 | loss: 3.756617 | lr 6.0000e-05 | norm: 0.5274 | dt: 85441.51ms | tok/sec: 61362.21
2024-06-16 02:13:43,931 train.py step  1326 | loss: 3.766851 | lr 6.0000e-05 | norm: 0.4997 | dt: 85486.46ms | tok/sec: 61329.95
2024-06-16 02:15:09,405 train.py step  1327 | loss: 3.741143 | lr 6.0000e-05 | norm: 0.5164 | dt: 85473.21ms | tok/sec: 61339.45
2024-06-16 02:16:34,877 train.py step  1328 | loss: 3.697923 | lr 6.0000e-05 | norm: 0.4509 | dt: 85472.37ms | tok/sec: 61340.06
2024-06-16 02:18:00,366 train.py step  1329 | loss: 3.678011 | lr 6.0000e-05 | norm: 0.4881 | dt: 85487.84ms | tok/sec: 61328.95
2024-06-16 02:19:25,882 train.py step  1330 | loss: 3.796016 | lr 6.0000e-05 | norm: 0.5279 | dt: 85515.92ms | tok/sec: 61308.82
2024-06-16 02:20:51,365 train.py step  1331 | loss: 3.761817 | lr 6.0000e-05 | norm: 0.5760 | dt: 85482.73ms | tok/sec: 61332.62
2024-06-16 02:22:16,848 train.py step  1332 | loss: 3.729384 | lr 6.0000e-05 | norm: 0.6013 | dt: 85482.31ms | tok/sec: 61332.92
2024-06-16 02:23:42,340 train.py step  1333 | loss: 3.658130 | lr 6.0000e-05 | norm: 0.5104 | dt: 85491.98ms | tok/sec: 61325.99
2024-06-16 02:25:07,844 train.py step  1334 | loss: 3.713390 | lr 6.0000e-05 | norm: 0.5263 | dt: 85503.81ms | tok/sec: 61317.50
2024-06-16 02:26:33,355 train.py step  1335 | loss: 3.805510 | lr 6.0000e-05 | norm: 0.5266 | dt: 85510.77ms | tok/sec: 61312.51
2024-06-16 02:27:58,843 train.py step  1336 | loss: 3.753208 | lr 6.0000e-05 | norm: 0.6221 | dt: 85487.44ms | tok/sec: 61329.24
2024-06-16 02:29:24,346 train.py step  1337 | loss: 3.720820 | lr 6.0000e-05 | norm: 0.6584 | dt: 85501.95ms | tok/sec: 61318.84
2024-06-16 02:30:49,845 train.py step  1338 | loss: 3.677492 | lr 6.0000e-05 | norm: 0.6059 | dt: 85499.14ms | tok/sec: 61320.85
2024-06-16 02:32:15,336 train.py step  1339 | loss: 3.686137 | lr 6.0000e-05 | norm: 0.5368 | dt: 85490.12ms | tok/sec: 61327.32
2024-06-16 02:33:40,845 train.py step  1340 | loss: 3.768529 | lr 6.0000e-05 | norm: 0.5501 | dt: 85508.61ms | tok/sec: 61314.06
2024-06-16 02:35:06,321 train.py step  1341 | loss: 3.761126 | lr 6.0000e-05 | norm: 0.5986 | dt: 85475.67ms | tok/sec: 61337.69
2024-06-16 02:36:31,783 train.py step  1342 | loss: 3.725764 | lr 6.0000e-05 | norm: 0.5394 | dt: 85461.43ms | tok/sec: 61347.91
2024-06-16 02:37:57,258 train.py step  1343 | loss: 3.656579 | lr 6.0000e-05 | norm: 0.5506 | dt: 85475.58ms | tok/sec: 61337.75
2024-06-16 02:39:22,763 train.py step  1344 | loss: 3.733876 | lr 6.0000e-05 | norm: 0.5896 | dt: 85504.34ms | tok/sec: 61317.12
2024-06-16 02:40:48,249 train.py step  1345 | loss: 3.762126 | lr 6.0000e-05 | norm: 0.4947 | dt: 85484.95ms | tok/sec: 61331.03
2024-06-16 02:42:13,740 train.py step  1346 | loss: 3.731737 | lr 6.0000e-05 | norm: 0.5238 | dt: 85491.38ms | tok/sec: 61326.41
2024-06-16 02:43:39,266 train.py step  1347 | loss: 3.699572 | lr 6.0000e-05 | norm: 0.5275 | dt: 85525.14ms | tok/sec: 61302.21
2024-06-16 02:45:04,825 train.py step  1348 | loss: 3.657853 | lr 6.0000e-05 | norm: 0.5222 | dt: 85558.94ms | tok/sec: 61277.99
2024-06-16 02:46:30,355 train.py step  1349 | loss: 3.791274 | lr 6.0000e-05 | norm: 0.6051 | dt: 85529.40ms | tok/sec: 61299.15
2024-06-16 02:47:55,838 train.py step  1350 | loss: 3.756028 | lr 6.0000e-05 | norm: 0.5874 | dt: 85482.36ms | tok/sec: 61332.89
2024-06-16 02:49:21,341 train.py step  1351 | loss: 3.722208 | lr 6.0000e-05 | norm: 0.5532 | dt: 85502.56ms | tok/sec: 61318.40
2024-06-16 02:50:46,828 train.py step  1352 | loss: 3.658417 | lr 6.0000e-05 | norm: 0.5592 | dt: 85486.69ms | tok/sec: 61329.78
2024-06-16 02:52:12,346 train.py step  1353 | loss: 3.688371 | lr 6.0000e-05 | norm: 0.5800 | dt: 85518.28ms | tok/sec: 61307.13
2024-06-16 02:53:37,883 train.py step  1354 | loss: 3.800883 | lr 6.0000e-05 | norm: 0.5768 | dt: 85536.48ms | tok/sec: 61294.08
2024-06-16 02:55:03,422 train.py step  1355 | loss: 3.759684 | lr 6.0000e-05 | norm: 0.6166 | dt: 85538.87ms | tok/sec: 61292.37
2024-06-16 02:56:28,925 train.py step  1356 | loss: 3.702836 | lr 6.0000e-05 | norm: 0.5605 | dt: 85501.88ms | tok/sec: 61318.89
2024-06-16 02:57:54,391 train.py step  1357 | loss: 3.672448 | lr 6.0000e-05 | norm: 0.5063 | dt: 85465.77ms | tok/sec: 61344.80
2024-06-16 02:59:19,835 train.py step  1358 | loss: 3.669938 | lr 6.0000e-05 | norm: 0.5341 | dt: 85443.42ms | tok/sec: 61360.84
2024-06-16 03:00:45,255 train.py step  1359 | loss: 3.762876 | lr 6.0000e-05 | norm: 0.5989 | dt: 85420.16ms | tok/sec: 61377.55
2024-06-16 03:02:10,682 train.py step  1360 | loss: 3.752140 | lr 6.0000e-05 | norm: 0.5764 | dt: 85426.03ms | tok/sec: 61373.33
2024-06-16 03:03:36,114 train.py step  1361 | loss: 3.719078 | lr 6.0000e-05 | norm: 0.6352 | dt: 85432.06ms | tok/sec: 61369.00
2024-06-16 03:05:01,591 train.py step  1362 | loss: 3.656031 | lr 6.0000e-05 | norm: 0.6263 | dt: 85476.57ms | tok/sec: 61337.04
2024-06-16 03:06:27,069 train.py step  1363 | loss: 3.715677 | lr 6.0000e-05 | norm: 0.5635 | dt: 85477.18ms | tok/sec: 61336.61
2024-06-16 03:07:52,506 train.py step  1364 | loss: 3.760824 | lr 6.0000e-05 | norm: 0.5459 | dt: 85436.85ms | tok/sec: 61365.56
2024-06-16 03:09:17,971 train.py step  1365 | loss: 3.718755 | lr 6.0000e-05 | norm: 0.5263 | dt: 85465.09ms | tok/sec: 61345.28
2024-06-16 03:10:43,428 train.py step  1366 | loss: 3.700182 | lr 6.0000e-05 | norm: 0.5969 | dt: 85456.15ms | tok/sec: 61351.70
2024-06-16 03:12:08,857 train.py step  1367 | loss: 3.644439 | lr 6.0000e-05 | norm: 0.5642 | dt: 85428.77ms | tok/sec: 61371.36
2024-06-16 03:13:34,297 train.py step  1368 | loss: 3.775405 | lr 6.0000e-05 | norm: 0.5237 | dt: 85440.16ms | tok/sec: 61363.18
2024-06-16 03:14:59,741 train.py step  1369 | loss: 3.749558 | lr 6.0000e-05 | norm: 0.5342 | dt: 85442.98ms | tok/sec: 61361.15
2024-06-16 03:16:25,195 train.py step  1370 | loss: 3.720311 | lr 6.0000e-05 | norm: 0.4830 | dt: 85453.45ms | tok/sec: 61353.64
2024-06-16 03:17:50,653 train.py step  1371 | loss: 3.655023 | lr 6.0000e-05 | norm: 0.5251 | dt: 85457.94ms | tok/sec: 61350.42
2024-06-16 03:19:16,132 train.py step  1372 | loss: 3.668589 | lr 6.0000e-05 | norm: 0.5260 | dt: 85478.50ms | tok/sec: 61335.66
2024-06-16 03:20:41,587 train.py step  1373 | loss: 3.787065 | lr 6.0000e-05 | norm: 0.5371 | dt: 85454.35ms | tok/sec: 61352.99
2024-06-16 03:22:07,048 train.py step  1374 | loss: 3.757285 | lr 6.0000e-05 | norm: 0.5886 | dt: 85461.39ms | tok/sec: 61347.94
2024-06-16 03:23:32,501 train.py step  1375 | loss: 3.696039 | lr 6.0000e-05 | norm: 0.5882 | dt: 85452.59ms | tok/sec: 61354.26
2024-06-16 03:24:57,951 train.py step  1376 | loss: 3.671517 | lr 6.0000e-05 | norm: 0.5656 | dt: 85449.45ms | tok/sec: 61356.51
2024-06-16 03:26:23,451 train.py step  1377 | loss: 3.648661 | lr 6.0000e-05 | norm: 0.5638 | dt: 85498.71ms | tok/sec: 61321.16
2024-06-16 03:27:48,958 train.py step  1378 | loss: 3.759441 | lr 6.0000e-05 | norm: 0.5891 | dt: 85506.67ms | tok/sec: 61315.45
2024-06-16 03:29:14,432 train.py step  1379 | loss: 3.742863 | lr 6.0000e-05 | norm: 0.5013 | dt: 85474.03ms | tok/sec: 61338.86
2024-06-16 03:30:39,904 train.py step  1380 | loss: 3.712189 | lr 6.0000e-05 | norm: 0.5674 | dt: 85471.50ms | tok/sec: 61340.68
2024-06-16 03:32:05,362 train.py step  1381 | loss: 3.653007 | lr 6.0000e-05 | norm: 0.5921 | dt: 85457.70ms | tok/sec: 61350.59
2024-06-16 03:33:30,830 train.py step  1382 | loss: 3.703413 | lr 6.0000e-05 | norm: 0.5411 | dt: 85467.65ms | tok/sec: 61343.45
2024-06-16 03:34:56,332 train.py step  1383 | loss: 3.752224 | lr 6.0000e-05 | norm: 0.5624 | dt: 85501.03ms | tok/sec: 61319.50
2024-06-16 03:36:21,830 train.py step  1384 | loss: 3.710469 | lr 6.0000e-05 | norm: 0.5857 | dt: 85498.33ms | tok/sec: 61321.43
2024-06-16 03:37:47,303 train.py step  1385 | loss: 3.696390 | lr 6.0000e-05 | norm: 0.5344 | dt: 85472.76ms | tok/sec: 61339.78
2024-06-16 03:39:12,766 train.py step  1386 | loss: 3.634711 | lr 6.0000e-05 | norm: 0.6200 | dt: 85461.90ms | tok/sec: 61347.57
2024-06-16 03:40:38,219 train.py step  1387 | loss: 3.755436 | lr 6.0000e-05 | norm: 0.6608 | dt: 85453.41ms | tok/sec: 61353.66
2024-06-16 03:42:03,692 train.py step  1388 | loss: 3.746695 | lr 6.0000e-05 | norm: 0.5748 | dt: 85471.65ms | tok/sec: 61340.57
2024-06-16 03:43:29,213 train.py step  1389 | loss: 3.716238 | lr 6.0000e-05 | norm: 0.5912 | dt: 85521.21ms | tok/sec: 61305.03
2024-06-16 03:44:54,741 train.py step  1390 | loss: 3.659077 | lr 6.0000e-05 | norm: 0.6328 | dt: 85527.93ms | tok/sec: 61300.21
2024-06-16 03:46:20,250 train.py step  1391 | loss: 3.650015 | lr 6.0000e-05 | norm: 0.6469 | dt: 85508.24ms | tok/sec: 61314.32
2024-06-16 03:47:45,761 train.py step  1392 | loss: 3.777003 | lr 6.0000e-05 | norm: 0.6581 | dt: 85510.31ms | tok/sec: 61312.84
2024-06-16 03:49:11,265 train.py step  1393 | loss: 3.755500 | lr 6.0000e-05 | norm: 0.6302 | dt: 85504.01ms | tok/sec: 61317.36
2024-06-16 03:50:36,744 train.py step  1394 | loss: 3.690677 | lr 6.0000e-05 | norm: 0.5727 | dt: 85478.30ms | tok/sec: 61335.80
2024-06-16 03:52:02,210 train.py step  1395 | loss: 3.673311 | lr 6.0000e-05 | norm: 0.6122 | dt: 85465.15ms | tok/sec: 61345.24
2024-06-16 03:53:27,674 train.py step  1396 | loss: 3.626864 | lr 6.0000e-05 | norm: 0.6064 | dt: 85464.31ms | tok/sec: 61345.84
2024-06-16 03:54:53,156 train.py step  1397 | loss: 3.757471 | lr 6.0000e-05 | norm: 0.6351 | dt: 85481.20ms | tok/sec: 61333.72
2024-06-16 03:56:18,661 train.py step  1398 | loss: 3.730577 | lr 6.0000e-05 | norm: 0.6905 | dt: 85504.60ms | tok/sec: 61316.93
2024-06-16 03:57:44,157 train.py step  1399 | loss: 3.710306 | lr 6.0000e-05 | norm: 0.5638 | dt: 85496.05ms | tok/sec: 61323.07
2024-06-16 03:59:09,638 train.py step  1400 | loss: 3.653260 | lr 6.0000e-05 | norm: 0.5632 | dt: 85480.70ms | tok/sec: 61334.08
2024-06-16 04:00:35,125 train.py step  1401 | loss: 3.686929 | lr 6.0000e-05 | norm: 0.5911 | dt: 85486.52ms | tok/sec: 61329.90
2024-06-16 04:02:00,632 train.py step  1402 | loss: 3.740802 | lr 6.0000e-05 | norm: 0.5512 | dt: 85506.21ms | tok/sec: 61315.78
2024-06-16 04:03:26,141 train.py step  1403 | loss: 3.705403 | lr 6.0000e-05 | norm: 0.5039 | dt: 85508.64ms | tok/sec: 61314.04
2024-06-16 04:04:51,647 train.py step  1404 | loss: 3.691669 | lr 6.0000e-05 | norm: 0.5599 | dt: 85505.88ms | tok/sec: 61316.02
2024-06-16 04:06:17,170 train.py step  1405 | loss: 3.628163 | lr 6.0000e-05 | norm: 0.4922 | dt: 85522.50ms | tok/sec: 61304.10
2024-06-16 04:07:42,640 train.py step  1406 | loss: 3.737460 | lr 6.0000e-05 | norm: 0.5162 | dt: 85469.09ms | tok/sec: 61342.41
2024-06-16 04:09:08,113 train.py step  1407 | loss: 3.738514 | lr 6.0000e-05 | norm: 0.5360 | dt: 85472.86ms | tok/sec: 61339.71
2024-06-16 04:10:33,595 train.py step  1408 | loss: 3.711914 | lr 6.0000e-05 | norm: 0.5259 | dt: 85482.28ms | tok/sec: 61332.95
2024-06-16 04:11:59,077 train.py step  1409 | loss: 3.652456 | lr 6.0000e-05 | norm: 0.4706 | dt: 85481.60ms | tok/sec: 61333.43
2024-06-16 04:13:24,547 train.py step  1410 | loss: 3.636362 | lr 6.0000e-05 | norm: 0.4748 | dt: 85469.05ms | tok/sec: 61342.44
2024-06-16 04:14:50,016 train.py step  1411 | loss: 3.766611 | lr 6.0000e-05 | norm: 0.5265 | dt: 85468.78ms | tok/sec: 61342.63
2024-06-16 04:16:15,468 train.py step  1412 | loss: 3.747569 | lr 6.0000e-05 | norm: 0.6270 | dt: 85451.12ms | tok/sec: 61355.31
2024-06-16 04:17:40,932 train.py step  1413 | loss: 3.688474 | lr 6.0000e-05 | norm: 0.6964 | dt: 85464.42ms | tok/sec: 61345.76
2024-06-16 04:19:06,381 train.py step  1414 | loss: 3.673756 | lr 6.0000e-05 | norm: 0.6892 | dt: 85448.42ms | tok/sec: 61357.25
2024-06-16 04:20:31,856 train.py step  1415 | loss: 3.606349 | lr 6.0000e-05 | norm: 0.7305 | dt: 85474.14ms | tok/sec: 61338.78
2024-06-16 04:21:57,353 train.py step  1416 | loss: 3.752023 | lr 6.0000e-05 | norm: 0.7364 | dt: 85497.04ms | tok/sec: 61322.36
2024-06-16 04:23:22,824 train.py step  1417 | loss: 3.719422 | lr 6.0000e-05 | norm: 0.5991 | dt: 85470.65ms | tok/sec: 61341.29
2024-06-16 04:24:48,308 train.py step  1418 | loss: 3.714025 | lr 6.0000e-05 | norm: 0.6754 | dt: 85483.52ms | tok/sec: 61332.06
2024-06-16 04:26:13,787 train.py step  1419 | loss: 3.646948 | lr 6.0000e-05 | norm: 0.6306 | dt: 85478.95ms | tok/sec: 61335.34
2024-06-16 04:27:39,300 train.py step  1420 | loss: 3.670005 | lr 6.0000e-05 | norm: 0.5162 | dt: 85512.04ms | tok/sec: 61311.60
2024-06-16 04:29:04,799 train.py step  1421 | loss: 3.737770 | lr 6.0000e-05 | norm: 0.5628 | dt: 85498.62ms | tok/sec: 61321.23
2024-06-16 04:30:30,286 train.py step  1422 | loss: 3.699363 | lr 6.0000e-05 | norm: 0.6285 | dt: 85487.23ms | tok/sec: 61329.40
2024-06-16 04:31:55,801 train.py step  1423 | loss: 3.686262 | lr 6.0000e-05 | norm: 0.5584 | dt: 85513.85ms | tok/sec: 61310.30
2024-06-16 04:33:21,303 train.py step  1424 | loss: 3.628305 | lr 6.0000e-05 | norm: 0.6733 | dt: 85501.52ms | tok/sec: 61319.14
2024-06-16 04:34:46,820 train.py step  1425 | loss: 3.714261 | lr 6.0000e-05 | norm: 0.6693 | dt: 85516.48ms | tok/sec: 61308.42
2024-06-16 04:36:12,369 train.py step  1426 | loss: 3.731439 | lr 6.0000e-05 | norm: 0.6226 | dt: 85548.66ms | tok/sec: 61285.35
2024-06-16 04:37:37,927 train.py step  1427 | loss: 3.712789 | lr 6.0000e-05 | norm: 0.6271 | dt: 85558.30ms | tok/sec: 61278.45
2024-06-16 04:39:03,480 train.py step  1428 | loss: 3.648072 | lr 6.0000e-05 | norm: 0.5049 | dt: 85552.24ms | tok/sec: 61282.79
2024-06-16 04:40:29,062 train.py step  1429 | loss: 3.623768 | lr 6.0000e-05 | norm: 0.5134 | dt: 85581.85ms | tok/sec: 61261.59
2024-06-16 04:41:54,573 train.py step  1430 | loss: 3.750630 | lr 6.0000e-05 | norm: 0.5370 | dt: 85510.26ms | tok/sec: 61312.88
2024-06-16 04:43:20,067 train.py step  1431 | loss: 3.748735 | lr 6.0000e-05 | norm: 0.5818 | dt: 85493.80ms | tok/sec: 61324.68
2024-06-16 04:44:45,537 train.py step  1432 | loss: 3.686687 | lr 6.0000e-05 | norm: 0.5630 | dt: 85469.53ms | tok/sec: 61342.10
2024-06-16 04:46:11,026 train.py step  1433 | loss: 3.661341 | lr 6.0000e-05 | norm: 0.4793 | dt: 85488.66ms | tok/sec: 61328.37
2024-06-16 04:47:36,518 train.py step  1434 | loss: 3.599774 | lr 6.0000e-05 | norm: 0.5946 | dt: 85491.32ms | tok/sec: 61326.46
2024-06-16 04:49:01,990 train.py step  1435 | loss: 3.735809 | lr 6.0000e-05 | norm: 0.6198 | dt: 85472.07ms | tok/sec: 61340.27
2024-06-16 04:50:27,467 train.py step  1436 | loss: 3.713418 | lr 6.0000e-05 | norm: 0.6072 | dt: 85476.46ms | tok/sec: 61337.12
2024-06-16 04:51:52,941 train.py step  1437 | loss: 3.706101 | lr 6.0000e-05 | norm: 0.6185 | dt: 85473.43ms | tok/sec: 61339.29
2024-06-16 04:53:18,417 train.py step  1438 | loss: 3.648217 | lr 6.0000e-05 | norm: 0.6219 | dt: 85476.16ms | tok/sec: 61337.33
2024-06-16 04:54:43,934 train.py step  1439 | loss: 3.648249 | lr 6.0000e-05 | norm: 0.5483 | dt: 85516.27ms | tok/sec: 61308.57
2024-06-16 04:56:09,430 train.py step  1440 | loss: 3.734264 | lr 6.0000e-05 | norm: 0.5230 | dt: 85495.97ms | tok/sec: 61323.13
2024-06-16 04:57:34,935 train.py step  1441 | loss: 3.689548 | lr 6.0000e-05 | norm: 0.5125 | dt: 85504.50ms | tok/sec: 61317.01
2024-06-16 04:59:00,443 train.py step  1442 | loss: 3.681378 | lr 6.0000e-05 | norm: 0.4933 | dt: 85507.15ms | tok/sec: 61315.11
2024-06-16 05:00:25,959 train.py step  1443 | loss: 3.627637 | lr 6.0000e-05 | norm: 0.4985 | dt: 85515.75ms | tok/sec: 61308.94
2024-06-16 05:01:51,472 train.py step  1444 | loss: 3.693951 | lr 6.0000e-05 | norm: 0.5549 | dt: 85513.07ms | tok/sec: 61310.86
2024-06-16 05:03:16,956 train.py step  1445 | loss: 3.730128 | lr 6.0000e-05 | norm: 0.6480 | dt: 85483.31ms | tok/sec: 61332.20
2024-06-16 05:04:42,442 train.py step  1446 | loss: 3.705727 | lr 6.0000e-05 | norm: 0.7859 | dt: 85485.69ms | tok/sec: 61330.50
2024-06-16 05:06:07,919 train.py step  1447 | loss: 3.650415 | lr 6.0000e-05 | norm: 0.8868 | dt: 85477.09ms | tok/sec: 61336.67
2024-06-16 05:07:33,394 train.py step  1448 | loss: 3.609020 | lr 6.0000e-05 | norm: 0.7587 | dt: 85473.89ms | tok/sec: 61338.97
2024-06-16 05:08:58,878 train.py step  1449 | loss: 3.741126 | lr 6.0000e-05 | norm: 0.6492 | dt: 85483.72ms | tok/sec: 61331.91
2024-06-16 05:10:24,388 train.py step  1450 | loss: 3.744779 | lr 6.0000e-05 | norm: 0.7031 | dt: 85510.29ms | tok/sec: 61312.86
2024-06-16 05:11:49,882 train.py step  1451 | loss: 3.686069 | lr 6.0000e-05 | norm: 0.6595 | dt: 85493.54ms | tok/sec: 61324.87
2024-06-16 05:13:15,399 train.py step  1452 | loss: 3.661025 | lr 6.0000e-05 | norm: 0.5618 | dt: 85515.74ms | tok/sec: 61308.94
2024-06-16 05:14:40,922 train.py step  1453 | loss: 3.592029 | lr 6.0000e-05 | norm: 0.6814 | dt: 85523.54ms | tok/sec: 61303.36
2024-06-16 05:16:06,406 train.py step  1454 | loss: 3.720515 | lr 6.0000e-05 | norm: 0.7036 | dt: 85483.16ms | tok/sec: 61332.31
2024-06-16 05:17:31,875 train.py step  1455 | loss: 3.698421 | lr 6.0000e-05 | norm: 0.7115 | dt: 85469.06ms | tok/sec: 61342.43
2024-06-16 05:18:57,361 train.py step  1456 | loss: 3.711791 | lr 6.0000e-05 | norm: 0.7006 | dt: 85485.66ms | tok/sec: 61330.52
2024-06-16 05:20:22,846 train.py step  1457 | loss: 3.646928 | lr 6.0000e-05 | norm: 0.6410 | dt: 85484.64ms | tok/sec: 61331.25
2024-06-16 05:21:48,325 train.py step  1458 | loss: 3.631785 | lr 6.0000e-05 | norm: 0.6046 | dt: 85478.36ms | tok/sec: 61335.76
2024-06-16 05:23:13,826 train.py step  1459 | loss: 3.728985 | lr 6.0000e-05 | norm: 0.6153 | dt: 85499.84ms | tok/sec: 61320.35
2024-06-16 05:24:39,334 train.py step  1460 | loss: 3.685920 | lr 6.0000e-05 | norm: 0.5877 | dt: 85507.93ms | tok/sec: 61314.55
2024-06-16 05:26:04,846 train.py step  1461 | loss: 3.674686 | lr 6.0000e-05 | norm: 0.5461 | dt: 85512.10ms | tok/sec: 61311.56
2024-06-16 05:27:30,373 train.py step  1462 | loss: 3.624148 | lr 6.0000e-05 | norm: 0.5380 | dt: 85526.38ms | tok/sec: 61301.32
2024-06-16 05:28:55,891 train.py step  1463 | loss: 3.682566 | lr 6.0000e-05 | norm: 0.5436 | dt: 85517.71ms | tok/sec: 61307.54
2024-06-16 05:30:21,388 train.py step  1464 | loss: 3.720973 | lr 6.0000e-05 | norm: 0.5432 | dt: 85496.08ms | tok/sec: 61323.04
2024-06-16 05:31:46,892 train.py step  1465 | loss: 3.698213 | lr 6.0000e-05 | norm: 0.5270 | dt: 85504.01ms | tok/sec: 61317.36
2024-06-16 05:33:12,411 train.py step  1466 | loss: 3.644214 | lr 6.0000e-05 | norm: 0.5447 | dt: 85518.15ms | tok/sec: 61307.22
2024-06-16 05:34:37,894 train.py step  1467 | loss: 3.593714 | lr 6.0000e-05 | norm: 0.5403 | dt: 85483.51ms | tok/sec: 61332.06
2024-06-16 05:36:03,388 train.py step  1468 | loss: 3.730341 | lr 6.0000e-05 | norm: 0.5744 | dt: 85493.00ms | tok/sec: 61325.26
2024-06-16 05:37:28,887 train.py step  1469 | loss: 3.735711 | lr 6.0000e-05 | norm: 0.5953 | dt: 85498.35ms | tok/sec: 61321.41
2024-06-16 05:38:54,387 train.py step  1470 | loss: 3.681983 | lr 6.0000e-05 | norm: 0.6151 | dt: 85500.28ms | tok/sec: 61320.03
2024-06-16 05:40:19,891 train.py step  1471 | loss: 3.656582 | lr 6.0000e-05 | norm: 0.5458 | dt: 85503.36ms | tok/sec: 61317.83
2024-06-16 05:41:45,401 train.py step  1472 | loss: 3.586989 | lr 6.0000e-05 | norm: 0.5701 | dt: 85509.24ms | tok/sec: 61313.61
2024-06-16 05:43:10,915 train.py step  1473 | loss: 3.702944 | lr 6.0000e-05 | norm: 0.5624 | dt: 85514.20ms | tok/sec: 61310.05
2024-06-16 05:44:36,444 train.py step  1474 | loss: 3.688395 | lr 6.0000e-05 | norm: 0.4894 | dt: 85528.36ms | tok/sec: 61299.90
2024-06-16 05:46:01,982 train.py step  1475 | loss: 3.704163 | lr 6.0000e-05 | norm: 0.5553 | dt: 85538.10ms | tok/sec: 61292.92
2024-06-16 05:47:27,535 train.py step  1476 | loss: 3.645807 | lr 6.0000e-05 | norm: 0.5047 | dt: 85552.27ms | tok/sec: 61282.77
2024-06-16 05:48:53,075 train.py step  1477 | loss: 3.609409 | lr 6.0000e-05 | norm: 0.5522 | dt: 85539.26ms | tok/sec: 61292.09
2024-06-16 05:50:18,571 train.py step  1478 | loss: 3.723284 | lr 6.0000e-05 | norm: 0.6270 | dt: 85496.20ms | tok/sec: 61322.96
2024-06-16 05:51:44,055 train.py step  1479 | loss: 3.682288 | lr 6.0000e-05 | norm: 0.6341 | dt: 85483.18ms | tok/sec: 61332.30
2024-06-16 05:53:09,541 train.py step  1480 | loss: 3.671223 | lr 6.0000e-05 | norm: 0.7011 | dt: 85485.91ms | tok/sec: 61330.34
2024-06-16 05:54:35,065 train.py step  1481 | loss: 3.619529 | lr 6.0000e-05 | norm: 0.7670 | dt: 85523.98ms | tok/sec: 61303.04
2024-06-16 05:56:00,581 train.py step  1482 | loss: 3.675474 | lr 6.0000e-05 | norm: 0.7919 | dt: 85515.29ms | tok/sec: 61309.27
2024-06-16 05:57:26,049 train.py step  1483 | loss: 3.712679 | lr 6.0000e-05 | norm: 0.7328 | dt: 85467.80ms | tok/sec: 61343.34
2024-06-16 05:58:51,510 train.py step  1484 | loss: 3.695517 | lr 6.0000e-05 | norm: 0.6349 | dt: 85459.76ms | tok/sec: 61349.11
2024-06-16 06:00:16,967 train.py step  1485 | loss: 3.644436 | lr 6.0000e-05 | norm: 0.6475 | dt: 85457.23ms | tok/sec: 61350.93
2024-06-16 06:01:42,452 train.py step  1486 | loss: 3.585617 | lr 6.0000e-05 | norm: 0.6240 | dt: 85484.92ms | tok/sec: 61331.05
2024-06-16 06:03:07,981 train.py step  1487 | loss: 3.714914 | lr 6.0000e-05 | norm: 0.6316 | dt: 85527.84ms | tok/sec: 61300.27
2024-06-16 06:04:33,468 train.py step  1488 | loss: 3.728423 | lr 6.0000e-05 | norm: 0.5905 | dt: 85486.50ms | tok/sec: 61329.91
2024-06-16 06:05:58,953 train.py step  1489 | loss: 3.675495 | lr 6.0000e-05 | norm: 0.5352 | dt: 85485.14ms | tok/sec: 61330.89
2024-06-16 06:07:24,426 train.py step  1490 | loss: 3.655363 | lr 6.0000e-05 | norm: 0.5824 | dt: 85472.18ms | tok/sec: 61340.19
2024-06-16 06:08:49,925 train.py step  1491 | loss: 3.582323 | lr 6.0000e-05 | norm: 0.5520 | dt: 85498.96ms | tok/sec: 61320.98
2024-06-16 06:10:15,405 train.py step  1492 | loss: 3.688092 | lr 6.0000e-05 | norm: 0.5714 | dt: 85480.17ms | tok/sec: 61334.46
2024-06-16 06:11:40,896 train.py step  1493 | loss: 3.680933 | lr 6.0000e-05 | norm: 0.6393 | dt: 85489.74ms | tok/sec: 61327.59
2024-06-16 06:13:06,382 train.py step  1494 | loss: 3.699348 | lr 6.0000e-05 | norm: 0.6435 | dt: 85485.93ms | tok/sec: 61330.33
2024-06-16 06:14:31,871 train.py step  1495 | loss: 3.646070 | lr 6.0000e-05 | norm: 0.6131 | dt: 85488.17ms | tok/sec: 61328.72
2024-06-16 06:15:57,314 train.py step  1496 | loss: 3.592011 | lr 6.0000e-05 | norm: 0.6254 | dt: 85443.16ms | tok/sec: 61361.03
2024-06-16 06:17:22,760 train.py step  1497 | loss: 3.715705 | lr 6.0000e-05 | norm: 0.5791 | dt: 85445.49ms | tok/sec: 61359.35
2024-06-16 06:18:48,190 train.py step  1498 | loss: 3.677575 | lr 6.0000e-05 | norm: 0.6607 | dt: 85429.61ms | tok/sec: 61370.76
2024-06-16 06:20:13,617 train.py step  1499 | loss: 3.667697 | lr 6.0000e-05 | norm: 0.6575 | dt: 85426.12ms | tok/sec: 61373.26
2024-06-16 06:20:15,789 train.py validation loss: 3.9628
2024-06-16 06:21:42,289 train.py step  1500 | loss: 3.611593 | lr 6.0000e-05 | norm: 0.5433 | dt: 88671.76ms | tok/sec: 59126.83
2024-06-16 06:23:07,680 train.py step  1501 | loss: 3.655654 | lr 6.0000e-05 | norm: 0.5730 | dt: 85390.78ms | tok/sec: 61398.66
2024-06-16 06:24:33,079 train.py step  1502 | loss: 3.711997 | lr 6.0000e-05 | norm: 0.6054 | dt: 85398.36ms | tok/sec: 61393.22
2024-06-16 06:25:58,500 train.py step  1503 | loss: 3.693023 | lr 6.0000e-05 | norm: 0.6084 | dt: 85421.30ms | tok/sec: 61376.73
2024-06-16 06:27:23,951 train.py step  1504 | loss: 3.638709 | lr 6.0000e-05 | norm: 0.6192 | dt: 85450.56ms | tok/sec: 61355.71
2024-06-16 06:28:49,407 train.py step  1505 | loss: 3.572191 | lr 6.0000e-05 | norm: 0.5569 | dt: 85455.42ms | tok/sec: 61352.23
2024-06-16 06:30:14,862 train.py step  1506 | loss: 3.694415 | lr 6.0000e-05 | norm: 0.5678 | dt: 85454.83ms | tok/sec: 61352.65
2024-06-16 06:31:40,327 train.py step  1507 | loss: 3.730541 | lr 6.0000e-05 | norm: 0.5420 | dt: 85464.23ms | tok/sec: 61345.90
2024-06-16 06:33:05,781 train.py step  1508 | loss: 3.675309 | lr 6.0000e-05 | norm: 0.5501 | dt: 85453.21ms | tok/sec: 61353.81
2024-06-16 06:34:31,225 train.py step  1509 | loss: 3.640125 | lr 6.0000e-05 | norm: 0.5875 | dt: 85443.68ms | tok/sec: 61360.66
2024-06-16 06:35:56,663 train.py step  1510 | loss: 3.585982 | lr 6.0000e-05 | norm: 0.5872 | dt: 85437.80ms | tok/sec: 61364.88
2024-06-16 06:37:22,122 train.py step  1511 | loss: 3.666623 | lr 6.0000e-05 | norm: 0.5802 | dt: 85458.71ms | tok/sec: 61349.86
2024-06-16 06:38:47,618 train.py step  1512 | loss: 3.674745 | lr 6.0000e-05 | norm: 0.6428 | dt: 85495.66ms | tok/sec: 61323.34
2024-06-16 06:40:13,078 train.py step  1513 | loss: 3.692348 | lr 6.0000e-05 | norm: 0.6447 | dt: 85459.34ms | tok/sec: 61349.41
2024-06-16 06:41:38,556 train.py step  1514 | loss: 3.646571 | lr 6.0000e-05 | norm: 0.6548 | dt: 85478.31ms | tok/sec: 61335.79
2024-06-16 06:43:04,054 train.py step  1515 | loss: 3.579420 | lr 6.0000e-05 | norm: 0.6841 | dt: 85496.77ms | tok/sec: 61322.55
2024-06-16 06:44:29,508 train.py step  1516 | loss: 3.710877 | lr 6.0000e-05 | norm: 0.7893 | dt: 85454.19ms | tok/sec: 61353.11
2024-06-16 06:45:54,960 train.py step  1517 | loss: 3.674355 | lr 6.0000e-05 | norm: 0.8692 | dt: 85451.96ms | tok/sec: 61354.71
2024-06-16 06:47:20,434 train.py step  1518 | loss: 3.662785 | lr 6.0000e-05 | norm: 0.8668 | dt: 85473.25ms | tok/sec: 61339.43
2024-06-16 06:48:45,917 train.py step  1519 | loss: 3.609659 | lr 6.0000e-05 | norm: 0.8127 | dt: 85483.04ms | tok/sec: 61332.40
2024-06-16 06:50:11,375 train.py step  1520 | loss: 3.644972 | lr 6.0000e-05 | norm: 0.7994 | dt: 85457.37ms | tok/sec: 61350.83
2024-06-16 06:51:36,837 train.py step  1521 | loss: 3.707289 | lr 6.0000e-05 | norm: 0.7801 | dt: 85461.40ms | tok/sec: 61347.93
2024-06-16 06:53:02,317 train.py step  1522 | loss: 3.690801 | lr 6.0000e-05 | norm: 0.7601 | dt: 85479.60ms | tok/sec: 61334.87
2024-06-16 06:54:27,782 train.py step  1523 | loss: 3.634981 | lr 6.0000e-05 | norm: 0.7045 | dt: 85464.56ms | tok/sec: 61345.66
2024-06-16 06:55:53,240 train.py step  1524 | loss: 3.569341 | lr 6.0000e-05 | norm: 0.6924 | dt: 85457.34ms | tok/sec: 61350.85
2024-06-16 06:57:18,688 train.py step  1525 | loss: 3.679360 | lr 6.0000e-05 | norm: 0.6724 | dt: 85448.01ms | tok/sec: 61357.54
2024-06-16 06:58:44,169 train.py step  1526 | loss: 3.730749 | lr 6.0000e-05 | norm: 0.6069 | dt: 85481.02ms | tok/sec: 61333.85
2024-06-16 07:00:09,615 train.py step  1527 | loss: 3.664731 | lr 6.0000e-05 | norm: 0.6396 | dt: 85445.25ms | tok/sec: 61359.52
2024-06-16 07:01:35,112 train.py step  1528 | loss: 3.629779 | lr 6.0000e-05 | norm: 0.5989 | dt: 85496.25ms | tok/sec: 61322.92
2024-06-16 07:03:00,616 train.py step  1529 | loss: 3.590461 | lr 6.0000e-05 | norm: 0.5706 | dt: 85504.29ms | tok/sec: 61317.16
2024-06-16 07:04:26,103 train.py step  1530 | loss: 3.650478 | lr 6.0000e-05 | norm: 0.6003 | dt: 85486.03ms | tok/sec: 61330.26
2024-06-16 07:05:51,609 train.py step  1531 | loss: 3.667836 | lr 6.0000e-05 | norm: 0.5483 | dt: 85506.23ms | tok/sec: 61315.77
2024-06-16 07:07:17,137 train.py step  1532 | loss: 3.687354 | lr 6.0000e-05 | norm: 0.5708 | dt: 85527.47ms | tok/sec: 61300.54
2024-06-16 07:08:42,630 train.py step  1533 | loss: 3.644804 | lr 6.0000e-05 | norm: 0.5026 | dt: 85492.60ms | tok/sec: 61325.54
2024-06-16 07:10:08,163 train.py step  1534 | loss: 3.563722 | lr 6.0000e-05 | norm: 0.5510 | dt: 85532.16ms | tok/sec: 61297.18
2024-06-16 07:11:33,696 train.py step  1535 | loss: 3.696871 | lr 6.0000e-05 | norm: 0.5640 | dt: 85532.53ms | tok/sec: 61296.91
2024-06-16 07:12:59,223 train.py step  1536 | loss: 3.675110 | lr 6.0000e-05 | norm: 0.5736 | dt: 85526.50ms | tok/sec: 61301.23
2024-06-16 07:14:24,744 train.py step  1537 | loss: 3.648628 | lr 6.0000e-05 | norm: 0.5293 | dt: 85520.61ms | tok/sec: 61305.46
2024-06-16 07:15:50,256 train.py step  1538 | loss: 3.601155 | lr 6.0000e-05 | norm: 0.4918 | dt: 85512.37ms | tok/sec: 61311.36
2024-06-16 07:17:15,791 train.py step  1539 | loss: 3.632630 | lr 6.0000e-05 | norm: 0.5579 | dt: 85533.84ms | tok/sec: 61295.97
2024-06-16 07:18:41,315 train.py step  1540 | loss: 3.699076 | lr 6.0000e-05 | norm: 0.5852 | dt: 85523.75ms | tok/sec: 61303.20
2024-06-16 07:20:06,871 train.py step  1541 | loss: 3.682085 | lr 6.0000e-05 | norm: 0.6626 | dt: 85555.99ms | tok/sec: 61280.10
2024-06-16 07:21:32,368 train.py step  1542 | loss: 3.629878 | lr 6.0000e-05 | norm: 0.7347 | dt: 85496.97ms | tok/sec: 61322.41
2024-06-16 07:22:57,891 train.py step  1543 | loss: 3.566945 | lr 6.0000e-05 | norm: 0.6888 | dt: 85522.29ms | tok/sec: 61304.25
2024-06-16 07:24:23,428 train.py step  1544 | loss: 3.658184 | lr 6.0000e-05 | norm: 0.6380 | dt: 85536.15ms | tok/sec: 61294.32
2024-06-16 07:25:48,960 train.py step  1545 | loss: 3.724077 | lr 6.0000e-05 | norm: 0.6553 | dt: 85531.73ms | tok/sec: 61297.48
2024-06-16 07:27:14,470 train.py step  1546 | loss: 3.660069 | lr 6.0000e-05 | norm: 0.7255 | dt: 85509.96ms | tok/sec: 61313.09
2024-06-16 07:28:39,951 train.py step  1547 | loss: 3.629961 | lr 6.0000e-05 | norm: 0.6617 | dt: 85480.06ms | tok/sec: 61334.54
2024-06-16 07:30:05,445 train.py step  1548 | loss: 3.583630 | lr 6.0000e-05 | norm: 0.6003 | dt: 85493.58ms | tok/sec: 61324.84
2024-06-16 07:31:30,943 train.py step  1549 | loss: 3.632440 | lr 6.0000e-05 | norm: 0.6170 | dt: 85497.56ms | tok/sec: 61321.98
2024-06-16 07:32:56,401 train.py step  1550 | loss: 3.670923 | lr 6.0000e-05 | norm: 0.6410 | dt: 85458.42ms | tok/sec: 61350.07
2024-06-16 07:34:21,852 train.py step  1551 | loss: 3.681079 | lr 6.0000e-05 | norm: 0.6036 | dt: 85449.86ms | tok/sec: 61356.22
2024-06-16 07:35:47,314 train.py step  1552 | loss: 3.635472 | lr 6.0000e-05 | norm: 0.5660 | dt: 85462.38ms | tok/sec: 61347.23
2024-06-16 07:37:12,782 train.py step  1553 | loss: 3.562964 | lr 6.0000e-05 | norm: 0.5528 | dt: 85467.14ms | tok/sec: 61343.81
2024-06-16 07:38:38,283 train.py step  1554 | loss: 3.680635 | lr 6.0000e-05 | norm: 0.5945 | dt: 85500.49ms | tok/sec: 61319.88
2024-06-16 07:40:03,771 train.py step  1555 | loss: 3.669644 | lr 6.0000e-05 | norm: 0.6223 | dt: 85488.18ms | tok/sec: 61328.71
2024-06-16 07:41:29,275 train.py step  1556 | loss: 3.648995 | lr 6.0000e-05 | norm: 0.5853 | dt: 85503.49ms | tok/sec: 61317.73
2024-06-16 07:42:54,764 train.py step  1557 | loss: 3.595244 | lr 6.0000e-05 | norm: 0.5761 | dt: 85488.51ms | tok/sec: 61328.48
2024-06-16 07:44:20,232 train.py step  1558 | loss: 3.613081 | lr 6.0000e-05 | norm: 0.5783 | dt: 85467.34ms | tok/sec: 61343.66
2024-06-16 07:45:45,726 train.py step  1559 | loss: 3.697734 | lr 6.0000e-05 | norm: 0.6215 | dt: 85493.65ms | tok/sec: 61324.79
2024-06-16 07:47:11,203 train.py step  1560 | loss: 3.672760 | lr 6.0000e-05 | norm: 0.6427 | dt: 85476.23ms | tok/sec: 61337.29
2024-06-16 07:48:36,676 train.py step  1561 | loss: 3.630635 | lr 6.0000e-05 | norm: 0.7433 | dt: 85473.47ms | tok/sec: 61339.27
2024-06-16 07:50:02,184 train.py step  1562 | loss: 3.562474 | lr 6.0000e-05 | norm: 0.7153 | dt: 85507.02ms | tok/sec: 61315.20
2024-06-16 07:51:27,678 train.py step  1563 | loss: 3.641435 | lr 6.0000e-05 | norm: 0.6634 | dt: 85493.51ms | tok/sec: 61324.89
2024-06-16 07:52:53,141 train.py step  1564 | loss: 3.720154 | lr 6.0000e-05 | norm: 0.6882 | dt: 85462.68ms | tok/sec: 61347.01
2024-06-16 07:54:18,622 train.py step  1565 | loss: 3.654970 | lr 6.0000e-05 | norm: 0.8089 | dt: 85480.89ms | tok/sec: 61333.94
2024-06-16 07:55:44,116 train.py step  1566 | loss: 3.625470 | lr 6.0000e-05 | norm: 0.8411 | dt: 85493.62ms | tok/sec: 61324.81
2024-06-16 07:57:09,601 train.py step  1567 | loss: 3.582881 | lr 6.0000e-05 | norm: 0.7350 | dt: 85485.01ms | tok/sec: 61330.98
2024-06-16 07:58:35,119 train.py step  1568 | loss: 3.616083 | lr 6.0000e-05 | norm: 0.7426 | dt: 85516.86ms | tok/sec: 61308.14
2024-06-16 08:00:00,637 train.py step  1569 | loss: 3.675099 | lr 6.0000e-05 | norm: 0.6976 | dt: 85518.39ms | tok/sec: 61307.05
2024-06-16 08:01:26,162 train.py step  1570 | loss: 3.667411 | lr 6.0000e-05 | norm: 0.6300 | dt: 85523.66ms | tok/sec: 61303.27
2024-06-16 08:02:51,711 train.py step  1571 | loss: 3.636922 | lr 6.0000e-05 | norm: 0.5991 | dt: 85548.98ms | tok/sec: 61285.13
2024-06-16 08:04:17,218 train.py step  1572 | loss: 3.552974 | lr 6.0000e-05 | norm: 0.6146 | dt: 85506.89ms | tok/sec: 61315.29
2024-06-16 08:05:42,735 train.py step  1573 | loss: 3.667461 | lr 6.0000e-05 | norm: 0.6184 | dt: 85516.29ms | tok/sec: 61308.56
2024-06-16 08:07:08,252 train.py step  1574 | loss: 3.665025 | lr 6.0000e-05 | norm: 0.6324 | dt: 85517.00ms | tok/sec: 61308.04
2024-06-16 08:08:33,746 train.py step  1575 | loss: 3.645786 | lr 6.0000e-05 | norm: 0.6857 | dt: 85493.70ms | tok/sec: 61324.75
2024-06-16 08:09:59,278 train.py step  1576 | loss: 3.599438 | lr 6.0000e-05 | norm: 0.6686 | dt: 85531.31ms | tok/sec: 61297.79
2024-06-16 08:11:24,812 train.py step  1577 | loss: 3.592047 | lr 6.0000e-05 | norm: 0.6390 | dt: 85533.04ms | tok/sec: 61296.55
2024-06-16 08:12:50,331 train.py step  1578 | loss: 3.695473 | lr 6.0000e-05 | norm: 0.6216 | dt: 85519.06ms | tok/sec: 61306.57
2024-06-16 08:14:15,839 train.py step  1579 | loss: 3.660473 | lr 6.0000e-05 | norm: 0.5856 | dt: 85507.86ms | tok/sec: 61314.59
2024-06-16 08:15:41,350 train.py step  1580 | loss: 3.629094 | lr 6.0000e-05 | norm: 0.5721 | dt: 85510.43ms | tok/sec: 61312.75
2024-06-16 08:17:06,831 train.py step  1581 | loss: 3.559991 | lr 6.0000e-05 | norm: 0.5955 | dt: 85480.43ms | tok/sec: 61334.27
2024-06-16 08:18:32,318 train.py step  1582 | loss: 3.627462 | lr 6.0000e-05 | norm: 0.5678 | dt: 85487.05ms | tok/sec: 61329.52
2024-06-16 08:19:57,803 train.py step  1583 | loss: 3.708462 | lr 6.0000e-05 | norm: 0.5772 | dt: 85484.58ms | tok/sec: 61331.30
2024-06-16 08:21:23,308 train.py step  1584 | loss: 3.647475 | lr 6.0000e-05 | norm: 0.5514 | dt: 85504.03ms | tok/sec: 61317.34
2024-06-16 08:22:48,811 train.py step  1585 | loss: 3.621175 | lr 6.0000e-05 | norm: 0.5626 | dt: 85502.95ms | tok/sec: 61318.12
2024-06-16 08:24:14,350 train.py step  1586 | loss: 3.579097 | lr 6.0000e-05 | norm: 0.6623 | dt: 85538.35ms | tok/sec: 61292.74
2024-06-16 08:25:39,839 train.py step  1587 | loss: 3.600308 | lr 6.0000e-05 | norm: 0.7392 | dt: 85489.40ms | tok/sec: 61327.84
2024-06-16 08:27:05,287 train.py step  1588 | loss: 3.667328 | lr 6.0000e-05 | norm: 0.7190 | dt: 85447.42ms | tok/sec: 61357.97
2024-06-16 08:28:30,777 train.py step  1589 | loss: 3.663516 | lr 6.0000e-05 | norm: 0.6540 | dt: 85489.72ms | tok/sec: 61327.61
2024-06-16 08:29:56,271 train.py step  1590 | loss: 3.632801 | lr 6.0000e-05 | norm: 0.7050 | dt: 85492.82ms | tok/sec: 61325.39
2024-06-16 08:31:21,750 train.py step  1591 | loss: 3.552220 | lr 6.0000e-05 | norm: 0.6925 | dt: 85479.48ms | tok/sec: 61334.96
2024-06-16 08:32:47,240 train.py step  1592 | loss: 3.650807 | lr 6.0000e-05 | norm: 0.6203 | dt: 85488.67ms | tok/sec: 61328.36
2024-06-16 08:34:12,710 train.py step  1593 | loss: 3.660860 | lr 6.0000e-05 | norm: 0.6367 | dt: 85470.52ms | tok/sec: 61341.38
2024-06-16 08:35:38,168 train.py step  1594 | loss: 3.636078 | lr 6.0000e-05 | norm: 0.6511 | dt: 85457.17ms | tok/sec: 61350.97
2024-06-16 08:37:03,624 train.py step  1595 | loss: 3.597933 | lr 6.0000e-05 | norm: 0.6339 | dt: 85455.41ms | tok/sec: 61352.23
2024-06-16 08:38:29,097 train.py step  1596 | loss: 3.576284 | lr 6.0000e-05 | norm: 0.5907 | dt: 85473.16ms | tok/sec: 61339.49
2024-06-16 08:39:54,583 train.py step  1597 | loss: 3.689878 | lr 6.0000e-05 | norm: 0.6423 | dt: 85485.08ms | tok/sec: 61330.93
2024-06-16 08:41:20,078 train.py step  1598 | loss: 3.657598 | lr 6.0000e-05 | norm: 0.6583 | dt: 85495.00ms | tok/sec: 61323.82
2024-06-16 08:42:45,631 train.py step  1599 | loss: 3.626555 | lr 6.0000e-05 | norm: 0.5845 | dt: 85552.65ms | tok/sec: 61282.50
2024-06-16 08:44:11,165 train.py step  1600 | loss: 3.557601 | lr 6.0000e-05 | norm: 0.5388 | dt: 85532.84ms | tok/sec: 61296.69
2024-06-16 08:45:36,684 train.py step  1601 | loss: 3.606224 | lr 6.0000e-05 | norm: 0.5844 | dt: 85519.37ms | tok/sec: 61306.35
2024-06-16 08:47:02,199 train.py step  1602 | loss: 3.700659 | lr 6.0000e-05 | norm: 0.6103 | dt: 85514.33ms | tok/sec: 61309.96
2024-06-16 08:48:27,713 train.py step  1603 | loss: 3.646277 | lr 6.0000e-05 | norm: 0.7110 | dt: 85514.00ms | tok/sec: 61310.20
2024-06-16 08:49:53,216 train.py step  1604 | loss: 3.619588 | lr 6.0000e-05 | norm: 0.7848 | dt: 85501.86ms | tok/sec: 61318.90
2024-06-16 08:51:18,708 train.py step  1605 | loss: 3.578367 | lr 6.0000e-05 | norm: 0.8511 | dt: 85491.54ms | tok/sec: 61326.30
2024-06-16 08:52:44,156 train.py step  1606 | loss: 3.585244 | lr 6.0000e-05 | norm: 0.7320 | dt: 85448.02ms | tok/sec: 61357.53
2024-06-16 08:54:09,648 train.py step  1607 | loss: 3.662129 | lr 6.0000e-05 | norm: 0.5901 | dt: 85491.42ms | tok/sec: 61326.39
2024-06-16 08:55:35,164 train.py step  1608 | loss: 3.656790 | lr 6.0000e-05 | norm: 0.7606 | dt: 85515.81ms | tok/sec: 61308.89
2024-06-16 08:57:00,659 train.py step  1609 | loss: 3.627865 | lr 6.0000e-05 | norm: 0.7994 | dt: 85494.09ms | tok/sec: 61324.48
2024-06-16 08:58:26,128 train.py step  1610 | loss: 3.558556 | lr 6.0000e-05 | norm: 0.7712 | dt: 85468.57ms | tok/sec: 61342.78
2024-06-16 08:59:51,589 train.py step  1611 | loss: 3.627752 | lr 6.0000e-05 | norm: 0.7045 | dt: 85461.42ms | tok/sec: 61347.91
2024-06-16 09:01:17,082 train.py step  1612 | loss: 3.658691 | lr 6.0000e-05 | norm: 0.6250 | dt: 85492.37ms | tok/sec: 61325.71
2024-06-16 09:02:42,557 train.py step  1613 | loss: 3.630152 | lr 6.0000e-05 | norm: 0.7244 | dt: 85474.10ms | tok/sec: 61338.82
2024-06-16 09:04:08,045 train.py step  1614 | loss: 3.599285 | lr 6.0000e-05 | norm: 0.6600 | dt: 85488.13ms | tok/sec: 61328.75
2024-06-16 09:05:33,527 train.py step  1615 | loss: 3.557930 | lr 6.0000e-05 | norm: 0.5952 | dt: 85481.88ms | tok/sec: 61333.23
2024-06-16 09:06:59,035 train.py step  1616 | loss: 3.686202 | lr 6.0000e-05 | norm: 0.6116 | dt: 85507.70ms | tok/sec: 61314.71
2024-06-16 09:08:24,547 train.py step  1617 | loss: 3.651620 | lr 6.0000e-05 | norm: 0.6730 | dt: 85510.72ms | tok/sec: 61312.54
2024-06-16 09:09:50,047 train.py step  1618 | loss: 3.622074 | lr 6.0000e-05 | norm: 0.5877 | dt: 85500.43ms | tok/sec: 61319.93
2024-06-16 09:11:15,563 train.py step  1619 | loss: 3.558479 | lr 6.0000e-05 | norm: 0.5470 | dt: 85515.01ms | tok/sec: 61309.47
2024-06-16 09:12:41,083 train.py step  1620 | loss: 3.585010 | lr 6.0000e-05 | norm: 0.5604 | dt: 85520.34ms | tok/sec: 61305.65
2024-06-16 09:14:06,612 train.py step  1621 | loss: 3.695977 | lr 6.0000e-05 | norm: 0.6018 | dt: 85528.13ms | tok/sec: 61300.06
2024-06-16 09:15:32,130 train.py step  1622 | loss: 3.653706 | lr 6.0000e-05 | norm: 0.6057 | dt: 85518.12ms | tok/sec: 61307.24
2024-06-16 09:16:57,626 train.py step  1623 | loss: 3.602623 | lr 6.0000e-05 | norm: 0.6104 | dt: 85494.80ms | tok/sec: 61323.96
2024-06-16 09:18:23,126 train.py step  1624 | loss: 3.573094 | lr 6.0000e-05 | norm: 0.6563 | dt: 85500.04ms | tok/sec: 61320.20
2024-06-16 09:19:48,625 train.py step  1625 | loss: 3.570038 | lr 6.0000e-05 | norm: 0.6304 | dt: 85498.15ms | tok/sec: 61321.56
2024-06-16 09:21:14,130 train.py step  1626 | loss: 3.658194 | lr 6.0000e-05 | norm: 0.6385 | dt: 85505.51ms | tok/sec: 61316.28
2024-06-16 09:22:39,654 train.py step  1627 | loss: 3.650054 | lr 6.0000e-05 | norm: 0.8154 | dt: 85523.26ms | tok/sec: 61303.56
2024-06-16 09:24:05,182 train.py step  1628 | loss: 3.624068 | lr 6.0000e-05 | norm: 0.9490 | dt: 85527.93ms | tok/sec: 61300.21
2024-06-16 09:25:30,710 train.py step  1629 | loss: 3.560119 | lr 6.0000e-05 | norm: 0.8843 | dt: 85527.20ms | tok/sec: 61300.73
2024-06-16 09:26:56,252 train.py step  1630 | loss: 3.614578 | lr 6.0000e-05 | norm: 0.7561 | dt: 85541.19ms | tok/sec: 61290.71
2024-06-16 09:28:21,790 train.py step  1631 | loss: 3.660108 | lr 6.0000e-05 | norm: 0.7481 | dt: 85538.22ms | tok/sec: 61292.83
2024-06-16 09:29:47,303 train.py step  1632 | loss: 3.617395 | lr 6.0000e-05 | norm: 0.7712 | dt: 85512.52ms | tok/sec: 61311.26
2024-06-16 09:31:12,834 train.py step  1633 | loss: 3.602638 | lr 6.0000e-05 | norm: 0.6312 | dt: 85530.66ms | tok/sec: 61298.26
2024-06-16 09:32:38,349 train.py step  1634 | loss: 3.544548 | lr 6.0000e-05 | norm: 0.6766 | dt: 85514.36ms | tok/sec: 61309.94
2024-06-16 09:34:03,870 train.py step  1635 | loss: 3.674810 | lr 6.0000e-05 | norm: 0.7214 | dt: 85520.34ms | tok/sec: 61305.65
2024-06-16 09:35:29,368 train.py step  1636 | loss: 3.648017 | lr 6.0000e-05 | norm: 0.6594 | dt: 85497.84ms | tok/sec: 61321.78
2024-06-16 09:36:54,856 train.py step  1637 | loss: 3.621376 | lr 6.0000e-05 | norm: 0.5858 | dt: 85487.27ms | tok/sec: 61329.37
2024-06-16 09:38:20,374 train.py step  1638 | loss: 3.558438 | lr 6.0000e-05 | norm: 0.6235 | dt: 85517.95ms | tok/sec: 61307.36
2024-06-16 09:39:45,877 train.py step  1639 | loss: 3.567303 | lr 6.0000e-05 | norm: 0.6086 | dt: 85503.16ms | tok/sec: 61317.97
2024-06-16 09:41:11,379 train.py step  1640 | loss: 3.685589 | lr 6.0000e-05 | norm: 0.6137 | dt: 85501.29ms | tok/sec: 61319.31
2024-06-16 09:42:36,862 train.py step  1641 | loss: 3.655274 | lr 6.0000e-05 | norm: 0.5966 | dt: 85482.79ms | tok/sec: 61332.58
2024-06-16 09:44:02,331 train.py step  1642 | loss: 3.596424 | lr 6.0000e-05 | norm: 0.5987 | dt: 85468.53ms | tok/sec: 61342.81
2024-06-16 09:45:27,823 train.py step  1643 | loss: 3.573195 | lr 6.0000e-05 | norm: 0.5948 | dt: 85490.92ms | tok/sec: 61326.75
2024-06-16 09:46:53,293 train.py step  1644 | loss: 3.549829 | lr 6.0000e-05 | norm: 0.6184 | dt: 85470.20ms | tok/sec: 61341.62
2024-06-16 09:48:18,792 train.py step  1645 | loss: 3.657723 | lr 6.0000e-05 | norm: 0.6653 | dt: 85498.90ms | tok/sec: 61321.02
2024-06-16 09:49:44,297 train.py step  1646 | loss: 3.641333 | lr 6.0000e-05 | norm: 0.6687 | dt: 85504.36ms | tok/sec: 61317.11
2024-06-16 09:51:09,778 train.py step  1647 | loss: 3.616372 | lr 6.0000e-05 | norm: 0.6672 | dt: 85480.48ms | tok/sec: 61334.24
2024-06-16 09:52:35,296 train.py step  1648 | loss: 3.556808 | lr 6.0000e-05 | norm: 0.6504 | dt: 85517.85ms | tok/sec: 61307.43
2024-06-16 09:54:00,824 train.py step  1649 | loss: 3.600932 | lr 6.0000e-05 | norm: 0.6455 | dt: 85527.25ms | tok/sec: 61300.69
2024-06-16 09:55:26,355 train.py step  1650 | loss: 3.652693 | lr 6.0000e-05 | norm: 0.7101 | dt: 85530.81ms | tok/sec: 61298.15
2024-06-16 09:56:51,876 train.py step  1651 | loss: 3.609437 | lr 6.0000e-05 | norm: 0.7035 | dt: 85520.26ms | tok/sec: 61305.71
2024-06-16 09:58:17,408 train.py step  1652 | loss: 3.600385 | lr 6.0000e-05 | norm: 0.7008 | dt: 85531.93ms | tok/sec: 61297.34
2024-06-16 09:59:42,948 train.py step  1653 | loss: 3.537458 | lr 6.0000e-05 | norm: 0.6460 | dt: 85539.40ms | tok/sec: 61291.99
2024-06-16 10:01:08,480 train.py step  1654 | loss: 3.652730 | lr 6.0000e-05 | norm: 0.6719 | dt: 85531.80ms | tok/sec: 61297.43
2024-06-16 10:02:34,015 train.py step  1655 | loss: 3.646575 | lr 6.0000e-05 | norm: 0.6225 | dt: 85534.70ms | tok/sec: 61295.36
2024-06-16 10:03:59,522 train.py step  1656 | loss: 3.616853 | lr 6.0000e-05 | norm: 0.5661 | dt: 85506.74ms | tok/sec: 61315.40
2024-06-16 10:05:25,033 train.py step  1657 | loss: 3.560483 | lr 6.0000e-05 | norm: 0.6201 | dt: 85510.18ms | tok/sec: 61312.93
2024-06-16 10:06:50,525 train.py step  1658 | loss: 3.552865 | lr 6.0000e-05 | norm: 0.6125 | dt: 85491.76ms | tok/sec: 61326.15
2024-06-16 10:08:16,005 train.py step  1659 | loss: 3.672230 | lr 6.0000e-05 | norm: 0.6077 | dt: 85479.66ms | tok/sec: 61334.82
2024-06-16 10:09:41,485 train.py step  1660 | loss: 3.653389 | lr 6.0000e-05 | norm: 0.5853 | dt: 85479.82ms | tok/sec: 61334.71
2024-06-16 10:11:06,959 train.py step  1661 | loss: 3.591548 | lr 6.0000e-05 | norm: 0.6304 | dt: 85472.84ms | tok/sec: 61339.72
2024-06-16 10:12:32,460 train.py step  1662 | loss: 3.577473 | lr 6.0000e-05 | norm: 0.6695 | dt: 85500.70ms | tok/sec: 61319.73
2024-06-16 10:13:57,972 train.py step  1663 | loss: 3.528262 | lr 6.0000e-05 | norm: 0.7079 | dt: 85511.51ms | tok/sec: 61311.98
2024-06-16 10:15:23,518 train.py step  1664 | loss: 3.657166 | lr 6.0000e-05 | norm: 0.7347 | dt: 85546.14ms | tok/sec: 61287.16
2024-06-16 10:16:49,030 train.py step  1665 | loss: 3.626430 | lr 6.0000e-05 | norm: 0.6584 | dt: 85512.04ms | tok/sec: 61311.60
2024-06-16 10:18:14,534 train.py step  1666 | loss: 3.618152 | lr 6.0000e-05 | norm: 0.7169 | dt: 85503.61ms | tok/sec: 61317.64
2024-06-16 10:19:40,028 train.py step  1667 | loss: 3.556556 | lr 6.0000e-05 | norm: 0.6322 | dt: 85492.93ms | tok/sec: 61325.31
2024-06-16 10:21:05,529 train.py step  1668 | loss: 3.585637 | lr 6.0000e-05 | norm: 0.6263 | dt: 85501.33ms | tok/sec: 61319.28
2024-06-16 10:22:31,032 train.py step  1669 | loss: 3.640783 | lr 6.0000e-05 | norm: 0.6125 | dt: 85502.44ms | tok/sec: 61318.48
2024-06-16 10:23:56,527 train.py step  1670 | loss: 3.606780 | lr 6.0000e-05 | norm: 0.6091 | dt: 85493.87ms | tok/sec: 61324.63
2024-06-16 10:25:22,030 train.py step  1671 | loss: 3.594411 | lr 6.0000e-05 | norm: 0.6258 | dt: 85503.55ms | tok/sec: 61317.69
2024-06-16 10:26:47,508 train.py step  1672 | loss: 3.535378 | lr 6.0000e-05 | norm: 0.7265 | dt: 85476.89ms | tok/sec: 61336.82
2024-06-16 10:28:12,972 train.py step  1673 | loss: 3.638325 | lr 6.0000e-05 | norm: 0.8954 | dt: 85463.96ms | tok/sec: 61346.10
2024-06-16 10:29:38,443 train.py step  1674 | loss: 3.643082 | lr 6.0000e-05 | norm: 0.9173 | dt: 85470.22ms | tok/sec: 61341.60
2024-06-16 10:31:03,911 train.py step  1675 | loss: 3.616510 | lr 6.0000e-05 | norm: 0.7946 | dt: 85468.35ms | tok/sec: 61342.94
2024-06-16 10:32:29,392 train.py step  1676 | loss: 3.558215 | lr 6.0000e-05 | norm: 0.6937 | dt: 85480.18ms | tok/sec: 61334.46
2024-06-16 10:33:54,867 train.py step  1677 | loss: 3.541576 | lr 6.0000e-05 | norm: 0.6748 | dt: 85474.42ms | tok/sec: 61338.59
2024-06-16 10:35:20,356 train.py step  1678 | loss: 3.666683 | lr 6.0000e-05 | norm: 0.7106 | dt: 85489.34ms | tok/sec: 61327.88
2024-06-16 10:36:45,847 train.py step  1679 | loss: 3.648000 | lr 6.0000e-05 | norm: 0.6907 | dt: 85490.16ms | tok/sec: 61327.29
2024-06-16 10:38:11,318 train.py step  1680 | loss: 3.591063 | lr 6.0000e-05 | norm: 0.7637 | dt: 85470.60ms | tok/sec: 61341.33
2024-06-16 10:39:36,786 train.py step  1681 | loss: 3.576835 | lr 6.0000e-05 | norm: 0.7130 | dt: 85467.54ms | tok/sec: 61343.52
2024-06-16 10:41:02,297 train.py step  1682 | loss: 3.510556 | lr 6.0000e-05 | norm: 0.6638 | dt: 85510.24ms | tok/sec: 61312.89
2024-06-16 10:42:27,797 train.py step  1683 | loss: 3.651867 | lr 6.0000e-05 | norm: 0.7060 | dt: 85500.46ms | tok/sec: 61319.90
2024-06-16 10:43:53,300 train.py step  1684 | loss: 3.620516 | lr 6.0000e-05 | norm: 0.7092 | dt: 85502.55ms | tok/sec: 61318.40
2024-06-16 10:45:18,837 train.py step  1685 | loss: 3.618135 | lr 6.0000e-05 | norm: 0.8138 | dt: 85536.52ms | tok/sec: 61294.05
2024-06-16 10:46:44,401 train.py step  1686 | loss: 3.553602 | lr 6.0000e-05 | norm: 0.6413 | dt: 85563.00ms | tok/sec: 61275.09
2024-06-16 10:48:09,927 train.py step  1687 | loss: 3.571120 | lr 6.0000e-05 | norm: 0.5991 | dt: 85525.56ms | tok/sec: 61301.91
2024-06-16 10:49:35,428 train.py step  1688 | loss: 3.639632 | lr 6.0000e-05 | norm: 0.6847 | dt: 85501.09ms | tok/sec: 61319.45
2024-06-16 10:51:00,930 train.py step  1689 | loss: 3.600111 | lr 6.0000e-05 | norm: 0.6331 | dt: 85501.86ms | tok/sec: 61318.90
2024-06-16 10:52:26,433 train.py step  1690 | loss: 3.590587 | lr 6.0000e-05 | norm: 0.5862 | dt: 85502.59ms | tok/sec: 61318.37
2024-06-16 10:53:51,905 train.py step  1691 | loss: 3.534708 | lr 6.0000e-05 | norm: 0.6687 | dt: 85471.18ms | tok/sec: 61340.91
2024-06-16 10:55:17,400 train.py step  1692 | loss: 3.613938 | lr 6.0000e-05 | norm: 0.6645 | dt: 85494.49ms | tok/sec: 61324.19
2024-06-16 10:56:42,875 train.py step  1693 | loss: 3.636101 | lr 6.0000e-05 | norm: 0.6533 | dt: 85475.30ms | tok/sec: 61337.96
2024-06-16 10:58:08,356 train.py step  1694 | loss: 3.614454 | lr 6.0000e-05 | norm: 0.6370 | dt: 85480.36ms | tok/sec: 61334.32
2024-06-16 10:59:33,822 train.py step  1695 | loss: 3.554779 | lr 6.0000e-05 | norm: 0.7639 | dt: 85465.51ms | tok/sec: 61344.98
2024-06-16 11:00:59,291 train.py step  1696 | loss: 3.529274 | lr 6.0000e-05 | norm: 0.7203 | dt: 85468.22ms | tok/sec: 61343.03
2024-06-16 11:02:24,773 train.py step  1697 | loss: 3.652164 | lr 6.0000e-05 | norm: 0.7041 | dt: 85482.10ms | tok/sec: 61333.08
2024-06-16 11:03:50,264 train.py step  1698 | loss: 3.652440 | lr 6.0000e-05 | norm: 0.6842 | dt: 85490.12ms | tok/sec: 61327.32
2024-06-16 11:05:15,753 train.py step  1699 | loss: 3.588982 | lr 6.0000e-05 | norm: 0.6901 | dt: 85489.16ms | tok/sec: 61328.01
2024-06-16 11:06:41,216 train.py step  1700 | loss: 3.568727 | lr 6.0000e-05 | norm: 0.7049 | dt: 85462.36ms | tok/sec: 61347.24
2024-06-16 11:08:06,664 train.py step  1701 | loss: 3.506481 | lr 6.0000e-05 | norm: 0.7126 | dt: 85447.41ms | tok/sec: 61357.97
2024-06-16 11:09:32,105 train.py step  1702 | loss: 3.637285 | lr 6.0000e-05 | norm: 0.7085 | dt: 85440.40ms | tok/sec: 61363.01
2024-06-16 11:10:57,559 train.py step  1703 | loss: 3.617249 | lr 6.0000e-05 | norm: 0.7133 | dt: 85453.60ms | tok/sec: 61353.53
2024-06-16 11:12:23,045 train.py step  1704 | loss: 3.610642 | lr 6.0000e-05 | norm: 0.6993 | dt: 85485.88ms | tok/sec: 61330.37
2024-06-16 11:13:48,536 train.py step  1705 | loss: 3.554864 | lr 6.0000e-05 | norm: 0.6661 | dt: 85490.76ms | tok/sec: 61326.86
2024-06-16 11:15:14,029 train.py step  1706 | loss: 3.552550 | lr 6.0000e-05 | norm: 0.6882 | dt: 85492.60ms | tok/sec: 61325.54
2024-06-16 11:16:39,513 train.py step  1707 | loss: 3.637286 | lr 6.0000e-05 | norm: 0.7007 | dt: 85483.79ms | tok/sec: 61331.86
2024-06-16 11:18:05,019 train.py step  1708 | loss: 3.593009 | lr 6.0000e-05 | norm: 0.6569 | dt: 85505.54ms | tok/sec: 61316.26
2024-06-16 11:19:30,501 train.py step  1709 | loss: 3.589102 | lr 6.0000e-05 | norm: 0.6592 | dt: 85481.79ms | tok/sec: 61333.30
2024-06-16 11:20:56,010 train.py step  1710 | loss: 3.534794 | lr 6.0000e-05 | norm: 0.7401 | dt: 85507.94ms | tok/sec: 61314.54
2024-06-16 11:22:21,508 train.py step  1711 | loss: 3.598520 | lr 6.0000e-05 | norm: 0.7448 | dt: 85498.29ms | tok/sec: 61321.46
2024-06-16 11:23:47,004 train.py step  1712 | loss: 3.634902 | lr 6.0000e-05 | norm: 0.8318 | dt: 85495.41ms | tok/sec: 61323.52
2024-06-16 11:25:12,498 train.py step  1713 | loss: 3.611589 | lr 6.0000e-05 | norm: 0.8783 | dt: 85493.21ms | tok/sec: 61325.11
2024-06-16 11:26:37,988 train.py step  1714 | loss: 3.554527 | lr 6.0000e-05 | norm: 0.7297 | dt: 85489.93ms | tok/sec: 61327.45
2024-06-16 11:28:03,471 train.py step  1715 | loss: 3.514193 | lr 6.0000e-05 | norm: 0.7057 | dt: 85482.48ms | tok/sec: 61332.81
2024-06-16 11:29:28,944 train.py step  1716 | loss: 3.641808 | lr 6.0000e-05 | norm: 0.6814 | dt: 85472.53ms | tok/sec: 61339.94
2024-06-16 11:30:54,393 train.py step  1717 | loss: 3.648701 | lr 6.0000e-05 | norm: 0.7006 | dt: 85448.73ms | tok/sec: 61357.02
2024-06-16 11:32:19,860 train.py step  1718 | loss: 3.589912 | lr 6.0000e-05 | norm: 0.6991 | dt: 85466.50ms | tok/sec: 61344.27
2024-06-16 11:33:45,335 train.py step  1719 | loss: 3.566993 | lr 6.0000e-05 | norm: 0.6459 | dt: 85475.15ms | tok/sec: 61338.06
2024-06-16 11:35:10,803 train.py step  1720 | loss: 3.498635 | lr 6.0000e-05 | norm: 0.6322 | dt: 85467.16ms | tok/sec: 61343.79
2024-06-16 11:36:36,282 train.py step  1721 | loss: 3.623295 | lr 6.0000e-05 | norm: 0.6904 | dt: 85478.66ms | tok/sec: 61335.55
2024-06-16 11:38:01,780 train.py step  1722 | loss: 3.598369 | lr 6.0000e-05 | norm: 0.6830 | dt: 85497.61ms | tok/sec: 61321.95
2024-06-16 11:39:27,271 train.py step  1723 | loss: 3.617935 | lr 6.0000e-05 | norm: 0.6343 | dt: 85490.28ms | tok/sec: 61327.21
2024-06-16 11:40:52,763 train.py step  1724 | loss: 3.554990 | lr 6.0000e-05 | norm: 0.6642 | dt: 85492.26ms | tok/sec: 61325.79
2024-06-16 11:42:18,278 train.py step  1725 | loss: 3.534375 | lr 6.0000e-05 | norm: 0.6321 | dt: 85514.58ms | tok/sec: 61309.78
2024-06-16 11:43:43,816 train.py step  1726 | loss: 3.632742 | lr 6.0000e-05 | norm: 0.7291 | dt: 85537.41ms | tok/sec: 61293.41
2024-06-16 11:45:09,324 train.py step  1727 | loss: 3.589499 | lr 6.0000e-05 | norm: 0.6831 | dt: 85508.06ms | tok/sec: 61314.45
2024-06-16 11:46:34,806 train.py step  1728 | loss: 3.581792 | lr 6.0000e-05 | norm: 0.7204 | dt: 85480.78ms | tok/sec: 61334.02
2024-06-16 11:48:00,282 train.py step  1729 | loss: 3.532449 | lr 6.0000e-05 | norm: 0.6852 | dt: 85476.04ms | tok/sec: 61337.42
2024-06-16 11:49:25,786 train.py step  1730 | loss: 3.587789 | lr 6.0000e-05 | norm: 0.6262 | dt: 85503.29ms | tok/sec: 61317.87
2024-06-16 11:50:51,262 train.py step  1731 | loss: 3.625106 | lr 6.0000e-05 | norm: 0.5946 | dt: 85475.74ms | tok/sec: 61337.64
2024-06-16 11:52:16,748 train.py step  1732 | loss: 3.604218 | lr 6.0000e-05 | norm: 0.6829 | dt: 85485.72ms | tok/sec: 61330.48
2024-06-16 11:53:42,223 train.py step  1733 | loss: 3.553558 | lr 6.0000e-05 | norm: 0.6570 | dt: 85474.87ms | tok/sec: 61338.26
2024-06-16 11:55:07,687 train.py step  1734 | loss: 3.499324 | lr 6.0000e-05 | norm: 0.5955 | dt: 85463.54ms | tok/sec: 61346.39
2024-06-16 11:56:33,142 train.py step  1735 | loss: 3.635612 | lr 6.0000e-05 | norm: 0.7114 | dt: 85454.67ms | tok/sec: 61352.76
2024-06-16 11:57:58,652 train.py step  1736 | loss: 3.638886 | lr 6.0000e-05 | norm: 0.6939 | dt: 85509.40ms | tok/sec: 61313.49
2024-06-16 11:59:24,181 train.py step  1737 | loss: 3.584348 | lr 6.0000e-05 | norm: 0.7305 | dt: 85529.03ms | tok/sec: 61299.42
2024-06-16 12:00:49,681 train.py step  1738 | loss: 3.569482 | lr 6.0000e-05 | norm: 0.7445 | dt: 85498.88ms | tok/sec: 61321.04
2024-06-16 12:02:15,144 train.py step  1739 | loss: 3.496034 | lr 6.0000e-05 | norm: 0.7209 | dt: 85463.11ms | tok/sec: 61346.70
2024-06-16 12:03:40,648 train.py step  1740 | loss: 3.609132 | lr 6.0000e-05 | norm: 0.6999 | dt: 85503.13ms | tok/sec: 61317.99
2024-06-16 12:05:06,184 train.py step  1741 | loss: 3.592643 | lr 6.0000e-05 | norm: 0.7205 | dt: 85535.92ms | tok/sec: 61294.49
2024-06-16 12:06:31,719 train.py step  1742 | loss: 3.610564 | lr 6.0000e-05 | norm: 0.6932 | dt: 85534.35ms | tok/sec: 61295.61
2024-06-16 12:07:57,249 train.py step  1743 | loss: 3.557574 | lr 6.0000e-05 | norm: 0.7182 | dt: 85530.35ms | tok/sec: 61298.47
2024-06-16 12:09:22,771 train.py step  1744 | loss: 3.517264 | lr 6.0000e-05 | norm: 0.7464 | dt: 85520.73ms | tok/sec: 61305.37
2024-06-16 12:10:48,276 train.py step  1745 | loss: 3.628110 | lr 6.0000e-05 | norm: 0.7440 | dt: 85505.27ms | tok/sec: 61316.46
2024-06-16 12:12:13,801 train.py step  1746 | loss: 3.586827 | lr 6.0000e-05 | norm: 0.6618 | dt: 85524.14ms | tok/sec: 61302.93
2024-06-16 12:13:39,362 train.py step  1747 | loss: 3.579641 | lr 6.0000e-05 | norm: 0.7142 | dt: 85560.46ms | tok/sec: 61276.90
2024-06-16 12:15:04,875 train.py step  1748 | loss: 3.522893 | lr 6.0000e-05 | norm: 0.7114 | dt: 85512.68ms | tok/sec: 61311.14
2024-06-16 12:16:30,370 train.py step  1749 | loss: 3.582093 | lr 6.0000e-05 | norm: 0.6196 | dt: 85495.02ms | tok/sec: 61323.80
2024-06-16 12:16:32,651 train.py validation loss: 3.9311
2024-06-16 12:17:59,152 train.py step  1750 | loss: 3.618885 | lr 6.0000e-05 | norm: 0.6871 | dt: 88781.59ms | tok/sec: 59053.68
2024-06-16 12:19:24,629 train.py step  1751 | loss: 3.601851 | lr 6.0000e-05 | norm: 0.7976 | dt: 85476.58ms | tok/sec: 61337.03
2024-06-16 12:20:50,115 train.py step  1752 | loss: 3.552711 | lr 6.0000e-05 | norm: 0.7766 | dt: 85485.27ms | tok/sec: 61330.80
2024-06-16 12:22:15,619 train.py step  1753 | loss: 3.494843 | lr 6.0000e-05 | norm: 0.6981 | dt: 85504.25ms | tok/sec: 61317.18
2024-06-16 12:23:41,103 train.py step  1754 | loss: 3.619813 | lr 6.0000e-05 | norm: 0.7596 | dt: 85483.13ms | tok/sec: 61332.34
2024-06-16 12:25:06,633 train.py step  1755 | loss: 3.634062 | lr 6.0000e-05 | norm: 0.7370 | dt: 85529.59ms | tok/sec: 61299.02
2024-06-16 12:26:32,153 train.py step  1756 | loss: 3.581100 | lr 6.0000e-05 | norm: 0.6794 | dt: 85520.32ms | tok/sec: 61305.66
2024-06-16 12:27:57,627 train.py step  1757 | loss: 3.563665 | lr 6.0000e-05 | norm: 0.6566 | dt: 85473.74ms | tok/sec: 61339.08
2024-06-16 12:29:23,129 train.py step  1758 | loss: 3.494486 | lr 6.0000e-05 | norm: 0.6683 | dt: 85501.26ms | tok/sec: 61319.33
2024-06-16 12:30:48,681 train.py step  1759 | loss: 3.594009 | lr 6.0000e-05 | norm: 0.7703 | dt: 85551.76ms | tok/sec: 61283.13
2024-06-16 12:32:14,257 train.py step  1760 | loss: 3.587241 | lr 6.0000e-05 | norm: 0.7236 | dt: 85575.57ms | tok/sec: 61266.09
2024-06-16 12:33:39,798 train.py step  1761 | loss: 3.606045 | lr 6.0000e-05 | norm: 0.7541 | dt: 85540.40ms | tok/sec: 61291.27
2024-06-16 12:35:05,356 train.py step  1762 | loss: 3.555809 | lr 6.0000e-05 | norm: 0.6639 | dt: 85558.14ms | tok/sec: 61278.56
2024-06-16 12:36:30,888 train.py step  1763 | loss: 3.499144 | lr 6.0000e-05 | norm: 0.6301 | dt: 85531.20ms | tok/sec: 61297.86
2024-06-16 12:37:56,420 train.py step  1764 | loss: 3.623984 | lr 6.0000e-05 | norm: 0.7433 | dt: 85531.58ms | tok/sec: 61297.59
2024-06-16 12:39:21,971 train.py step  1765 | loss: 3.583861 | lr 6.0000e-05 | norm: 0.7966 | dt: 85550.97ms | tok/sec: 61283.70
2024-06-16 12:40:47,498 train.py step  1766 | loss: 3.577518 | lr 6.0000e-05 | norm: 0.8365 | dt: 85525.74ms | tok/sec: 61301.78
2024-06-16 12:42:13,019 train.py step  1767 | loss: 3.521257 | lr 6.0000e-05 | norm: 0.8402 | dt: 85521.02ms | tok/sec: 61305.16
2024-06-16 12:43:38,516 train.py step  1768 | loss: 3.566578 | lr 6.0000e-05 | norm: 0.8078 | dt: 85496.57ms | tok/sec: 61322.69
2024-06-16 12:45:03,997 train.py step  1769 | loss: 3.620937 | lr 6.0000e-05 | norm: 0.7569 | dt: 85481.01ms | tok/sec: 61333.85
2024-06-16 12:46:29,487 train.py step  1770 | loss: 3.601610 | lr 6.0000e-05 | norm: 0.7500 | dt: 85489.06ms | tok/sec: 61328.08
2024-06-16 12:47:54,955 train.py step  1771 | loss: 3.549277 | lr 6.0000e-05 | norm: 0.6681 | dt: 85467.80ms | tok/sec: 61343.33
2024-06-16 12:49:20,390 train.py step  1772 | loss: 3.484461 | lr 6.0000e-05 | norm: 0.7448 | dt: 85434.57ms | tok/sec: 61367.19
2024-06-16 12:50:45,845 train.py step  1773 | loss: 3.599279 | lr 6.0000e-05 | norm: 0.7797 | dt: 85454.91ms | tok/sec: 61352.59
2024-06-16 12:52:11,325 train.py step  1774 | loss: 3.640896 | lr 6.0000e-05 | norm: 0.7355 | dt: 85479.12ms | tok/sec: 61335.21
2024-06-16 12:53:36,808 train.py step  1775 | loss: 3.582782 | lr 6.0000e-05 | norm: 0.7023 | dt: 85482.48ms | tok/sec: 61332.80
2024-06-16 12:55:02,301 train.py step  1776 | loss: 3.549478 | lr 6.0000e-05 | norm: 0.7767 | dt: 85493.22ms | tok/sec: 61325.10
2024-06-16 12:56:27,793 train.py step  1777 | loss: 3.501070 | lr 6.0000e-05 | norm: 0.7228 | dt: 85491.17ms | tok/sec: 61326.57
2024-06-16 12:57:53,288 train.py step  1778 | loss: 3.573927 | lr 6.0000e-05 | norm: 0.6955 | dt: 85494.96ms | tok/sec: 61323.85
2024-06-16 12:59:18,774 train.py step  1779 | loss: 3.582400 | lr 6.0000e-05 | norm: 0.6869 | dt: 85486.01ms | tok/sec: 61330.27
2024-06-16 13:00:44,270 train.py step  1780 | loss: 3.601823 | lr 6.0000e-05 | norm: 0.7400 | dt: 85495.11ms | tok/sec: 61323.74
2024-06-16 13:02:09,773 train.py step  1781 | loss: 3.559194 | lr 6.0000e-05 | norm: 0.7615 | dt: 85502.91ms | tok/sec: 61318.15
2024-06-16 13:03:35,277 train.py step  1782 | loss: 3.489245 | lr 6.0000e-05 | norm: 0.7203 | dt: 85503.22ms | tok/sec: 61317.93
2024-06-16 13:05:00,798 train.py step  1783 | loss: 3.615062 | lr 6.0000e-05 | norm: 0.7520 | dt: 85521.31ms | tok/sec: 61304.96
2024-06-16 13:06:26,318 train.py step  1784 | loss: 3.582784 | lr 6.0000e-05 | norm: 0.7914 | dt: 85518.83ms | tok/sec: 61306.73
2024-06-16 13:07:51,847 train.py step  1785 | loss: 3.569288 | lr 6.0000e-05 | norm: 0.7174 | dt: 85529.19ms | tok/sec: 61299.31
2024-06-16 13:09:17,390 train.py step  1786 | loss: 3.519269 | lr 6.0000e-05 | norm: 0.7505 | dt: 85542.76ms | tok/sec: 61289.58
2024-06-16 13:10:42,923 train.py step  1787 | loss: 3.553548 | lr 6.0000e-05 | norm: 0.8212 | dt: 85531.97ms | tok/sec: 61297.31
2024-06-16 13:12:08,433 train.py step  1788 | loss: 3.614680 | lr 6.0000e-05 | norm: 0.7927 | dt: 85509.85ms | tok/sec: 61313.17
2024-06-16 13:13:33,926 train.py step  1789 | loss: 3.597000 | lr 6.0000e-05 | norm: 0.7526 | dt: 85492.97ms | tok/sec: 61325.28
2024-06-16 13:14:59,399 train.py step  1790 | loss: 3.545065 | lr 6.0000e-05 | norm: 0.6553 | dt: 85472.42ms | tok/sec: 61340.02
2024-06-16 13:16:24,907 train.py step  1791 | loss: 3.481108 | lr 6.0000e-05 | norm: 0.7398 | dt: 85507.26ms | tok/sec: 61315.03
2024-06-16 13:17:50,419 train.py step  1792 | loss: 3.584522 | lr 6.0000e-05 | norm: 0.7130 | dt: 85511.59ms | tok/sec: 61311.92
2024-06-16 13:19:15,884 train.py step  1793 | loss: 3.638497 | lr 6.0000e-05 | norm: 0.6458 | dt: 85464.94ms | tok/sec: 61345.39
2024-06-16 13:20:41,356 train.py step  1794 | loss: 3.570435 | lr 6.0000e-05 | norm: 0.6853 | dt: 85471.87ms | tok/sec: 61340.42
2024-06-16 13:22:06,845 train.py step  1795 | loss: 3.544216 | lr 6.0000e-05 | norm: 0.7460 | dt: 85488.26ms | tok/sec: 61328.65
2024-06-16 13:23:32,360 train.py step  1796 | loss: 3.502878 | lr 6.0000e-05 | norm: 0.7263 | dt: 85514.81ms | tok/sec: 61309.62
2024-06-16 13:24:57,888 train.py step  1797 | loss: 3.558307 | lr 6.0000e-05 | norm: 0.7063 | dt: 85527.67ms | tok/sec: 61300.39
2024-06-16 13:26:23,388 train.py step  1798 | loss: 3.578259 | lr 6.0000e-05 | norm: 0.7041 | dt: 85498.93ms | tok/sec: 61321.00
2024-06-16 13:27:48,891 train.py step  1799 | loss: 3.596844 | lr 6.0000e-05 | norm: 0.6778 | dt: 85503.31ms | tok/sec: 61317.86
2024-06-16 13:29:14,371 train.py step  1800 | loss: 3.558740 | lr 6.0000e-05 | norm: 0.7091 | dt: 85478.89ms | tok/sec: 61335.38
2024-06-16 13:30:39,858 train.py step  1801 | loss: 3.476281 | lr 6.0000e-05 | norm: 0.6681 | dt: 85487.47ms | tok/sec: 61329.22
2024-06-16 13:32:05,376 train.py step  1802 | loss: 3.605666 | lr 6.0000e-05 | norm: 0.7240 | dt: 85516.80ms | tok/sec: 61308.18
2024-06-16 13:33:30,884 train.py step  1803 | loss: 3.585863 | lr 6.0000e-05 | norm: 0.8757 | dt: 85507.88ms | tok/sec: 61314.58
2024-06-16 13:34:56,383 train.py step  1804 | loss: 3.560926 | lr 6.0000e-05 | norm: 0.7409 | dt: 85499.04ms | tok/sec: 61320.93
2024-06-16 13:36:21,881 train.py step  1805 | loss: 3.515173 | lr 6.0000e-05 | norm: 0.8130 | dt: 85497.61ms | tok/sec: 61321.95
2024-06-16 13:37:47,383 train.py step  1806 | loss: 3.545852 | lr 6.0000e-05 | norm: 0.8416 | dt: 85501.47ms | tok/sec: 61319.18
2024-06-16 13:39:12,861 train.py step  1807 | loss: 3.609209 | lr 6.0000e-05 | norm: 0.6949 | dt: 85477.81ms | tok/sec: 61336.15
2024-06-16 13:40:38,378 train.py step  1808 | loss: 3.591083 | lr 6.0000e-05 | norm: 0.7172 | dt: 85516.11ms | tok/sec: 61308.68
2024-06-16 13:42:03,889 train.py step  1809 | loss: 3.543617 | lr 6.0000e-05 | norm: 0.8006 | dt: 85510.65ms | tok/sec: 61312.60
2024-06-16 13:43:29,386 train.py step  1810 | loss: 3.480079 | lr 6.0000e-05 | norm: 0.7290 | dt: 85496.81ms | tok/sec: 61322.52
2024-06-16 13:44:54,900 train.py step  1811 | loss: 3.566286 | lr 6.0000e-05 | norm: 0.7303 | dt: 85513.80ms | tok/sec: 61310.34
2024-06-16 13:46:20,417 train.py step  1812 | loss: 3.634639 | lr 6.0000e-05 | norm: 0.8522 | dt: 85516.01ms | tok/sec: 61308.76
2024-06-16 13:47:45,919 train.py step  1813 | loss: 3.568190 | lr 6.0000e-05 | norm: 0.7943 | dt: 85501.60ms | tok/sec: 61319.09
2024-06-16 13:49:11,390 train.py step  1814 | loss: 3.543636 | lr 6.0000e-05 | norm: 0.7619 | dt: 85470.64ms | tok/sec: 61341.30
2024-06-16 13:50:36,816 train.py step  1815 | loss: 3.499026 | lr 6.0000e-05 | norm: 0.8368 | dt: 85426.48ms | tok/sec: 61373.01
2024-06-16 13:52:02,254 train.py step  1816 | loss: 3.542752 | lr 6.0000e-05 | norm: 0.6858 | dt: 85437.24ms | tok/sec: 61365.28
2024-06-16 13:53:27,669 train.py step  1817 | loss: 3.580565 | lr 6.0000e-05 | norm: 0.6997 | dt: 85414.21ms | tok/sec: 61381.83
2024-06-16 13:54:53,108 train.py step  1818 | loss: 3.592638 | lr 6.0000e-05 | norm: 0.7682 | dt: 85438.64ms | tok/sec: 61364.28
2024-06-16 13:56:18,571 train.py step  1819 | loss: 3.549759 | lr 6.0000e-05 | norm: 0.7103 | dt: 85462.89ms | tok/sec: 61346.86
2024-06-16 13:57:44,024 train.py step  1820 | loss: 3.476471 | lr 6.0000e-05 | norm: 0.6408 | dt: 85452.85ms | tok/sec: 61354.07
2024-06-16 13:59:09,471 train.py step  1821 | loss: 3.589332 | lr 6.0000e-05 | norm: 0.7415 | dt: 85446.38ms | tok/sec: 61358.71
2024-06-16 14:00:34,949 train.py step  1822 | loss: 3.582161 | lr 6.0000e-05 | norm: 0.8074 | dt: 85477.65ms | tok/sec: 61336.27
2024-06-16 14:02:00,417 train.py step  1823 | loss: 3.560172 | lr 6.0000e-05 | norm: 0.7412 | dt: 85467.86ms | tok/sec: 61343.29
2024-06-16 14:03:25,927 train.py step  1824 | loss: 3.510154 | lr 6.0000e-05 | norm: 0.7434 | dt: 85508.87ms | tok/sec: 61313.87
2024-06-16 14:04:51,428 train.py step  1825 | loss: 3.525162 | lr 6.0000e-05 | norm: 0.7041 | dt: 85500.70ms | tok/sec: 61319.73
2024-06-16 14:06:16,917 train.py step  1826 | loss: 3.608707 | lr 6.0000e-05 | norm: 0.7130 | dt: 85489.43ms | tok/sec: 61327.81
2024-06-16 14:07:42,399 train.py step  1827 | loss: 3.582108 | lr 6.0000e-05 | norm: 0.7266 | dt: 85481.22ms | tok/sec: 61333.70
2024-06-16 14:09:07,852 train.py step  1828 | loss: 3.545509 | lr 6.0000e-05 | norm: 0.7168 | dt: 85452.15ms | tok/sec: 61354.57
2024-06-16 14:10:33,309 train.py step  1829 | loss: 3.475718 | lr 6.0000e-05 | norm: 0.6920 | dt: 85456.74ms | tok/sec: 61351.27
2024-06-16 14:11:58,842 train.py step  1830 | loss: 3.551744 | lr 6.0000e-05 | norm: 0.7217 | dt: 85532.64ms | tok/sec: 61296.83
2024-06-16 14:13:24,374 train.py step  1831 | loss: 3.628668 | lr 6.0000e-05 | norm: 0.6372 | dt: 85531.82ms | tok/sec: 61297.42
2024-06-16 14:14:49,876 train.py step  1832 | loss: 3.562773 | lr 6.0000e-05 | norm: 0.7043 | dt: 85501.66ms | tok/sec: 61319.04
2024-06-16 14:16:15,390 train.py step  1833 | loss: 3.536305 | lr 6.0000e-05 | norm: 0.6579 | dt: 85513.65ms | tok/sec: 61310.45
2024-06-16 14:17:40,909 train.py step  1834 | loss: 3.496663 | lr 6.0000e-05 | norm: 0.7012 | dt: 85518.97ms | tok/sec: 61306.63
2024-06-16 14:19:06,410 train.py step  1835 | loss: 3.527309 | lr 6.0000e-05 | norm: 0.7440 | dt: 85499.90ms | tok/sec: 61320.30
2024-06-16 14:20:31,927 train.py step  1836 | loss: 3.584745 | lr 6.0000e-05 | norm: 0.7181 | dt: 85516.71ms | tok/sec: 61308.25
2024-06-16 14:21:57,482 train.py step  1837 | loss: 3.579391 | lr 6.0000e-05 | norm: 0.7012 | dt: 85554.88ms | tok/sec: 61280.90
2024-06-16 14:23:23,010 train.py step  1838 | loss: 3.551258 | lr 6.0000e-05 | norm: 0.6938 | dt: 85527.25ms | tok/sec: 61300.70
2024-06-16 14:24:48,524 train.py step  1839 | loss: 3.467187 | lr 6.0000e-05 | norm: 0.7099 | dt: 85513.94ms | tok/sec: 61310.24
2024-06-16 14:26:14,059 train.py step  1840 | loss: 3.575792 | lr 6.0000e-05 | norm: 0.8386 | dt: 85534.26ms | tok/sec: 61295.67
2024-06-16 14:27:39,605 train.py step  1841 | loss: 3.580595 | lr 6.0000e-05 | norm: 0.8524 | dt: 85545.83ms | tok/sec: 61287.38
2024-06-16 14:29:05,111 train.py step  1842 | loss: 3.557295 | lr 6.0000e-05 | norm: 0.8031 | dt: 85506.05ms | tok/sec: 61315.90
2024-06-16 14:30:30,583 train.py step  1843 | loss: 3.514343 | lr 6.0000e-05 | norm: 0.7096 | dt: 85471.11ms | tok/sec: 61340.96
2024-06-16 14:31:56,090 train.py step  1844 | loss: 3.505544 | lr 6.0000e-05 | norm: 0.7501 | dt: 85506.74ms | tok/sec: 61315.40
2024-06-16 14:33:21,589 train.py step  1845 | loss: 3.606088 | lr 6.0000e-05 | norm: 0.7754 | dt: 85499.15ms | tok/sec: 61320.84
2024-06-16 14:34:47,095 train.py step  1846 | loss: 3.573223 | lr 6.0000e-05 | norm: 0.8066 | dt: 85504.97ms | tok/sec: 61316.67
2024-06-16 14:36:12,556 train.py step  1847 | loss: 3.544616 | lr 6.0000e-05 | norm: 0.6964 | dt: 85460.35ms | tok/sec: 61348.69
2024-06-16 14:37:38,043 train.py step  1848 | loss: 3.474469 | lr 6.0000e-05 | norm: 0.6640 | dt: 85486.85ms | tok/sec: 61329.67
2024-06-16 14:39:03,538 train.py step  1849 | loss: 3.541277 | lr 6.0000e-05 | norm: 0.7634 | dt: 85495.22ms | tok/sec: 61323.67
2024-06-16 14:40:29,015 train.py step  1850 | loss: 3.617638 | lr 6.0000e-05 | norm: 0.7204 | dt: 85476.53ms | tok/sec: 61337.07
2024-06-16 14:41:54,472 train.py step  1851 | loss: 3.560166 | lr 6.0000e-05 | norm: 0.7729 | dt: 85456.50ms | tok/sec: 61351.45
2024-06-16 14:43:19,943 train.py step  1852 | loss: 3.535353 | lr 6.0000e-05 | norm: 0.7038 | dt: 85470.01ms | tok/sec: 61341.75
2024-06-16 14:44:45,440 train.py step  1853 | loss: 3.496010 | lr 6.0000e-05 | norm: 0.7641 | dt: 85496.74ms | tok/sec: 61322.57
2024-06-16 14:46:10,924 train.py step  1854 | loss: 3.511056 | lr 6.0000e-05 | norm: 0.7168 | dt: 85484.21ms | tok/sec: 61331.56
2024-06-16 14:47:36,426 train.py step  1855 | loss: 3.578205 | lr 6.0000e-05 | norm: 0.6856 | dt: 85500.93ms | tok/sec: 61319.57
2024-06-16 14:49:01,980 train.py step  1856 | loss: 3.574308 | lr 6.0000e-05 | norm: 0.7296 | dt: 85554.14ms | tok/sec: 61281.43
2024-06-16 14:50:27,539 train.py step  1857 | loss: 3.548104 | lr 6.0000e-05 | norm: 0.7442 | dt: 85558.88ms | tok/sec: 61278.03
2024-06-16 14:51:53,100 train.py step  1858 | loss: 3.467320 | lr 6.0000e-05 | norm: 0.7032 | dt: 85560.60ms | tok/sec: 61276.80
2024-06-16 14:53:18,624 train.py step  1859 | loss: 3.561659 | lr 6.0000e-05 | norm: 0.7633 | dt: 85523.05ms | tok/sec: 61303.71
2024-06-16 14:54:44,164 train.py step  1860 | loss: 3.573106 | lr 6.0000e-05 | norm: 0.7373 | dt: 85539.98ms | tok/sec: 61291.57
2024-06-16 14:56:09,678 train.py step  1861 | loss: 3.548526 | lr 6.0000e-05 | norm: 0.7430 | dt: 85513.38ms | tok/sec: 61310.64
2024-06-16 14:57:35,153 train.py step  1862 | loss: 3.514981 | lr 6.0000e-05 | norm: 0.6710 | dt: 85474.51ms | tok/sec: 61338.52
2024-06-16 14:59:00,601 train.py step  1863 | loss: 3.490504 | lr 6.0000e-05 | norm: 0.7677 | dt: 85447.89ms | tok/sec: 61357.63
2024-06-16 15:00:26,029 train.py step  1864 | loss: 3.603400 | lr 6.0000e-05 | norm: 0.7676 | dt: 85427.15ms | tok/sec: 61372.53
2024-06-16 15:01:51,470 train.py step  1865 | loss: 3.568089 | lr 6.0000e-05 | norm: 0.7380 | dt: 85441.05ms | tok/sec: 61362.54
2024-06-16 15:03:16,905 train.py step  1866 | loss: 3.542264 | lr 6.0000e-05 | norm: 0.7339 | dt: 85434.25ms | tok/sec: 61367.42
2024-06-16 15:04:42,368 train.py step  1867 | loss: 3.477231 | lr 6.0000e-05 | norm: 0.7854 | dt: 85463.33ms | tok/sec: 61346.55
2024-06-16 15:06:07,827 train.py step  1868 | loss: 3.517659 | lr 6.0000e-05 | norm: 0.6786 | dt: 85458.32ms | tok/sec: 61350.14
2024-06-16 15:07:33,274 train.py step  1869 | loss: 3.611320 | lr 6.0000e-05 | norm: 0.6137 | dt: 85446.21ms | tok/sec: 61358.84
2024-06-16 15:08:58,712 train.py step  1870 | loss: 3.557135 | lr 6.0000e-05 | norm: 0.7312 | dt: 85438.05ms | tok/sec: 61364.70
2024-06-16 15:10:24,145 train.py step  1871 | loss: 3.533772 | lr 6.0000e-05 | norm: 0.6574 | dt: 85432.96ms | tok/sec: 61368.36
2024-06-16 15:11:49,560 train.py step  1872 | loss: 3.491435 | lr 6.0000e-05 | norm: 0.6692 | dt: 85414.18ms | tok/sec: 61381.84
2024-06-16 15:13:14,970 train.py step  1873 | loss: 3.499055 | lr 6.0000e-05 | norm: 0.6523 | dt: 85410.15ms | tok/sec: 61384.74
2024-06-16 15:14:40,397 train.py step  1874 | loss: 3.573418 | lr 6.0000e-05 | norm: 0.6676 | dt: 85425.91ms | tok/sec: 61373.42
2024-06-16 15:16:05,856 train.py step  1875 | loss: 3.567468 | lr 6.0000e-05 | norm: 0.6991 | dt: 85458.53ms | tok/sec: 61349.99
2024-06-16 15:17:31,347 train.py step  1876 | loss: 3.542989 | lr 6.0000e-05 | norm: 0.7577 | dt: 85491.11ms | tok/sec: 61326.61
2024-06-16 15:18:56,798 train.py step  1877 | loss: 3.473326 | lr 6.0000e-05 | norm: 0.7593 | dt: 85450.50ms | tok/sec: 61355.76
2024-06-16 15:20:22,242 train.py step  1878 | loss: 3.539112 | lr 6.0000e-05 | norm: 0.8223 | dt: 85443.61ms | tok/sec: 61360.70
2024-06-16 15:21:47,729 train.py step  1879 | loss: 3.574905 | lr 6.0000e-05 | norm: 0.9099 | dt: 85486.46ms | tok/sec: 61329.94
2024-06-16 15:23:13,214 train.py step  1880 | loss: 3.543588 | lr 6.0000e-05 | norm: 0.7974 | dt: 85484.56ms | tok/sec: 61331.31
2024-06-16 15:24:38,683 train.py step  1881 | loss: 3.515878 | lr 6.0000e-05 | norm: 0.7543 | dt: 85468.99ms | tok/sec: 61342.48
2024-06-16 15:26:04,154 train.py step  1882 | loss: 3.475030 | lr 6.0000e-05 | norm: 0.8257 | dt: 85470.34ms | tok/sec: 61341.51
2024-06-16 15:27:29,621 train.py step  1883 | loss: 3.599889 | lr 6.0000e-05 | norm: 0.7882 | dt: 85467.01ms | tok/sec: 61343.90
2024-06-16 15:28:55,110 train.py step  1884 | loss: 3.564880 | lr 6.0000e-05 | norm: 0.8190 | dt: 85488.64ms | tok/sec: 61328.38
2024-06-16 15:30:20,607 train.py step  1885 | loss: 3.540130 | lr 6.0000e-05 | norm: 0.8537 | dt: 85496.04ms | tok/sec: 61323.07
2024-06-16 15:31:46,089 train.py step  1886 | loss: 3.476966 | lr 6.0000e-05 | norm: 0.7312 | dt: 85482.01ms | tok/sec: 61333.14
2024-06-16 15:33:11,555 train.py step  1887 | loss: 3.498681 | lr 6.0000e-05 | norm: 0.6777 | dt: 85465.50ms | tok/sec: 61344.99
2024-06-16 15:34:37,026 train.py step  1888 | loss: 3.605676 | lr 6.0000e-05 | norm: 0.6531 | dt: 85470.37ms | tok/sec: 61341.49
2024-06-16 15:36:02,488 train.py step  1889 | loss: 3.567654 | lr 6.0000e-05 | norm: 0.6525 | dt: 85462.03ms | tok/sec: 61347.48
2024-06-16 15:37:27,969 train.py step  1890 | loss: 3.517606 | lr 6.0000e-05 | norm: 0.6352 | dt: 85480.45ms | tok/sec: 61334.26
2024-06-16 15:38:53,492 train.py step  1891 | loss: 3.489088 | lr 6.0000e-05 | norm: 0.6395 | dt: 85522.32ms | tok/sec: 61304.23
2024-06-16 15:40:18,992 train.py step  1892 | loss: 3.484245 | lr 6.0000e-05 | norm: 0.6377 | dt: 85499.91ms | tok/sec: 61320.30
2024-06-16 15:41:44,491 train.py step  1893 | loss: 3.570981 | lr 6.0000e-05 | norm: 0.6872 | dt: 85498.59ms | tok/sec: 61321.24
2024-06-16 15:43:09,986 train.py step  1894 | loss: 3.560869 | lr 6.0000e-05 | norm: 0.6758 | dt: 85494.60ms | tok/sec: 61324.11
2024-06-16 15:44:35,488 train.py step  1895 | loss: 3.537718 | lr 6.0000e-05 | norm: 0.6966 | dt: 85501.82ms | tok/sec: 61318.93
2024-06-16 15:46:00,995 train.py step  1896 | loss: 3.472812 | lr 6.0000e-05 | norm: 0.7337 | dt: 85506.85ms | tok/sec: 61315.32
2024-06-16 15:47:26,504 train.py step  1897 | loss: 3.529755 | lr 6.0000e-05 | norm: 0.8549 | dt: 85508.13ms | tok/sec: 61314.40
2024-06-16 15:48:52,001 train.py step  1898 | loss: 3.573260 | lr 6.0000e-05 | norm: 0.8971 | dt: 85496.97ms | tok/sec: 61322.41
2024-06-16 15:50:17,498 train.py step  1899 | loss: 3.532442 | lr 6.0000e-05 | norm: 0.9041 | dt: 85496.03ms | tok/sec: 61323.08
2024-06-16 15:51:42,999 train.py step  1900 | loss: 3.520750 | lr 6.0000e-05 | norm: 0.8615 | dt: 85500.68ms | tok/sec: 61319.75
2024-06-16 15:53:08,493 train.py step  1901 | loss: 3.459998 | lr 6.0000e-05 | norm: 0.7474 | dt: 85493.34ms | tok/sec: 61325.01
2024-06-16 15:54:33,971 train.py step  1902 | loss: 3.588695 | lr 6.0000e-05 | norm: 0.7766 | dt: 85478.44ms | tok/sec: 61335.70
2024-06-16 15:55:59,485 train.py step  1903 | loss: 3.561489 | lr 6.0000e-05 | norm: 0.7641 | dt: 85513.18ms | tok/sec: 61310.79
2024-06-16 15:57:24,972 train.py step  1904 | loss: 3.539121 | lr 6.0000e-05 | norm: 0.7151 | dt: 85486.77ms | tok/sec: 61329.73
2024-06-16 15:58:50,485 train.py step  1905 | loss: 3.477010 | lr 6.0000e-05 | norm: 0.7749 | dt: 85513.07ms | tok/sec: 61310.86
2024-06-16 16:00:16,030 train.py step  1906 | loss: 3.482702 | lr 6.0000e-05 | norm: 0.7023 | dt: 85544.18ms | tok/sec: 61288.56
2024-06-16 16:01:41,560 train.py step  1907 | loss: 3.595871 | lr 6.0000e-05 | norm: 0.6452 | dt: 85529.12ms | tok/sec: 61299.36
2024-06-16 16:03:07,053 train.py step  1908 | loss: 3.569528 | lr 6.0000e-05 | norm: 0.7538 | dt: 85493.59ms | tok/sec: 61324.83
2024-06-16 16:04:32,581 train.py step  1909 | loss: 3.512852 | lr 6.0000e-05 | norm: 0.7528 | dt: 85526.86ms | tok/sec: 61300.97
2024-06-16 16:05:58,132 train.py step  1910 | loss: 3.490571 | lr 6.0000e-05 | norm: 0.7714 | dt: 85551.00ms | tok/sec: 61283.68
2024-06-16 16:07:23,672 train.py step  1911 | loss: 3.466023 | lr 6.0000e-05 | norm: 0.8127 | dt: 85539.41ms | tok/sec: 61291.98
2024-06-16 16:08:49,188 train.py step  1912 | loss: 3.574246 | lr 6.0000e-05 | norm: 0.8272 | dt: 85515.37ms | tok/sec: 61309.21
2024-06-16 16:10:14,718 train.py step  1913 | loss: 3.552724 | lr 6.0000e-05 | norm: 0.7079 | dt: 85529.66ms | tok/sec: 61298.97
2024-06-16 16:11:40,233 train.py step  1914 | loss: 3.534092 | lr 6.0000e-05 | norm: 0.7437 | dt: 85514.67ms | tok/sec: 61309.71
2024-06-16 16:13:05,749 train.py step  1915 | loss: 3.475457 | lr 6.0000e-05 | norm: 0.8367 | dt: 85515.36ms | tok/sec: 61309.22
2024-06-16 16:14:31,246 train.py step  1916 | loss: 3.516829 | lr 6.0000e-05 | norm: 0.8266 | dt: 85497.29ms | tok/sec: 61322.18
2024-06-16 16:15:56,737 train.py step  1917 | loss: 3.564314 | lr 6.0000e-05 | norm: 0.7229 | dt: 85490.73ms | tok/sec: 61326.88
2024-06-16 16:17:22,245 train.py step  1918 | loss: 3.527114 | lr 6.0000e-05 | norm: 0.8696 | dt: 85507.55ms | tok/sec: 61314.82
2024-06-16 16:18:47,718 train.py step  1919 | loss: 3.519483 | lr 6.0000e-05 | norm: 0.9179 | dt: 85472.42ms | tok/sec: 61340.02
2024-06-16 16:20:13,169 train.py step  1920 | loss: 3.457259 | lr 6.0000e-05 | norm: 0.8743 | dt: 85450.80ms | tok/sec: 61355.54
2024-06-16 16:21:38,631 train.py step  1921 | loss: 3.568627 | lr 6.0000e-05 | norm: 0.8857 | dt: 85461.31ms | tok/sec: 61348.00
2024-06-16 16:23:04,118 train.py step  1922 | loss: 3.561727 | lr 6.0000e-05 | norm: 0.9062 | dt: 85486.72ms | tok/sec: 61329.76
2024-06-16 16:24:29,628 train.py step  1923 | loss: 3.538116 | lr 6.0000e-05 | norm: 0.8566 | dt: 85509.65ms | tok/sec: 61313.31
2024-06-16 16:25:55,085 train.py step  1924 | loss: 3.480603 | lr 6.0000e-05 | norm: 0.8076 | dt: 85456.53ms | tok/sec: 61351.43
2024-06-16 16:27:20,547 train.py step  1925 | loss: 3.470339 | lr 6.0000e-05 | norm: 0.7230 | dt: 85461.46ms | tok/sec: 61347.89
2024-06-16 16:28:46,039 train.py step  1926 | loss: 3.587002 | lr 6.0000e-05 | norm: 0.7874 | dt: 85491.99ms | tok/sec: 61325.98
2024-06-16 16:30:11,519 train.py step  1927 | loss: 3.569843 | lr 6.0000e-05 | norm: 0.7898 | dt: 85479.10ms | tok/sec: 61335.22
2024-06-16 16:31:37,041 train.py step  1928 | loss: 3.507755 | lr 6.0000e-05 | norm: 0.6699 | dt: 85522.36ms | tok/sec: 61304.20
2024-06-16 16:33:02,560 train.py step  1929 | loss: 3.495743 | lr 6.0000e-05 | norm: 0.7034 | dt: 85518.41ms | tok/sec: 61307.03
2024-06-16 16:34:28,027 train.py step  1930 | loss: 3.444962 | lr 6.0000e-05 | norm: 0.6559 | dt: 85465.93ms | tok/sec: 61344.68
2024-06-16 16:35:53,489 train.py step  1931 | loss: 3.571072 | lr 6.0000e-05 | norm: 0.7045 | dt: 85462.33ms | tok/sec: 61347.26
2024-06-16 16:37:18,979 train.py step  1932 | loss: 3.541007 | lr 6.0000e-05 | norm: 0.7950 | dt: 85489.44ms | tok/sec: 61327.81
2024-06-16 16:38:44,465 train.py step  1933 | loss: 3.538537 | lr 6.0000e-05 | norm: 0.8615 | dt: 85485.17ms | tok/sec: 61330.87
2024-06-16 16:40:09,944 train.py step  1934 | loss: 3.476746 | lr 6.0000e-05 | norm: 0.8443 | dt: 85479.06ms | tok/sec: 61335.25
2024-06-16 16:41:35,435 train.py step  1935 | loss: 3.502961 | lr 6.0000e-05 | norm: 0.8686 | dt: 85490.67ms | tok/sec: 61326.93
2024-06-16 16:43:00,917 train.py step  1936 | loss: 3.558775 | lr 6.0000e-05 | norm: 0.9547 | dt: 85481.45ms | tok/sec: 61333.54
2024-06-16 16:44:26,412 train.py step  1937 | loss: 3.526998 | lr 6.0000e-05 | norm: 0.9521 | dt: 85494.22ms | tok/sec: 61324.38
2024-06-16 16:45:51,930 train.py step  1938 | loss: 3.514642 | lr 6.0000e-05 | norm: 0.8174 | dt: 85518.39ms | tok/sec: 61307.05
2024-06-16 16:47:17,433 train.py step  1939 | loss: 3.456228 | lr 6.0000e-05 | norm: 0.8717 | dt: 85502.02ms | tok/sec: 61318.79
2024-06-16 16:48:42,914 train.py step  1940 | loss: 3.552411 | lr 6.0000e-05 | norm: 0.8199 | dt: 85480.95ms | tok/sec: 61333.90
2024-06-16 16:50:08,402 train.py step  1941 | loss: 3.558328 | lr 6.0000e-05 | norm: 0.8772 | dt: 85487.84ms | tok/sec: 61328.95
2024-06-16 16:51:33,901 train.py step  1942 | loss: 3.534263 | lr 6.0000e-05 | norm: 0.7863 | dt: 85497.88ms | tok/sec: 61321.75
2024-06-16 16:52:59,388 train.py step  1943 | loss: 3.477719 | lr 6.0000e-05 | norm: 0.7707 | dt: 85487.32ms | tok/sec: 61329.33
2024-06-16 16:54:24,872 train.py step  1944 | loss: 3.461215 | lr 6.0000e-05 | norm: 0.7872 | dt: 85483.16ms | tok/sec: 61332.31
2024-06-16 16:55:50,354 train.py step  1945 | loss: 3.580677 | lr 6.0000e-05 | norm: 0.6956 | dt: 85481.67ms | tok/sec: 61333.38
2024-06-16 16:57:15,875 train.py step  1946 | loss: 3.562339 | lr 6.0000e-05 | norm: 0.7235 | dt: 85521.01ms | tok/sec: 61305.17
2024-06-16 16:58:41,413 train.py step  1947 | loss: 3.507329 | lr 6.0000e-05 | norm: 0.7130 | dt: 85537.71ms | tok/sec: 61293.20
2024-06-16 17:00:06,941 train.py step  1948 | loss: 3.496153 | lr 6.0000e-05 | norm: 0.6966 | dt: 85527.01ms | tok/sec: 61300.87
2024-06-16 17:01:32,438 train.py step  1949 | loss: 3.429846 | lr 6.0000e-05 | norm: 0.6368 | dt: 85496.64ms | tok/sec: 61322.65
2024-06-16 17:02:57,960 train.py step  1950 | loss: 3.565087 | lr 6.0000e-05 | norm: 0.6930 | dt: 85521.54ms | tok/sec: 61304.79
2024-06-16 17:04:23,491 train.py step  1951 | loss: 3.536570 | lr 6.0000e-05 | norm: 0.7934 | dt: 85530.44ms | tok/sec: 61298.41
2024-06-16 17:05:49,013 train.py step  1952 | loss: 3.536160 | lr 6.0000e-05 | norm: 0.7453 | dt: 85521.96ms | tok/sec: 61304.49
2024-06-16 17:07:14,542 train.py step  1953 | loss: 3.474086 | lr 6.0000e-05 | norm: 0.7570 | dt: 85528.54ms | tok/sec: 61299.77
2024-06-16 17:08:40,081 train.py step  1954 | loss: 3.487645 | lr 6.0000e-05 | norm: 0.7880 | dt: 85538.91ms | tok/sec: 61292.34
2024-06-16 17:10:05,627 train.py step  1955 | loss: 3.557520 | lr 6.0000e-05 | norm: 0.7834 | dt: 85545.52ms | tok/sec: 61287.60
2024-06-16 17:11:31,143 train.py step  1956 | loss: 3.519388 | lr 6.0000e-05 | norm: 0.9065 | dt: 85515.53ms | tok/sec: 61309.10
2024-06-16 17:12:56,675 train.py step  1957 | loss: 3.511498 | lr 6.0000e-05 | norm: 0.8643 | dt: 85531.92ms | tok/sec: 61297.35
2024-06-16 17:14:22,218 train.py step  1958 | loss: 3.457421 | lr 6.0000e-05 | norm: 0.8061 | dt: 85542.73ms | tok/sec: 61289.60
2024-06-16 17:15:47,722 train.py step  1959 | loss: 3.531483 | lr 6.0000e-05 | norm: 0.8146 | dt: 85503.68ms | tok/sec: 61317.59
2024-06-16 17:17:13,221 train.py step  1960 | loss: 3.552259 | lr 6.0000e-05 | norm: 0.7633 | dt: 85497.81ms | tok/sec: 61321.80
2024-06-16 17:18:38,690 train.py step  1961 | loss: 3.534640 | lr 6.0000e-05 | norm: 0.7613 | dt: 85469.42ms | tok/sec: 61342.17
2024-06-16 17:20:04,160 train.py step  1962 | loss: 3.474054 | lr 6.0000e-05 | norm: 0.7393 | dt: 85468.84ms | tok/sec: 61342.59
2024-06-16 17:21:29,621 train.py step  1963 | loss: 3.448895 | lr 6.0000e-05 | norm: 0.7379 | dt: 85460.52ms | tok/sec: 61348.56
2024-06-16 17:22:55,164 train.py step  1964 | loss: 3.567628 | lr 6.0000e-05 | norm: 0.7615 | dt: 85543.38ms | tok/sec: 61289.14
2024-06-16 17:24:20,806 train.py step  1965 | loss: 3.568471 | lr 6.0000e-05 | norm: 0.7196 | dt: 85641.27ms | tok/sec: 61219.08
2024-06-16 17:25:46,274 train.py step  1966 | loss: 3.505394 | lr 6.0000e-05 | norm: 0.7356 | dt: 85467.44ms | tok/sec: 61343.59
2024-06-16 17:27:11,746 train.py step  1967 | loss: 3.488907 | lr 6.0000e-05 | norm: 0.7323 | dt: 85472.11ms | tok/sec: 61340.24
2024-06-16 17:28:37,220 train.py step  1968 | loss: 3.427270 | lr 6.0000e-05 | norm: 0.7086 | dt: 85473.39ms | tok/sec: 61339.33
2024-06-16 17:30:02,676 train.py step  1969 | loss: 3.552876 | lr 6.0000e-05 | norm: 0.7299 | dt: 85455.69ms | tok/sec: 61352.03
2024-06-16 17:31:28,104 train.py step  1970 | loss: 3.532625 | lr 6.0000e-05 | norm: 0.7533 | dt: 85427.32ms | tok/sec: 61372.40
2024-06-16 17:32:53,533 train.py step  1971 | loss: 3.530018 | lr 6.0000e-05 | norm: 0.7465 | dt: 85428.75ms | tok/sec: 61371.38
2024-06-16 17:34:18,970 train.py step  1972 | loss: 3.474482 | lr 6.0000e-05 | norm: 0.7619 | dt: 85436.29ms | tok/sec: 61365.96
2024-06-16 17:35:44,387 train.py step  1973 | loss: 3.472483 | lr 6.0000e-05 | norm: 0.6817 | dt: 85416.36ms | tok/sec: 61380.28
2024-06-16 17:37:09,783 train.py step  1974 | loss: 3.551352 | lr 6.0000e-05 | norm: 0.7103 | dt: 85396.24ms | tok/sec: 61394.74
2024-06-16 17:38:35,202 train.py step  1975 | loss: 3.510934 | lr 6.0000e-05 | norm: 0.8297 | dt: 85418.89ms | tok/sec: 61378.46
2024-06-16 17:40:00,603 train.py step  1976 | loss: 3.511234 | lr 6.0000e-05 | norm: 0.8021 | dt: 85400.43ms | tok/sec: 61391.73
2024-06-16 17:41:25,993 train.py step  1977 | loss: 3.455265 | lr 6.0000e-05 | norm: 0.8614 | dt: 85389.81ms | tok/sec: 61399.37
2024-06-16 17:42:51,388 train.py step  1978 | loss: 3.518226 | lr 6.0000e-05 | norm: 0.8634 | dt: 85394.27ms | tok/sec: 61396.16
2024-06-16 17:44:16,792 train.py step  1979 | loss: 3.551917 | lr 6.0000e-05 | norm: 0.7942 | dt: 85403.21ms | tok/sec: 61389.73
2024-06-16 17:45:42,199 train.py step  1980 | loss: 3.526679 | lr 6.0000e-05 | norm: 0.7409 | dt: 85406.59ms | tok/sec: 61387.30
2024-06-16 17:47:07,640 train.py step  1981 | loss: 3.474055 | lr 6.0000e-05 | norm: 0.6777 | dt: 85440.87ms | tok/sec: 61362.67
2024-06-16 17:48:33,070 train.py step  1982 | loss: 3.436068 | lr 6.0000e-05 | norm: 0.7561 | dt: 85430.09ms | tok/sec: 61370.42
2024-06-16 17:49:58,536 train.py step  1983 | loss: 3.555947 | lr 6.0000e-05 | norm: 0.7879 | dt: 85465.05ms | tok/sec: 61345.31
2024-06-16 17:51:24,000 train.py step  1984 | loss: 3.566150 | lr 6.0000e-05 | norm: 0.8096 | dt: 85463.92ms | tok/sec: 61346.12
2024-06-16 17:52:49,423 train.py step  1985 | loss: 3.505221 | lr 6.0000e-05 | norm: 0.7577 | dt: 85422.44ms | tok/sec: 61375.91
2024-06-16 17:54:14,870 train.py step  1986 | loss: 3.490554 | lr 6.0000e-05 | norm: 0.7627 | dt: 85446.95ms | tok/sec: 61358.30
2024-06-16 17:55:40,315 train.py step  1987 | loss: 3.418830 | lr 6.0000e-05 | norm: 0.8073 | dt: 85444.50ms | tok/sec: 61360.06
2024-06-16 17:57:05,767 train.py step  1988 | loss: 3.540606 | lr 6.0000e-05 | norm: 0.7562 | dt: 85451.63ms | tok/sec: 61354.95
2024-06-16 17:58:33,110 train.py step  1989 | loss: 3.516925 | lr 6.0000e-05 | norm: 0.8188 | dt: 87341.95ms | tok/sec: 60027.05
2024-06-16 17:59:58,630 train.py step  1990 | loss: 3.537532 | lr 6.0000e-05 | norm: 0.7708 | dt: 85520.09ms | tok/sec: 61305.83
2024-06-16 18:01:24,271 train.py step  1991 | loss: 3.478232 | lr 6.0000e-05 | norm: 0.8474 | dt: 85640.54ms | tok/sec: 61219.60
